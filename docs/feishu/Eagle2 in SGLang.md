---
title: Speculative Decoding in SGLang(EAGLE2)
created: 2026-01-12
updated: 2026-01-18
tags:
  - LLMInference
description: æœ¬æ–‡å°†ä»ä¸ºä»€ä¹ˆéœ€è¦ speculative decoding å¼€å§‹è®²èµ·ï¼Œé€šè¿‡å‡ ç¯‡è®ºæ–‡æ¥è®²è¿°ç°åœ¨æŠ•æœºé‡‡æ ·æ¼”è¿›çš„è·¯çº¿ï¼Œä»¥ SGLang ä¸­ Eagle2 çš„å®ç°ä½œä¸º example è¿›è¡Œè§£æï¼Œå¹¶ç»“åˆçº¦æŸè§£ç è¿›è¡Œå¼‚æ­¥ä¼˜åŒ–è¿›è¡Œéƒ¨åˆ†ç»“æœå¯¹æ¯”ã€‚
cover: /img/eagle2.png
---

# Speculative Decoding in SGLang(EAGLE2)

åœ¨æ­£å¼è¿›å…¥ SGLang æºç å‰ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ speculative decoding ä»¥åŠä»€ä¹ˆæ˜¯ speculative decodingã€‚æœ‰äº†è¿™äº›è®¤è¯†åï¼Œæˆ‘ä»¬å¯ä»¥æ·±å…¥æºç æ¥äº†è§£ SGLang æ˜¯å¦‚ä½•å°† speculative decoding ä¸ scheduler é›†æˆèµ·æ¥çš„

è¿™é‡Œå…ˆå¤§æ¦‚ç»™ä¸€ä¸‹ speculative decoding çš„ç¤ºæ„å›¾

![](static/XtNobrb2EoAGDMxMx1LcRq5VnfT.png)

## **Speculative Decoding Motivation**

åŸºäºä»¥ä¸‹è§‚å¯Ÿï¼Œæå‡ºäº† speculative decodingï¼Œåˆ©ç”¨ç©ºé—²è®¡ç®—èµ„æºå¢åŠ å¹¶è¡Œæ€§

- Many easy tokens can be predicted with less computational overhead(using a smaller model)
- LLM æ¨ç†æ˜¯é«˜åº¦ memory-bound çš„ï¼Œå»¶è¿Ÿä¸»è¦åœ¨è¯»å–/å†™å…¥æ¨¡å‹å‚æ•°è€Œä¸æ˜¯è®¡ç®—

> æ¯æ¬¡ç”Ÿæˆä¸€ä¸ª tokenï¼Œéƒ½éœ€è¦æ¬è¿æ‰€æœ‰æ¨¡å‹æƒé‡ä» HBM åˆ° cache ä¸­

æˆ‘ä»¬éœ€è¦ä¿è¯ speculative decoding ç”Ÿæˆå¤šä¸ª token çš„æˆæœ¬è¦æ¯” auto-regressive ç”Ÿæˆ 1 ä¸ª token æˆæœ¬å·®ä¸å¤šï¼Œæ‰€ä»¥æŠ•æœºé‡‡æ ·è¦æƒ³è·å¾—æ€§èƒ½æ”¶ç›Šï¼Œæ ¸å¿ƒè¦è§£å†³ä»¥ä¸‹ä¸¤ä¸ªé—®é¢˜ï¼š

> åœ¨æ•´ä¸ªæŠ•æœºé‡‡æ ·çš„æµç¨‹ä¸­ï¼Œå‡è®¾è½»é‡ LLM ç”Ÿæˆ Draft Tokens çš„å¼€é”€ä¸º $p$ ï¼ŒåŸå§‹ LLM éªŒè¯ & Next Token ç”Ÿæˆçš„å¼€é”€è¿‘ä¼¼ä¸º 1 ï¼Œé‚£ä¹ˆ**æŠ•æœºé‡‡æ ·åœ¨æ¥å— Tokens æ•°å¤§äº **$1 + p$** çš„æƒ…å†µä¸‹æ‰æœ‰æ€§èƒ½æ”¶ç›Š**ï¼Œå¹¶ä¸”éšç€æ¥å—çš„ Tokens æ•°å¢åŠ è€Œæ€§èƒ½æ”¶ç›Šè¶Šå¤§ã€‚

1. **å¦‚ä½•é™ä½æŠ•æœºé‡‡æ ·çš„ overheadï¼Ÿ**
2. **å¦‚ä½•æå‡ Verify é˜¶æ®µçš„æ¥å—ç‡ï¼Ÿ**

## **What is Speculative Decoding(Original)**

ä¸€èˆ¬éµå¾ªä»¥ä¸‹æµç¨‹ï¼š

- Draft: ç”Ÿæˆ k ä¸ª candidate tokensï¼Œä¿å­˜äº†æ¦‚ç‡åˆ†å¸ƒï¼Œå³ logits
- Verify:
  - ç”¨ target model å¹¶è¡Œ verify all candidate tokens
  - å¯¹æ¯ä¸ªä½ç½®çš„åˆ†å¸ƒè®¡ç®—æ¦‚ç‡
- Accept / Reject:
  - æ¥å—æ‰€æœ‰ correct token
  - åœ¨ç¬¬ä¸€ä¸ªè¢«æ‹’ç»é‡‡æ ·çš„ä½ç½®ï¼Œåœ¨**è°ƒæ•´åçš„åˆ†å¸ƒ**ä¸­é‡æ–°é‡‡æ ·

> [!IMPORTANT]
> è™½ç„¶å¼•å…¥äº†å°æ¨¡å‹ï¼Œä½†æœ€ç»ˆç”Ÿæˆçš„æ–‡æœ¬åˆ†å¸ƒï¼ˆDistributionï¼‰åœ¨æ•°å­¦ä¸Šä¸¥æ ¼ç­‰åŒäºå¤§æ¨¡å‹ç‹¬è‡ªç”Ÿæˆçš„åˆ†å¸ƒã€‚ å®ƒæ˜¯æ— æŸçš„ï¼ˆLosslessï¼‰

---

### Why lossless?

åŸºäºæ‹’ç»é‡‡æ ·çš„å˜ä½“ï¼š

- $M_p$ï¼šå¤§æ¨¡å‹ï¼ˆTarget Modelï¼‰ï¼Œæ¦‚ç‡åˆ†å¸ƒä¸º $p(x)$ã€‚
- $M_q$ï¼šå°æ¨¡å‹ï¼ˆDraft Modelï¼‰ï¼Œæ¦‚ç‡åˆ†å¸ƒä¸º $q(x)$ã€‚

å¯¹äºå°æ¨¡å‹ç”Ÿæˆçš„æ¯ä¸€ä¸ª token $x$ï¼Œæˆ‘ä»¬éœ€è¦æ ¹æ®å¤§æ¨¡å‹çš„åˆ¤å®šæ¥å†³å®šæ˜¯å¦æ¥å—ã€‚

- æƒ…å†µ Aï¼šå¤§æ¨¡å‹è§‰å¾—å°æ¨¡å‹çš„çŒœæµ‹å¾ˆé è°±
  - å¦‚æœ $p(x) \ge q(x)$ï¼ˆå³å¤§æ¨¡å‹è®¤ä¸ºè¯¥è¯å‡ºç°çš„æ¦‚ç‡æ¯”å°æ¨¡å‹é¢„æµ‹çš„è¿˜è¦é«˜æˆ–ç›¸ç­‰ï¼‰
  - æ“ä½œï¼š ç›´æ¥æ¥å—è¯¥ tokenã€‚
  - æ•°å­¦å«ä¹‰ï¼š è¿™ç§æƒ…å†µä¸‹ï¼Œæ¥å—ç‡ä¸º 1ã€‚
- æƒ…å†µ Bï¼šå¤§æ¨¡å‹è§‰å¾—å°æ¨¡å‹åœ¨ççŒœ
  - å¦‚æœ $p(x) < q(x)$ï¼ˆå³å¤§æ¨¡å‹è®¤ä¸ºè¯¥è¯å‡ºç°çš„æ¦‚ç‡ä½äºå°æ¨¡å‹é¢„æµ‹çš„ï¼‰ï¼š
  - æ“ä½œï¼š ä»¥æ¦‚ç‡ $\alpha = \frac{p(x)}{q(x)}$ æ¥å—è¯¥ tokenã€‚å¦‚æœä¸æ¥å—ï¼Œåˆ™æ‹’ç»è¯¥ token åŠå…¶ä¹‹åç”Ÿæˆçš„æ‰€æœ‰è‰ç¨¿ã€‚
  - ä¿®æ­£ï¼ˆResamplingï¼‰ï¼š ä¸€æ—¦æ‹’ç»ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°ç”Ÿæˆè¿™ä¸€ä¸ª tokenã€‚ä¸ºäº†ä¿è¯åˆ†å¸ƒä¸€è‡´æ€§ï¼Œæˆ‘ä»¬éœ€è¦ä»ä¿®æ­£åçš„åˆ†å¸ƒ $p'(x)$ ä¸­é‡‡æ ·ï¼š
    $$p'(x) = \text{norm}(\max(0, p(x) - q(x)))$$
  - è¿™ç¡®ä¿äº†è™½ç„¶æˆ‘ä»¬æ‹’ç»äº†é”™è¯¯çš„è‰ç¨¿ï¼Œä½†è¡¥å……å›æ¥çš„ token èƒ½å¤Ÿå¡«è¡¥æ¦‚ç‡åˆ†å¸ƒçš„ç¼ºå£ï¼Œä½¿å¾—æ€»ä½“åˆ†å¸ƒå›å½’åˆ° $p(x)$ã€‚

![](static/TtMJbQcBQoZLxAxbcoQcdKJUnBe.png)

---

## Some Limitations

æˆ‘ä»¬éœ€è¦è®© Draft Model çš„ç”Ÿæˆçš„ç›®æ ‡åˆ†å¸ƒä¸ Target Model ç›¸åŒï¼Œè¿™é‡Œæœ‰å¤šç§é€‰æ‹©æ–¹å¼

- é€‰å–ä¸ target model åŒä¸€ family çš„è¾ƒå°çš„æ¨¡å‹
- Distill ä¸€ä¸ªè½»é‡æ¨¡å‹ï¼Œteacher é€‰å– target modelï¼Œè¿™ä¼šå¼•å…¥ training cost
- é€‰å– ngram æ¨¡å‹ï¼Œä½†æ˜¯è¿™ä¸ªçš„æ¥å—ç‡å¾ˆä½

Draft model å’Œ target model éœ€è¦å…±äº« vocabulary æˆ–è€…ä½¿ç”¨ç›¸åŒçš„ tokenizer

- $p(x)$ å’Œ $q(x)$ å¿…é¡»å®šä¹‰åœ¨åŒä¸€ä¸ªæ ·æœ¬ç©ºé—´ä¸Š

---

## **å‘å±•å†ç¨‹**

### **Speculative Decoding (Leviathan et al., 2023, Google)**

ğŸ“„ _Fast Inference from Transformers via Speculative Decoding_

- é¦–æ¬¡æå‡ºè¯¥æ–¹æ³•ï¼Œæ€è·¯ï¼š
  - ç”¨ä¸€ä¸ªå°æ¨¡å‹ï¼ˆdraft modelï¼‰ç”Ÿæˆå¤šä¸ªå€™é€‰ tokenï¼›
  - ç”¨å¤§æ¨¡å‹ï¼ˆtarget modelï¼‰éªŒè¯å…¶ä¸­çš„ä¸€éƒ¨åˆ†ï¼›
  - è‹¥éªŒè¯é€šè¿‡ï¼Œåˆ™ä¸€æ¬¡æäº¤å¤šä¸ª tokenï¼Œå‡å°‘å¤§æ¨¡å‹è°ƒç”¨æ¬¡æ•°ã€‚

- ç”¨æ›´é«˜æ•ˆçš„æ¨¡å‹ $M_q$ ç”Ÿæˆ **Î³** ä¸ªå€™é€‰ tokenï¼›
- ç„¶åä½¿ç”¨ç›®æ ‡æ¨¡å‹ $M_p$ **å¹¶è¡Œ Verify** è¿™äº›å€™é€‰æ ·æœ¬åŠå…¶åœ¨ $M_q$ ä¸­çš„æ¦‚ç‡ï¼Œ å¹¶**æ¥å—**æ‰€æœ‰èƒ½ä½¿åˆ†å¸ƒä¸ $M_p$ ä¸€è‡´çš„å€™é€‰ï¼›

  > _å†³å®šè¢«æ¥å—çš„æ•°é‡ nï¼ˆç”¨éšæœºæ•°è¿›è¡Œæ‹’ç»é‡‡æ ·ï¼‰_

- æ¥å—æ‰€æœ‰æ­£ç¡®çš„é‡‡æ ·
  - å¯¹ç¬¬ä¸€ä¸ªè¢«æ‹’ç»çš„å€™é€‰ï¼Œä»ä¸€ä¸ª**è°ƒæ•´åçš„åˆ†å¸ƒ**ä¸­é‡æ–°é‡‡æ ·

  > å¦‚æœè‰ç¨¿æ¨¡å‹ $M_q$ åœ¨ç¬¬ n+1 ä¸ª token è¢«æ‹’ç»ï¼Œé‚£ä¹ˆç›®æ ‡æ¨¡å‹ $M_p$ ä¸èƒ½ç›´æ¥ç”¨è‡ªå·±çš„åˆ†å¸ƒé‡‡æ ·ï¼Œè€Œå¿…é¡»æŠŠå·²ç»è¢« $M_q$ å°è¯•ä½†æ‹’ç»æ‰çš„æ¦‚ç‡è´¨é‡ $M_p$ ä¸­å‡æ‰ï¼Œå†é‡æ–°å½’ä¸€åŒ–
  - å¦‚æœæ‰€æœ‰å€™é€‰éƒ½è¢«æ¥å—ï¼Œåªæ¥å— **Î³-1** ä¸ªï¼Œç„¶åå†é‡‡æ ·ä¸€ä¸ªé¢å¤–çš„ token

  > ä¿®æ­£çš„æ‹’ç»é‡‡æ ·æ–¹æ¡ˆå¯ä»¥ä¿æŒä¸ target é‡‡æ ·ç›¸åŒçš„ç›®æ ‡åˆ†å¸ƒ

![](static/TtMJbQcBQoZLxAxbcoQcdKJUnBe.png)

- Limitations
  - ä½¿ç”¨ separate çš„ draft model
    - Draft model è®­ç»ƒåæ•ˆæœæ¯”è¾ƒå¥½ï¼Œå¼•å…¥äº†è®­ç»ƒæˆæœ¬
    - Draft model å’Œ target model ä¹‹é—´çš„ distribution shift
  - Memory overhead of second model
  - æ¯æ¬¡è¿­ä»£åªæœ‰ä¸€ä¸ª draft sequence
  - $\gamma$æ˜¯å›ºå®šçš„ï¼Œç®€å•çš„ token ä¼šæµªè´¹èµ„æºï¼Œå¤æ‚çš„ token éœ€è¦æ›´å¤šçš„æ¨æµ‹

---

### **Medusa(No need for a separate draft model)**

ğŸ“„ MEDUSA: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads

- ä¸æ˜¯å•ç‹¬çš„å°æ¨¡å‹ï¼Œè€Œæ˜¯ **åœ¨å¤§æ¨¡å‹ decoder çš„ last hidden states ä¸Šç›´æ¥åŠ å¤šä¸ªé¢„æµ‹å¤´(1-2 layer mlp)**ï¼›
- æ¯ä¸ª head ä¼šä¸ºå®ƒè´Ÿè´£çš„ä½ç½®ç”Ÿæˆå¤šä¸ªæœ€å¯èƒ½çš„é¢„æµ‹
  - ç¬¬ t ä¸ª position ä½ç½®å¤„ï¼Œç¬¬ k ä¸ª head é¢„æµ‹ t+k+1 ä¸ª token
  - è¿™ä¼šå¢åŠ ä¸€æ¬¡ decoding step çš„æ¥å—é•¿åº¦
  - Verification can be computationally intensive for a large number of completions

  > We need trade-off

- ä¸ºäº†**åŠ é€Ÿ**ä¸**è®¡ç®—ä»£ä»·**ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œå¼•å…¥äº†ä¸€ç§ **æ ‘çŠ¶ç»“æ„çš„æ³¨æ„åŠ›æœºåˆ¶ï¼ˆtree-structured attentionï¼‰**ï¼Œå¯ä»¥**å¹¶è¡Œå¤„ç†å¤šä¸ªå€™é€‰åºåˆ—ï¼Œä¸€æ¬¡éªŒè¯ä¸€æ•´æ£µæ ‘**
  - ä¾æ®é¢„æµ‹çš„ probs æ„é€ äº†ä¸€ä¸ªç¨€ç–çš„ candidate tokens æ ‘
  - **Tree Mask**ï¼š**æ¯ä¸ª token åªèƒ½çœ‹åˆ°æ¥è‡ªåŒä¸€æ¡å€™é€‰åºåˆ—ï¼ˆcontinuationï¼‰çš„å†å² token**ï¼Œä¸èƒ½è®¿é—®å…¶ä»–å€™é€‰çš„ tokenã€‚
  - æŒ‰ç…§æ ‘ç»“æ„ï¼Œæ­£ç¡®åˆ†é… positional encoding

  > åŒä¸€æ·±åº¦çš„ token ç”¨åŒä¸€ä¸ª position id

- **ä¼šé€‰æ‹©é•¿åº¦æœ€é•¿çš„å‰ç¼€ candidate tokens**

![](static/SBtkb0kqConi4NxoTkHcNGs3nbb.png)
![](static/IacXbP7UpoGGfoxTT0Mcw1qBnyh.png)

- Limitations:
  - Position-Independent Prediction / Limited Information
    - æ¯ä¸ª Medusa head é¢„æµ‹ä½ç½® i+kï¼Œä½†å®ƒä¸çŸ¥é“ä½ç½®$i+1\dots i+k-1$ å®é™…é¢„æµ‹äº†ä»€ä¹ˆ

      > ä¸çœŸå®çš„è‡ªå›å½’ä¸åŒ

    - Medusa head åªèƒ½çœ‹åˆ°æœ€åä¸€å±‚çš„è¡¨ç¤º
    - æœ€åä¸€å±‚æ˜¯ä¸ºé¢„æµ‹ä¸‹ä¸€ä¸ª token è®­ç»ƒçš„ï¼Œè€Œä¸æ˜¯ç¬¬ 2ã€3 ä¸ªä¹‹åçš„ token
    - æ— æ³•åˆ©ç”¨ä¸­é—´å±‚æ›´ä¸°å¯Œçš„è¡¨ç¤º

  - Lower acceptance rates for later positions in the draft
  - Speedup plateaus at ~3Ã— even with more heads

---

### **Lookahead Decoding**

ğŸ“„ Lookahead: An Inference Acceleration Framework for Large Language Model with Lossles

![](static/UF1Bb6GNQoa8VsxFiKucHlNan4e.png)

- å±‚æ¬¡åŒ–å¤šåˆ†æ”¯è‰ç¨¿ç­–ç•¥ (Hierarchical Multi-Branch Draft Strategy)ï¼š_åˆ©ç”¨å…±åŒçš„å‰ç¼€æ ‡è®°å°†å¤šä¸ªé¢„æµ‹çš„è‰ç¨¿åºåˆ—ï¼ˆåˆ†æ”¯ï¼‰è¿›è¡Œåˆå¹¶å’Œå‹ç¼©_
- åŸºäº Trie æ ‘çš„è‰ç¨¿æ£€ç´¢å’Œç®¡ç† (Trie-tree-based Retrieval and Management)
  - Trie æ ‘å­˜å‚¨äº†**è¾“å…¥æç¤º (Prompt)** å’Œ**å·²ç”Ÿæˆå“åº” (Generated response)** ä¸­å‡ºç°çš„ n-gram æ ‡è®°åºåˆ—ï¼ˆå³åˆ†æ”¯ï¼‰ã€‚
  - å¼•å…¥äº† **ç”Ÿæˆåˆ†æ”¯æ’å…¥ (Generated branch Inserting)** æœºåˆ¶ï¼Œèƒ½å¤ŸåŠ¨æ€åœ° (on-the-fly) å°†ç”Ÿæˆçš„é‡å¤åºåˆ—æ”¾å…¥ Trie æ ‘ä¸­ï¼Œä»è€Œåˆ©ç”¨è¾“å‡ºä¸­çš„é‡å¤æ¨¡å¼è¿›è¡ŒåŠ é€Ÿã€‚
  - é€šè¿‡**åˆ†æ”¯æ¶ˆé™¤**å’Œ**èŠ‚ç‚¹ä¿®å‰ª**ç­–ç•¥æ¥ä¿æŒ Trie æ ‘çš„é«˜æ•ˆæ€§ï¼Œæ§åˆ¶å†…å­˜æ¶ˆè€—ã€‚

---

### **EAGLE-1ï¼š Extrapolation Algorithm for Greater Language-model Efficiency**

ğŸ“„ EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty

- Train a lightweight plugin, called AutoRegression Head, in conjunction with the Original LLM's frozen embedding layer, to predict the next feature based on the current feature sequence form the second-top-layer of the Original model
- Decode using the frozen classification head of the Original LLM, which maps features to tokens
- Feed in tokens from one time step ahead
  ![](static/SGvZbgg5Ho8of8xOc3zcUEFlnOe.png)

#### EAGLE-1 Drafting

EAGLE-1 è§£å†³äº† Medusa çš„ä¸ç¡®å®šæ€§ï¼Œä½¿ç”¨äº† feature-level è¿›è¡Œé¢„æµ‹

- Feature prediction with known context is much more accurate
- EAGLE integrates embeddings and generates the next feature
- When predicting $f_j$, we already know $f_{j-1}$

$$
\begin{aligned}
(f_n, t_n)&\rightarrow f_{n+1} \\
f_{n+1} &\rightarrow LM\_Head \rightarrow t_{n+1}\\
(f_{n+1}, t_{n+1}) &\rightarrow f_{n+2}
\end{aligned}
$$

#### EAGLE-1 Verification

- å¯¹æ¯ä¸ª draft token position ç”Ÿæˆ target probs p
- **Tree Attention**ï¼šç›´æ¥ verify æ•´ä¸ª tree
  - EAGLE ç”Ÿæˆçš„æ ‘æ›´ç¨€ç–ã€ä¸Šä¸‹æ–‡æ›´å……åˆ†

  > æ¯ä¸€æ­¥é¢„æµ‹éƒ½çŸ¥é“å‰é¢ token æ˜¯ä»€ä¹ˆï¼Œé€šè¿‡ feature å¯ä»¥å¾—åˆ°æ›´å¤šçš„ä¿¡æ¯
  - Medusa Head 2 predicting t+2 doesnâ€™t know what t+1 will be

![](static/ESsIb5cwLo30xcx1fQScTQsknLd.png)
![](static/SxXrbrkuuoaXzjxMMvzcEB9Vnxf.png)

#### Multi-round speculative sampling

æŠŠåŒä¸€ä½ç½®çš„å¤šä¸ªå€™é€‰ token æŒ‰é¡ºåºåšå¤šè½® accept / rejectï¼›åªæœ‰å½“æ‰€æœ‰å€™é€‰éƒ½æ‹’ç»äº†ï¼Œæ‰ä»è°ƒæ•´åçš„åˆ†å¸ƒé‡ŒçœŸæ­£é‡‡æ ·ä¸€ä¸ª tokenã€‚è¿™æ ·èƒ½ æå‡æ¥å—ç‡ / å‡å°‘ fallbackï¼ŒåŒæ—¶ä»ç„¶ä¿æŒä¸¥æ ¼æ— åï¼ˆæœ€ç»ˆ token ä»æœä»ç›®æ ‡åˆ†å¸ƒ pï¼‰

- **ä¾æ¬¡å°è¯•** $t_1,t_2,t_3\dots ,t_k$
- æ¯æ¬¡å°è¯•å¤±è´¥ï¼Œä¸æ˜¯ç«‹åˆ»ä» adjusted distribution é‡‡æ ·ï¼Œè€Œæ˜¯ï¼š
  - **æ›´æ–°ç›®æ ‡åˆ†å¸ƒ p**ï¼ˆæ‰£æ‰æœ¬è½® proposal é‚£éƒ¨åˆ†æ¦‚ç‡é‡æ–°è¿›è¡Œåˆ†å¸ƒï¼‰
  - ç„¶åç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªå€™é€‰

- å¦‚æœ k ä¸ªéƒ½å¤±è´¥äº†ï¼Œæ‰ä»æœ€ç»ˆå‰©ä¸‹çš„ adjusted åˆ†å¸ƒé‡‡æ ·ä¸€æ¬¡

![](static/CPIYbPOrEofK1RxCLjAc1vRCnTd.png)

---

### **EAGLE-2: Context-Aware speculation**

ğŸ“„ EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees

- High confidence â†’ high acceptance probability â†’ expand the tree
- Low confidence â†’ low acceptance probability â†’ prune the tree

Context-aware speculation:

- Easy context (code boilerplate): Deeper trees
- Hard context (creative writing): Shallower, wider trees

#### Motivation

- æ¥å—ç‡é™¤äº†ä¸ **Token æ‰€åœ¨ä½ç½®ç›¸å…³ä»¥å¤–ï¼ˆåœ¨æ ‘ä¸­æ‰€å¤„çš„ä½ç½®ï¼‰ï¼Œè¿˜å’Œä¸Šæ–‡ç›¸å…³ï¼ˆæ ‘ä¸­çš„ç¥–å®—èŠ‚ç‚¹ï¼‰**ã€‚

  ![](static/XjY6bHv81omhS1xPgw3cFAxznGc.png)

  > _P3ã€P4 å’Œ P5ã€P6 è™½ç„¶éƒ½æ˜¯åŒä¸€å±‚çš„èŠ‚ç‚¹ï¼ˆå³åŒä¸€ä¸ª Step çš„ Draft Tokensï¼‰ï¼Œä½†æ¥æ”¶ç‡ä¸Š P3ã€P4 æ™®éé«˜äº P5ã€P6 èŠ‚ç‚¹ï¼Œä¸€ä¸ªé‡è¦çš„åŸå› æ˜¯ P3ã€P4 çš„çˆ¶èŠ‚ç‚¹ä¸º P1ï¼Œå…¶æ¦‚ç‡é«˜äº P5ã€P6 èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹ P2ã€‚P3ã€P4 çš„æ¦‚ç‡ç”šè‡³æ™®éé«˜äº P2 è¿™æ›´åŠ è¯´æ˜åœ¨ç”Ÿæˆ Draft æ ‘çš„æ—¶å€™ï¼Œé‡‡ç”¨é™æ€ Draft æ ‘å¹¶ä¸æ˜¯ä¸€ä¸ªæœ€ä¼˜é€‰æ‹©ï¼Œæ›´åº”è¯¥é€‰æ‹©åŠ¨æ€ Draft æ ‘ã€‚_

- åŸå§‹ LLM è‡ªå›å½’ç”Ÿæˆçš„ Token æ¦‚ç‡åˆ†å¸ƒè¡¨ç¤º Token æ¥æ”¶æ¦‚ç‡ã€‚Eagle çš„ Draft æ¨¡å‹ç”Ÿæˆçš„ Draft Tokens æ¦‚ç‡åˆ†å¸ƒä¸ Token æ¥æ”¶ç‡åˆ†å¸ƒæ¥è¿‘ã€‚ä¸‹å›¾å±•ç¤ºäº† Draft Tokens ç”Ÿæˆæ¦‚ç‡å’Œ Token æ¥æ”¶ç‡çš„åˆ†å¸ƒå›¾ï¼Œå¯ä»¥çœ‹å‡ºåˆ†å¸ƒå¾ˆæ¥è¿‘ï¼Œ**å¯ä»¥é€šè¿‡ Draft Tokens ç”Ÿæˆæ¦‚ç‡é¢„ä¼° Token çš„æ¥æ”¶ç‡ã€‚**

  ![](static/Q5SYb75o0oQ01pxLzJ3ck8Zbnjd.png)

#### EAGLE-2 Dynamic Tree Construction

EAGLE-2 ä¸ä¿®æ”¹ draft æ¨¡å‹çš„è®­ç»ƒä¸æ¨ç†æ–¹å¼ï¼Œä¹Ÿä¸æ”¹å˜éªŒè¯é˜¶æ®µã€‚å®ƒçš„æ”¹è¿›é›†ä¸­åœ¨ä¸¤ä¸ªæ–¹é¢ï¼š

1. å¦‚ä½•æ‰©å±•è‰ç¨¿æ ‘ï¼›
2. å¦‚ä½•å¯¹è‰ç¨¿ token è¿›è¡Œé‡æ–°æ’åº

- **Expand é˜¶æ®µ**ï¼šä»å½“å‰å±‚é€‰æ‹© **å…¨å±€æ¥å—æ¦‚ç‡ï¼ˆglobal acceptance probabilityï¼‰æœ€é«˜çš„å‰ k ä¸ª token** è¿›è¡Œæ‰©å±•ã€‚
  - ä¸€ä¸ª token çš„**å…¨å±€æ¥å—æ¦‚ç‡**æ˜¯å®ƒä»æ ¹èŠ‚ç‚¹åˆ°è¯¥èŠ‚ç‚¹è·¯å¾„ä¸Šæ‰€æœ‰ token çš„æ¥å—æ¦‚ç‡çš„ä¹˜ç§¯ï¼š
    $V_i = \prod_{t_j \in \text{Path(root, }t_i\text{)}} p_j \approx \prod c_jï¼Œ$ å…¶ä¸­$c_j$æ˜¯ draft æ¨¡å‹çš„ç½®ä¿¡åº¦
- **ReRank é˜¶æ®µ**ï¼š**ä¸ä¼šç›´æ¥ä½¿ç”¨æ‰©å±•é˜¶æ®µçš„ç»“æœï¼Œè€Œæ˜¯å¯¹æ‰€æœ‰è‰ç¨¿ token é‡æ–°æ’åº**ï¼Œé€‰å‡ºå…¨å±€ top-m çš„èŠ‚ç‚¹ã€‚

> _Expand çš„ç›®æ ‡æ˜¯åŠ æ·±è‰ç¨¿æ ‘ã€‚ç„¶è€Œï¼Œç”±äºæ¥å—ç‡åœ¨ 0â€“1 ä¹‹é—´ï¼Œè¶Šæ·±çš„ token å…¶å€¼è¶Šå°ã€‚_**ä¸€äº›æµ…å±‚æœªæ‰©å±•èŠ‚ç‚¹å¯èƒ½æ¯”æ·±å±‚èŠ‚ç‚¹æ›´æœ‰ä»·å€¼**_ã€‚_
> **å¯¹äºå€¼ç›¸åŒçš„èŠ‚ç‚¹ï¼Œä¼˜å…ˆé€‰æ‹©æµ…å±‚èŠ‚ç‚¹ï¼Œå§‹ç»ˆä¿æŒçˆ¶èŠ‚ç‚¹åœ¨å­èŠ‚ç‚¹ä¹‹å‰è¢«é€‰ä¸­ã€‚** è¿™æ ·å¯ä»¥ä¿è¯ top-m èŠ‚ç‚¹ä»æ„æˆä¸€æ£µè¿é€šæ ‘ã€‚

![](static/MY8GbmDMloCvYHxBR8ackqBEnMg.png)

- **Tree Mask**ï¼šæŠŠè¿™äº›é€‰ä¸­çš„ token **æ‹‰å¹³æˆä¸€ç»´åºåˆ—**ï¼Œé€å…¥ä¸»æ¨¡å‹è¿›è¡ŒéªŒè¯é˜¶æ®µã€‚ä¸ºäº†ä¸æ ‡å‡†è‡ªå›å½’è§£ç ä¿æŒä¸€è‡´ï¼Œæˆ‘ä»¬éœ€è¦è°ƒæ•´æ³¨æ„åŠ›æ©ç ã€‚ä¸åŒåˆ†æ”¯çš„ token ä¸åº”äº’ç›¸å¯è§ï¼Œå› æ­¤æ³¨æ„åŠ›æ©ç éœ€æ ¹æ®æ ‘ç»“æ„ä¿®æ”¹ï¼Œä½¿æ¯ä¸ª token ä»…èƒ½çœ‹åˆ°å®ƒçš„ç¥–å…ˆèŠ‚ç‚¹ã€‚

![](static/YvJ0bRiPko1c35xB773cDJEjnuc.png)

---

### EAGLE-3: Training-time test + Direct Token Prediction + Multi-level fusion

#### Motivation

- Increasing training data for EAGLE-1/2 provides **limited** improvement
- **EAGLE Training: Loss = L_fea + L_token**
  - Feature prediction loss constrains the model
  - Model must output something close to target features
  - This limits expressiveness!

- **The Feature Prediction Constraint:**
  - Forces draft model output to approximate target features
  - Limits the model's representational capacity
  - Token prediction is the goal; feature prediction is an auxiliary objective
  - If those outputs arenâ€™t â€œfeature-like,â€ the next step becomes out-of-distribution

#### EAGLE-3: Training-time test

**With L_fea (EAGLE-1/2)**

- Training step 2 still uses **ground-truth features** as context
- But at test time, step 2 uses **predicted** features
- L_fea partially masks this because predicted â‰ˆ ground-truth
  **Without L_fea (failure mode)**
- Training never sees the modelâ€™s unconstrained predictions as inputs
- Test time does â†’ out-of-distribution â†’ compounding error
  Core rule: **if the model will consume its own predictions at test time, it should practice that during training**
- Train by simulating multiple draft steps **using predicted states**, not ground truth
- Important implementation detail: **stop-gradient** through the simulated rollout so training remains stable

![](static/CHSkbIARBo6KKRxvu2Kcf36jn0g.png)

- Removes the need for a strict â€œfeature-likenessâ€ constraint
- Model learns to be robust to its own imperfect intermediate states
- Capacity is spent on â€œwhat helps token accuracy under rollout,â€ not â€œmatch a specific feature targetâ€

#### EAGLE-3: Tree Attention Mask during training of the draft model

- è™½ç„¶è‡ªå›å½’æ¨ç†åœ¨æ—¶é—´ä¸Šæ˜¯é¡ºåºçš„ï¼Œä½†åœ¨è®­ç»ƒæ—¶å¯ä»¥æŠŠå¤šæ­¥ rollout é‡æ„æˆä¸€æ£µæ ‘ï¼Œå¹¶ç”¨æ ‘çŠ¶ attention mask ä¸€æ¬¡æ€§å¹¶è¡Œè®¡ç®—ï¼Œä»è€Œè®©æ¨¡å‹åœ¨è®­ç»ƒé˜¶æ®µå°±ç»å†â€œä½¿ç”¨è‡ªèº«é¢„æµ‹ä½œä¸ºä¸Šä¸‹æ–‡â€çš„çœŸå®æµ‹è¯•æ¡ä»¶ã€‚
  ![](static/PHTwbskerob0S2xP7SFcSZDHngb.png)

#### EAGLE-3: Multi-layer feature fusion

ä¸€æ—¦ä¸å†å¼ºè¿«é¢„æµ‹ feature å»åƒæŸä¸€å±‚çš„ ground-truth featureâ€ï¼ˆç§»é™¤ $L_{\text{fea}}$ï¼‰ï¼Œæ¨¡å‹å°±å¯ä»¥è‡ªç”±åœ°åˆ©ç”¨ä¸åŒå±‚çš„è¡¨ç¤ºï¼š

- Top-layer features are "committed" to the immediate next token
- Lower layers contain richer, more general semantic information
- Predicting t+2 benefits from information not yet "collapsed" into next-token prediction
- Fusion captures multiple abstraction levels

![](static/SstFbSngvoTJwqxqwBOcGDp6n3b.png)

---

## Eagle2 æ¨ç†æµç¨‹

- Target Prefill/Decodeï¼šè·å– hidden_states + next_token
- Draft Prefil/Draft Tree Generationï¼šå¤šæ­¥å±•å¼€ï¼Œå¤šæ¬¡è°ƒç”¨ draft model ç”Ÿæˆ Draft Treeï¼ŒReRank å¾—åˆ°æœ€ç»ˆçš„ draft tokens tree
- Build Tree Maskï¼šæ„å»ºéªŒè¯éœ€è¦çš„ tree attention mask
- Target Verifyï¼šè·å– target model å¯¹æ¯ä¸ª draft token çš„æ¦‚ç‡åˆ†å¸ƒï¼Œç”¨äºåç»­çš„ speculative sampling éªŒè¯
- Target Sampleï¼šåŸºäºæ¦‚ç‡çš„ rejection sampling çš„é‡‡æ ·
- Draft Extendï¼šä¸ºä¸‹ä¸€è½® Draft åšå‡†å¤‡

### Prefill Phase

**Target Prefill**

ç›®æ ‡æ¨¡å‹å…ˆè¿›è¡Œ prefillï¼Œå¾—åˆ° hidden_states å’Œ next_token_ids

**Draft Prefill**

ä¿®æ”¹ batch.input*idsï¼Œæˆªæ–­ç¬¬ä¸€ä¸ª tokenï¼Œå°†ç”Ÿæˆçš„ next_token_ids æ‹¼æ¥åˆ°åé¢ã€‚å› ä¸ºEagle çš„æ ¸å¿ƒå…¬å¼é€šå¸¸æ˜¯ï¼š$$H*{t+1}^{draft} = \text{Eagle}(H*{t}^{base}, \text{Emb}(x*{t+1}))$$

- $H_{t}^{base}$ï¼šBase Model å¤„ç†ç¬¬ $t$ ä¸ªè¯åè¾“å‡ºçš„ç‰¹å¾ã€‚
- $x_{t+1}$ï¼šç¬¬ $t+1$ ä¸ªè¯ï¼ˆå³ä¸‹ä¸€ä¸ªè¯ï¼‰ã€‚
  - Prompt: [A, B, C]
  - Base Model è¾“å‡ºç‰¹å¾: [H_A, H_B, H_C]
  - Base Model é¢„æµ‹çš„æ–°è¯: D
  - Eagle éœ€è¦å­¦ä¹ /é¢„æµ‹çš„åºåˆ—å¯¹å¦‚ä¸‹ï¼š
    - åˆ©ç”¨ H_A å’Œ B $\rightarrow$ é¢„æµ‹ H_B'
    - åˆ©ç”¨ H_B å’Œ C $\rightarrow$ é¢„æµ‹ H_C'
    - åˆ©ç”¨ H_C å’Œ D $\rightarrow$ é¢„æµ‹ H_D'

æ„é€  EagleDraftInputï¼Œå°† next_token_ids ä½œä¸º verified_idï¼Œåé¢æ„é€  tree mask ç”¨åˆ°

```python
# Construct spec_info
next_draft_input = EagleDraftInput(
    hidden_states=target_hidden_states,
    verified_id=next_token_ids,
    new_seq_lens=batch.seq_lens,
    # draft mode is same with decode mode, only 1 num token per batch
    num_tokens_per_batch=1,
    num_tokens_for_logprob_per_batch=1,
)
```

è¿›è¡ŒçœŸæ­£çš„ Draft Model Forwardï¼Œæ›´æ–° hidden_states å’Œç›¸åº”çš„ topk_index

### Decode Phase

**Draft Tree Generation**
è·å– prefill æˆ–è€…ä¸Šä¸€ä¸ª decode çš„ topk_indexï¼Œhidden_statesã€‚

å¤šæ­¥å±•å¼€æ„å»º draft tree:

- é€‰æ‹© top-k tokens ä½œä¸ºè¿™ä¸€å±‚çš„æ‰©å±•èŠ‚ç‚¹ï¼Œparent_list è®°å½•æ¯ä¸ª token å¯¹åº”çš„çˆ¶èŠ‚ç‚¹ç´¢å¼•
- Draft Model Forward è·å–ä¸‹ä¸€å±‚çš„ logits ç”¨äºä¸‹ä¸€å±‚æ›´æ–°
  - batch çš„ input_ids æ˜¯è¿™ä¸€å±‚çš„ top-k tokens
- å¯¹ logits è¿›è¡Œ topk é€‰æ‹©ï¼Œæ›´æ–° topk_index ä»¥åŠ hidden_statesï¼Œç”¨äºä¸‹ä¸€å±‚æ›´æ–°

ReRank draft tokens

- åˆå¹¶æ‰€æœ‰æ­¥çš„åˆ†æ•°
- é€‰æ‹©åˆ†æ•°æœ€é«˜çš„ (num_draft_tokens - 1) ä¸ª
- æ’åºï¼Œå¦‚æœç›¸åŒé€‰æ‹©æµ…å±‚èŠ‚ç‚¹ä¿è¯æ ‘ç»“æ„çš„æ­£ç¡®æ€§

**Build Tree Mask**

å°† verified_id(æ¯ä¸ª req ä¸€ä¸ª) æ‹¼åœ¨ draft_tokens çš„æœ€å‰é¢ã€‚

- ä¸»æ¨¡å‹éªŒè¯ç¬¬ 1 ä¸ªè‰ç¨¿ Token æ—¶ï¼Œéœ€è¦ä¾èµ– verified_id ä½œä¸ºä¸Šä¸‹æ–‡ã€‚

- æ–°çš„ draft_tokens åºåˆ— = [Root, Node1, Node2, ...]ã€‚

è°ƒç”¨ CUDA kernel æ„å»º Tree maskï¼ŒæŠŠ Python/Pytorch å±‚é¢ç”Ÿæˆçš„ä¸€å †çˆ¶å­å…³ç³»åˆ—è¡¨ï¼Œå¹¶è¡Œåœ°è½¬æ¢æˆ Base Model æ¨ç†æ‰€å¿…é¡»çš„ä¸‰ä¸ªåº•å±‚å¼ é‡ï¼š

- tree_mask (Attention Mask)ï¼šå†³å®šæ¯ä¸ª Token èƒ½çœ‹åˆ°è°ï¼ˆåªèƒ½çœ‹ç¥–å…ˆï¼Œä¸èƒ½çœ‹å…„å¼Ÿï¼‰ã€‚

- positions (Position IDs)ï¼šå†³å®šæ¯ä¸ª Token åœ¨æ ‘ä¸­çš„æ·±åº¦ï¼ˆç”¨äºä½ç½®ç¼–ç ï¼‰ã€‚

- retrive\_\* (æ‹“æ‰‘ç´¢å¼•)ï¼šæ„å»ºé“¾è¡¨ç»“æ„ï¼Œç”¨äºéªŒè¯åå¿«é€Ÿæå–æœ€é•¿è·¯å¾„ã€‚

æ„å»º EagleVerifyInputï¼Œç”¨äºåé¢çš„ Target Verify

```python
EagleVerifyInput(
    draft_token=draft_tokens, # draft tree tokens
    custom_mask=tree_mask,    # tree mask
    positions=position,       # position in tree(depth)
    retrive_index=retrive_index, # ç”¨äºä» logits ä¸­æå–å¯¹åº” token çš„ç´¢å¼•
    retrive_next_token=retrive_next_token, # æ ‘ç»“æ„ä¸­çš„å­èŠ‚ç‚¹ç´¢å¼•
    retrive_next_sibling=retrive_next_sibling, # æ ‘ç»“æ„ä¸­çš„å…„å¼ŸèŠ‚ç‚¹ç´¢å¼•
    retrive_cum_len=None,
    spec_steps=self.speculative_num_steps, # æ ‘çš„æœ€å¤§æ·±åº¦
    topk=self.topk,
    draft_token_num=self.speculative_num_draft_tokens,
    capture_hidden_mode=None,
    seq_lens_sum=None,
    seq_lens_cpu=None,
)
```

**Target Verify**
verify input çš„ num_steps åº”è¯¥ + 1ï¼Œå› ä¸º verified_id éœ€è¦åŠ åœ¨æœ€å‰é¢

åˆ†é… KV Cacheï¼Œç„¶åæ„å»º forward batch ç»™ Target Model ä½¿ç”¨

Target verify æ˜¯ç”¨ target modelï¼ˆå¤§æ¨¡å‹ï¼‰å¯¹ draft model ç”Ÿæˆçš„ draft token tree è¿›è¡Œå¹¶è¡Œ forwardï¼š

è¾“å…¥: æ‰€æœ‰ draft tokensï¼ˆæ ‘å½¢ç»“æ„å±•å¹³åï¼‰
è¾“å‡º: æ¯ä¸ª draft token ä½ç½®çš„ logitsï¼ˆnext_token_logitsï¼‰
ç›®çš„: è·å– target model å¯¹æ¯ä¸ª draft token çš„æ¦‚ç‡åˆ†å¸ƒï¼Œç”¨äºåç»­çš„ speculative sampling éªŒè¯

**Target Sample**

ç„¶åè°ƒç”¨ Sample è¿›è¡Œé‡‡æ ·ï¼Œæ ¹æ® Target Model çš„ logits è¿›è¡Œåˆ¤æ–­æ˜¯å¦å¯ä»¥æ¥å— draft token

- Greedy: Target Model ç›´æ¥é€‰æ¦‚ç‡æœ€å¤§çš„è¯ï¼ˆTop-1ï¼‰ã€‚å¦‚æœ Target_Top1 == Draft_Tokenï¼Œåˆ™é€šè¿‡ï¼›å¦åˆ™æˆªæ–­
  - æŸä¸€å±‚çš„èŠ‚ç‚¹è¢«é€‰ä¸­ç›´æ¥å‰å¾€ä¸‹ä¸€å±‚ï¼›å¦‚æœæ²¡æœ‰é€‰ä¸­ï¼Œéå†è¿™ä¸€å±‚çš„å…„å¼ŸèŠ‚ç‚¹
  - Bonus Token: æ— è®ºæ˜¯å¦æœ‰ draft token éªŒè¯æˆåŠŸï¼Œä¸»æ¨¡å‹åœ¨æœ€åä¸€æ­¥é¢„æµ‹çš„é‚£ä¸ª Tokenï¼ˆå³ä½¿è‰ç¨¿æ²¡çŒœå¯¹ï¼‰ä¹Ÿä¼šè¢«ç›´æ¥é‡‡çº³

- Speculative Sampling: æ²¡æœ‰æŒ‰ç…§æ ‡å‡†çš„åšæ³•æ¥åšï¼Œè€Œæ˜¯ä½¿ç”¨äº†è¦†ç›–é‡‡æ ·å˜ä½“
  - prob_acc è¡¨ç¤ºå½“å‰è¿™ç»„è‰ç¨¿å…„å¼ŸèŠ‚ç‚¹æ‰€è¦†ç›–çš„ä¸»æ¨¡å‹æ¦‚ç‡æ€»å’Œã€‚
  - coin <= prob_acc / threshold_accï¼šå¦‚æœè¿™ç¾¤å…„å¼ŸåŠ èµ·æ¥çš„æ¦‚ç‡è¶³å¤Ÿå¤§ï¼ˆè¦†ç›–äº†éšæœºç¡¬å¸è½åœ¨çš„åŒºé—´ï¼‰ï¼Œæˆ‘ä»¬å°±ä»ä¸­é€‰ä¸€ä¸ªï¼ˆä»£ç é€»è¾‘ç®€åŒ–ä¸ºé€‰ç´¯åŠ åˆ°å½“å‰åˆšè¶…è¿‡é˜ˆå€¼çš„é‚£ä¸ªï¼‰ã€‚
  - target_prob_single >= threshold_singleï¼šå¦‚æœæœ‰ä»»ä½•ä¸€ä¸ª Token å•ç‹¬çš„ç½®ä¿¡åº¦æé«˜ï¼ˆæ¯”å¦‚ >0.9ï¼‰ï¼Œç›´æ¥é€šè¿‡ï¼Œä¸éœ€è¦ç®¡ç´¯è®¡æ¦‚ç‡ã€‚è¿™æ˜¯ä¸ºäº†ä¿ç•™ç¡®å®šæ€§ã€‚
  - Bonus Token: æ„é€ ä¸€ä¸ªæ®‹å·®åˆ†å¸ƒï¼š$P_{new}(x) = \text{Norm}(\max(0, P(x) - P_{consumed}(x)))$ï¼Œåœ¨è¿™ä¸ªåˆ†å¸ƒä¸­æŠ½å–ä¸€ä¸ª tokenï¼Œåœ¨ä¸»æ¨¡å‹çš„æ¦‚ç‡åˆ†å¸ƒä¸­ï¼ŒæŒ–æ‰åˆšæ‰æ‰€æœ‰è¢«æ‹’ç»çš„ Token æ‰€å çš„å‘ï¼Œç„¶ååœ¨å‰©ä¸‹çš„å‘é‡ŒéšæœºæŠ½ä¸€ä¸ª token(ä»£ç ä¸­é€‰æ‹©ç´¯è®¡æ¦‚ç‡è¶…è¿‡ u çš„é‚£ä¸ª Token)

ç„¶åé‡Šæ”¾å¹¶ç§»åŠ¨ KV Cacheï¼Œè®©å®ƒä»¬å˜å¾—è¿ç»­

æ›´æ–° verified_id(**bs å¤§å°ï¼Œæ¯ä¸ª req çš„æœ€åè¢«æ¥å—çš„ token**)ï¼Œç„¶åæ„å»ºä¸‹ä¸€æ¬¡ draft çš„ EagleDraftInput

```python
all_verified_id = predict[accept_index]
verified_id = torch.empty_like(accept_length, dtype=torch.int32)
fill_new_verified_id[(bs,)](
    all_verified_id,
    accept_length,
    verified_id,
    self.speculative_num_draft_tokens,
)
# Construct the next draft input
next_draft_input = EagleDraftInput(
    verified_id=verified_id,
    new_seq_lens=new_seq_lens,
    verify_done=verify_done,
)
```

**Draft Extend**
æ›´æ–° Draft Model forward_batch ç›¸å…³å…ƒæ•°æ®

```python
batch.input_ids = predict  (all accepted + bonus tokens)
batch.seq_lens += num_draft_tokens
batch.forward_mode = ForwardMode.DRAFT_EXTEND_V2
```

è¿›è¡Œä¸€æ¬¡ Draft Model Forwardï¼Œæ›´æ–° hidden_statesï¼Œtopk_indexï¼Œä¾›ä¸‹ä¸€æ¬¡ Draft Tree Generation ä½¿ç”¨

---

## Eagle2 KV Cache Management

å…±äº« req_to_token_pool å’Œ token_to_kv_pool_allocatorï¼Œå®é™…ä¸Š target model å’Œ draft model æœ‰è‡ªå·±çš„ KV Cache pool

```shell
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         å®é™…çš„ KV Cache æ¶æ„                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                      å…± äº« çš„ éƒ¨ åˆ†                                      â”‚   â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚   â”‚  req_to_token_pool          token_to_kv_pool_allocator                  â”‚   â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚   â”‚
â”‚   â”‚  â”‚ req â†’ slot æ˜ å°„   â”‚       â”‚ ç®¡ç† slot åˆ†é…/é‡Šæ”¾       â”‚                â”‚   â”‚
â”‚   â”‚  â”‚ (ç´¢å¼•è¡¨)          â”‚       â”‚ free_pages = [1,2,3...]  â”‚                â”‚   â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                       â”‚                                         â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚              â–¼                                                 â–¼                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚    Target Model KV Pool      â”‚          â”‚     Draft Model KV Pool      â”‚   â”‚
â”‚   â”‚    (å„è‡ªæ‹¥æœ‰çš„éƒ¨åˆ†)           â”‚          â”‚     (å„è‡ªæ‹¥æœ‰çš„éƒ¨åˆ†)          â”‚   â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚   â”‚  token_to_kv_pool            â”‚          â”‚  token_to_kv_pool            â”‚   â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚   â”‚  â”‚ k_buffer[L_t, S, H, D] â”‚  â”‚          â”‚  â”‚ k_buffer[L_d, S, H, D] â”‚  â”‚   â”‚
â”‚   â”‚  â”‚ v_buffer[L_t, S, H, D] â”‚  â”‚          â”‚  â”‚ v_buffer[L_d, S, H, D] â”‚  â”‚   â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚   â”‚  L_t = 32å±‚ (Targetå¤§æ¨¡å‹)   â”‚          â”‚  L_d = 1å±‚ (EAGLE Head)      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

L_t = Target Model çš„å±‚æ•° (e.g., 32 layers for 7B model)
L_d = Draft Model çš„å±‚æ•° (é€šå¸¸åªæœ‰ 1 å±‚ attention)
S = max_total_num_tokens (slot æ•°é‡)
H = num_kv_heads
D = head_dim
```

---

### KV Cache ç”Ÿå‘½å‘¨æœŸ

#### Overview

```shell
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           å®Œæ•´çš„ KV Cache ç”Ÿå‘½å‘¨æœŸ                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚  Iteration N:                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  1. prepare_for_decode() - é¢„åˆ†é…                                                 â”‚   â”‚
â”‚  â”‚     alloc_token_slots(2 * ALLOC_LEN_PER_DECODE)                                  â”‚   â”‚
â”‚  â”‚     â†’ out_cache_loc = [100, 101, 102, ..., 139]  (å‡è®¾åˆ†é…äº†40ä¸ªslots)           â”‚   â”‚
â”‚  â”‚     â†’ assign_req_to_token_pool æ›´æ–°æ˜ å°„è¡¨                                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                          â”‚                                              â”‚
â”‚                                          â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  2. Draft Forward - ä½¿ç”¨é¢„åˆ†é…çš„ä½ç½®                                              â”‚   â”‚
â”‚  â”‚     assign_draft_cache_locs_page_size_1 ä» req_to_token è¯»å–ä½ç½®                 â”‚   â”‚
â”‚  â”‚     Draft Model åœ¨è¿™äº›ä½ç½®å†™å…¥ KV Cache                                           â”‚   â”‚
â”‚  â”‚     â†’ ç”Ÿæˆ draft_tokens, tree_mask ç­‰                                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                          â”‚                                              â”‚
â”‚                                          â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  3. Target Verify - ä½¿ç”¨åŒæ ·çš„ä½ç½®                                                â”‚   â”‚
â”‚  â”‚     assign_extend_cache_locs_func ä» req_to_token è¯»å–ä½ç½®                       â”‚   â”‚
â”‚  â”‚     Target Model åœ¨è¿™äº›ä½ç½®å†™å…¥ KV Cache                                          â”‚   â”‚
â”‚  â”‚     â†’ éªŒè¯ draft tokensï¼Œå¾—åˆ° accept_index                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                          â”‚                                              â”‚
â”‚                                          â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  4. Free & Move - Scheduler å¤„ç†                                                  â”‚   â”‚
â”‚  â”‚                                                                                   â”‚   â”‚
â”‚  â”‚    é€šè¿‡ kv_committed_len å’Œ kv_allocated_len æ¥è¿›è¡Œé‡Šæ”¾
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                          â”‚                                              â”‚
â”‚                                          â–¼                                              â”‚
â”‚  Iteration N+1: é‡å¤ä¸Šè¿°è¿‡ç¨‹                                                             â”‚
â”‚                                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### Free æœºåˆ¶

```shell
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ä¸¤ç§ KV é•¿åº¦è¿½è¸ª                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚   req.kv_committed_len     req.kv_allocated_len                                        â”‚
â”‚          â”‚                         â”‚                                                    â”‚
â”‚          â”‚  å®é™…æœ‰æ•ˆçš„ KV é•¿åº¦      â”‚  å·²åˆ†é…ä½†å¯èƒ½æœªä½¿ç”¨çš„ KV é•¿åº¦                        â”‚
â”‚          â”‚  (accepted tokens)      â”‚  (åŒ…å«é¢„åˆ†é…çš„ç©ºé—´)                                 â”‚
â”‚          â–¼                         â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ KV Cache Slots:                                                                  â”‚  â”‚
â”‚   â”‚                                                                                  â”‚  â”‚
â”‚   â”‚ [  prefill tokens  ][  accepted  ][     overallocated (æœªä½¿ç”¨)     ]              â”‚  â”‚
â”‚   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚  â”‚
â”‚   â”‚           kv_committed_len        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚   â”‚                                              éœ€è¦é‡Šæ”¾çš„éƒ¨åˆ†                        â”‚  â”‚
â”‚   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚   â”‚                           kv_allocated_len                                       â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                         â”‚
â”‚   åœ¨ V2 ç‰ˆæœ¬ä¸­:                                                                          â”‚
â”‚   - kv_committed_len: ç”± scheduler åœ¨ _resolve_spec_overlap_token_ids() ä¸­æ›´æ–°          â”‚
â”‚   - kv_allocated_len: ç”± prepare_for_decode() åœ¨é¢„åˆ†é…æ—¶æ›´æ–°                             â”‚
â”‚   - å·®å€¼ (kv_allocated_len - kv_committed_len) = éœ€è¦é‡Šæ”¾çš„ rejected/unused slots        â”‚
â”‚                                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

rejected tokens çš„ KV Cache çš„**ä¸åœ¨ Verify åç«‹å³é‡Šæ”¾ï¼Œåœ¨è¯·æ±‚å®Œæˆæ—¶ç»Ÿä¸€é‡Šæ”¾**

1. Verify å®Œæˆåæ›´æ–° kv_committed_len
   ```python
   for i, req in enumerate(batch.reqs):
     req.kv_committed_len += accept_lens[i]  # â† åªæ›´æ–° committed é•¿åº¦
     predict_tokens.append(...)
     req.spec_verify_ct += 1
     req.spec_accepted_tokens += accept_lens[i] - 1
     # æ³¨æ„: è¿™é‡Œæ²¡æœ‰é‡Šæ”¾ rejected slotsï¼
     # kv_allocated_len ä¿æŒä¸å˜ï¼Œä»ç„¶æŒ‡å‘é¢„åˆ†é…çš„æœ«å°¾
   ```
2. ä¸‹ä¸€è½® decode æ—¶å¤ç”¨é¢„åˆ†é…ç©ºé—´
   ```python
    for r in batch.reqs:
    # Over-allocation happens here
    # å½“å‰æœ‰æ•ˆä½ç½® + éœ€è¦çš„ç©ºé—´ - å·²åˆ†é…çš„ä½ç½®
    x = r.kv_committed_len + 2 * self.ALLOC_LEN_PER_DECODE - r.kv_allocated_len
    cur_kv_lens_cpu.append(r.kv_allocated_len)
    nxt_kv_lens_cpu.append(r.kv_allocated_len + x)
    num_needed_tokens += x
    r.kv_allocated_len += x
   ```
3. è¯·æ±‚å®Œæˆæ—¶é‡Šæ”¾ overallocated slots

   ```python
   def release_kv_cache(req: Req, tree_cache: BasePrefixCache, is_insert: bool = True):
    # 1. å…ˆå¤„ç† committed éƒ¨åˆ† (å¯èƒ½æ’å…¥ radix cache)
    tree_cache.cache_finished_req(req, is_insert=is_insert)
    # 2. è·å– overallocated èŒƒå›´
    start_p, end_p = req.pop_overallocated_kv_cache()

    if spec_algo is None:
        assert (
            start_p == end_p
        ), f"Unexpected overallocated KV cache, {req.kv_committed_len=}, {req.kv_allocated_len=}"

    # 3. é‡Šæ”¾ overallocated çš„ slots
    if page_size > 1:
        start_p = ceil_align(start_p, page_size)

    if start_p >= end_p:
        return

    indices_to_free = tree_cache.req_to_token_pool.req_to_token[req.req_pool_idx][
        start_p:end_p
    ]
    tree_cache.token_to_kv_pool_allocator.free(indices_to_free)
   ```

---

#### Prefill Phase

Draft Prefill ä¸ Target Prefill ä½¿ç”¨ç›¸åŒçš„ KV slots å¡«å…… Draft çš„ KV Cache

#### Decode Phase

schedule batch è¿›è¡Œ decode é˜¶æ®µçš„é¢„åˆ†é…

```python
def prepare_for_decode(self: EagleDraftInput, batch: ScheduleBatch):
    for r in batch.reqs:
        # è¿‡åº¦åˆ†é…ï¼š2 * ALLOC_LEN_PER_DECODE
        # ALLOC_LEN_PER_DECODE = max(topk * num_steps, num_draft_tokens)
        x = r.kv_committed_len + 2 * self.ALLOC_LEN_PER_DECODE - r.kv_allocated_len
        num_needed_tokens += x
        r.kv_allocated_len += x

    out_cache_loc = alloc_token_slots(batch.tree_cache, num_needed_tokens)
```

åœ¨ Draft Tree Generation å‰ï¼Œä¸º draft tree çš„æ¯ä¸ª token åˆ†é… KV Cacheï¼Œå®é™…ä¸Šæ˜¯ä½¿ç”¨é¢„åˆ†é…çš„ slotsï¼›ç„¶åè¿›è¡Œ Draft Model Froward

åœ¨è¿›è¡Œ Target Verify å‰ï¼Œä¸º Target Model åˆ†é… KV Cacheï¼Œä»ç„¶ä½¿ç”¨çš„æ˜¯é¢„åˆ†é…çš„ slotsï¼›ç„¶å Target Model å¯¹æ‰€æœ‰çš„ draft token è¿›è¡Œä¸€æ¬¡ forward(batch.input_ids = EagleVerifyInput.draft_tokens)

Scheduler åœ¨åå¤„ç†æ—¶å¯¹ over allocation çš„é•¿åº¦è¿›è¡Œé‡Šæ”¾

---

## **Overlap Eagle2 + Grammar in SGLang**

### Overview

- Draft çš„çŠ¶æ€é€šè¿‡ batch.spec_info æ¥è¿›è¡Œç®¡ç†ï¼›ä¸åœåœ°åœ¨ Scheduler å’Œ EAGLEWorkerV2 ä¸­æµè½¬
- å°† draft å’Œ verify æ•°æ®å‡†å¤‡å·¥ä½œå•ç‹¬å¼€è¾Ÿä¸€ä¸ª GPU plan stream è¿›è¡Œï¼Œä¸ GPU compute stream å¹¶è¡Œ
- å› ä¸ºæ•°æ®å‡†å¤‡å·¥ä½œ(**KV Cache ç­‰**)ä¼šå½±å“åˆ°åç»­è¿™äº›è¿‡ç¨‹è®¡ç®—çš„æ­£ç¡®æ€§ï¼Œæ‰€ä»¥åœ¨å¯åŠ¨ GPU compute kernel å‰éœ€è¦ç­‰å¾… plan kernel æ‰§è¡Œå®Œæˆ

**åŒæ­¥ç‚¹**[è§ä¸‹æ–‡](#åŒæ­¥ç‚¹)**ï¼š**

1. Verify ä¸ Draft Extend ä¹‹é—´çš„åŒæ­¥
2. Draft ä¸ Verify ä¹‹é—´çš„åŒæ­¥
3. Verify ä¸ Sampling ä¹‹é—´çš„åŒæ­¥

![](static/WiM4bkw4Ko06PLxMGJgcyYAhnKb.png)

### æ—¶åºå›¾

![](../notes/sglang/img/eagle2+grammar.png)

### æ•´ä½“æµç¨‹

Prefill é˜¶æ®µç”Ÿæˆ batch ä¸ä¸å¼€å¯ spec å¹¶æ— ä¸åŒï¼›é€šè¿‡ self.future_map.resolve_future() å’Œ self.future_map.store_to_map() å®ç°å¼‚æ­¥çš„ç»“æœå­˜å–

`run_batch()` ä¼šå…ˆè°ƒç”¨ EAGLEWorkerV2::forward_batch_generation()

- target_worker(TpWorker) æ‰§è¡Œ `forward_batch_generation`ï¼Œé‡‡æ ·å‡ºç¬¬ä¸€ä¸ª token

> Eagle éœ€è¦è¿™ä¸ª token å¯¹åº”çš„ hidden states è¿›è¡Œ draft çš„æ¨ç†

- draft_worker(EAGLEWorkerV2) æ‰§è¡Œ `_draft_extend_for_prefill`
  - å°† target model ç”Ÿæˆçš„ token ä¹ŸåŠ å…¥åˆ° batch.input_ids é‡Œé¢
  - æ„é€  EagleDraftInputï¼ŒEAGLE v2 çš„ decode é˜¶æ®µä¼šåŸºäº `verified_id` ä½œä¸ºæ ‘çš„æ ¹èŠ‚ç‚¹ï¼Œå†ç”Ÿæˆ topk åˆ†æ”¯å¹¶æ„å»º tree maskã€positions ç­‰
  - è°ƒç”¨ draft model çš„ forward_extend() å¹¶è¿›è¡Œé‡‡æ ·ï¼Œå¾—åˆ° topk çš„ token index & prob ä»¥åŠ hidden states

- åœ¨ decode é˜¶æ®µï¼Œdraft worker å…ˆè°ƒç”¨ draft()ï¼Œå†è°ƒç”¨ verify()ï¼Œæœ€å \_draft_extend_for_decode()
  - draft(): æŒ‰ `speculative_num_steps` å¤šæ­¥æ‰©å±•ä¸€æ£µ top-k æ ‘ï¼Œè®°å½•æ¯ä¸ªèŠ‚ç‚¹ token/score/parentï¼Œæœ€åä»æ•´æ£µæ ‘é‡ŒæŒ‘ä¸€æ‰¹æœ€é«˜åˆ†èŠ‚ç‚¹ä½œä¸º `draft_tokens`ï¼Œå¹¶è¿”å›æ ‘ç»“æ„ä¿¡æ¯ç»™ `build_tree_kernel_efficient`ï¼Œæ„é€ å‡º EageleVerifyInput
    > åœ¨ build tree mask æ—¶ï¼Œä¼šå°† verified_id æ‹¼æ¥åˆ° draft tokens å‰é¢ä½œä¸º root
    ```python
    EagleVerifyInput(
        draft_token_=draft_tokens, # draft é˜¶æ®µæŒ‘é€‰å‡ºæ¥ã€å‡†å¤‡è®© target ä¸€æ¬¡éªŒè¯çš„ **å€™é€‰ token é›†åˆ**
        custom_mask_=tree_mask, # æ¯ä¸ªå€™é€‰èŠ‚ç‚¹èƒ½çœ‹åˆ°å“ªäº› token
        positions_=position, # æ¯ä¸ªå€™é€‰èŠ‚ç‚¹å¯¹åº”çš„ **position id**
        retrive_index_=retrive_index, # verify batch ä¸­ç¬¬ i è¡Œï¼Œå¯¹åº” draft æ ‘é‡Œçš„å“ªä¸ªèŠ‚ç‚¹
        retrive_next_token_=retrive_next_token, # å¦‚æœæŸä¸ªèŠ‚ç‚¹è¢«æ¥å—ï¼Œä¸‹ä¸€ä¸ªåº”è¯¥è·³åˆ°å“ªä¸ªèŠ‚ç‚¹
        retrive_next_sibling_=retrive_next_sibling, # å¦‚æœå½“å‰èŠ‚ç‚¹æ²¡è¢«æ¥å—ï¼Œä¸‹ä¸€ä¸ªå¤‡é€‰å…„å¼ŸèŠ‚ç‚¹æ˜¯è°
        retrive_cum_len_=None,
        spec_steps_=_self_.speculative_num_steps, # draft æ‰©å±•çš„æœ€å¤§æ·±åº¦ï¼ˆæ ‘çš„é«˜åº¦ï¼‰
        topk_=_self_.topk, # draft é˜¶æ®µæ¯ä¸ªèŠ‚ç‚¹çš„åˆ†æ”¯æ•°
        draft_token_num_=_self_.speculative_num_draft_tokens,
        capture_hidden_mode_=None,
        seq_lens_sum_=None,
        seq_lens_cpu_=None,
    )
    ```

- verify(): verify ä¸€æ¬¡ forwardï¼Œ**æœ€å¤šéªŒè¯ spec_steps ä¸ªæœªæ¥ token + å½“å‰ token**
  - æŠŠ verify æ‰€éœ€çš„ **tree ç´¢å¼•å’Œ token(verify_input)** ä» GPU æ‹·åˆ° CPUï¼Œå‡†å¤‡æ›´æ–° vocab mask
    > è¿™é‡Œåº”è¯¥ç”¨å¼‚æ­¥æ‹·è´
  - Target model æ‰§è¡Œ `forward_batch_generation()`ï¼Œå®é™…ä¸Šç›´æ¥è·³è¿‡äº† sampleï¼Œåªåš forwardï¼Œå¾—åˆ° logits(every draft token çš„æ¦‚ç‡åˆ†å¸ƒ)
  - CPU ä¸­ grammar åç«¯ç”Ÿæˆäº† token bitmask
    - å¯¹ draft æ ‘åš DFS æ„é€  vocab mask
    - æŠŠ batch.sampling_info.vocab_mask ç½®ç©ºï¼ˆ`None`ï¼‰
  - å°† mask æ‹·è´åˆ° GPUï¼Œå¯¹ target model ç”Ÿæˆçš„ logits åº”ç”¨è¿™ä¸ª vocab mask
  - å¯¹ draft input åš sampleï¼ŒåŒæ—¶è€ƒè™‘ target çš„æ¦‚ç‡åˆ†å¸ƒå’Œ draft çš„ token
    > [!IMPORTANT]
    > Anyway, ç›®æ ‡æ¨¡å‹ç”Ÿæˆçš„ bonus token æˆ‘ä»¬éƒ½ä¼šæ¥å—
- \_draft_extend_for_decode():
  - è®¡ç®—çš„ `select_index`ï¼Œåªä¿ç•™æœ€åä¸€ä¸ª Token çš„é¢„æµ‹ç»“æœã€‚
  - è®¡ç®—å‡ºçš„ `topk_p`ï¼ˆæ¦‚ç‡ï¼‰ã€`topk_index`ï¼ˆToken IDï¼‰å’Œ hidden_states è¢«å¡«å…¥`next_draft_input`ã€‚è¿™ä¸ªå¯¹è±¡ä¼šè¢«ä¼ é€’ç»™ä¸‹ä¸€ä¸ªå¾ªç¯çš„ `draft()` å‡½æ•°ï¼Œä½œä¸ºç”Ÿæˆæ–°çš„ Token æ ‘çš„**root**(verified_id)

å®é™…ä¸ŠçœŸæ­£çš„ grammar æ›´æ–°çŠ¶æ€åœ¨ scheduler çš„ post process é˜¶æ®µ

```python
# Speculative decode: next_token_id æ˜¯ accepted tokens åˆ—è¡¨
for token_id in next_token_id:
  req.grammar.accept_token(token_id)  â† æ­£å¼æ›´æ–°çŠ¶æ€
```

---

### åŒæ­¥ç‚¹

- Draft Extend N-1 ä¸ä¸‹ä¸€è½®è°ƒåº¦ç”± CPU è°ƒåº¦é€»è¾‘ä¿è¯åŒæ­¥
- Write future map å’Œ Read future map ç”± copy_to_cpu() ä¿è¯åŒæ­¥

  > ä¸Šä¸€è½®çš„ sample è´Ÿè´£ storeï¼Œè¿™ä¸€è½®çš„ run_batch() è¿›è¡Œ get

- Grammar å¸¦æ¥çš„åŒæ­¥
  - æˆ‘ä»¬ä¸ºäº†ç”Ÿæˆ vocab maskï¼Œéœ€è¦ verify inputï¼Œéœ€è¦æ‹·è´ GPU ä¸Šçš„æ•°æ®ï¼Œè¿™é‡Œç”¨çš„ .cpu() å®é™…ä¸Šæ˜¯ä¸€æ¬¡åŒæ­¥
  - Sample() å‰éœ€è¦å°† vocab mask åº”ç”¨åˆ° target verify å¾—åˆ°çš„ logits ä¸Šï¼Œè¿™é‡Œéœ€è¦å°† cpu çš„ vocab mask æ‹·è´åˆ° GPU ä¸Š
    > [!IMPORTANT]
    > **è¿™é‡Œåº”è¯¥ç”¨å¼‚æ­¥æ‹·è´**

- Draft Extend æ›´æ”¹å…ƒæ•°æ®ä¿¡æ¯ä¾èµ–äº verify çš„ accept length å’Œ predict ç»“æœï¼Œæ‰€ä»¥éœ€è¦åŒæ­¥

  > ç”± CPU ä¾§è°ƒåº¦ä¿è¯

![](static/orign_eagle2.png)

---

## ä¼˜åŒ– Overlap: speculative decoding + constrained decoding

### Motivation

æˆ‘ä»¬å®é™…ä¸Šæœ‰å¦‚ä¸‹ä¾èµ–å…³ç³»ï¼š

1. vocab_mask ç”Ÿæˆå¿…é¡»ç­‰å¾… last_batch accept å®Œæˆ
2. vocab_mask ç”Ÿæˆå¿…é¡»ç­‰å¾…å¼‚æ­¥æ‹·è´å®Œæˆ
3. Sample å¿…é¡»ç­‰å¾… vocab_mask åˆ°è¾¾ GPU

ä¹‹å‰çš„åšæ³•æ˜¯åœ¨ Scheduler çš„åå¤„ç†è¿›è¡Œ last_batch çš„ acceptï¼Œæˆ‘ä»¬å®é™…ä¸Šåªéœ€è¦ä¿è¯ vocab mask ç”Ÿæˆå‰ last_batch accept å³å¯ï¼›åŒæ—¶ target verify æ˜¯ GPU ä¸Šè€—æ—¶æ¯”è¾ƒé•¿çš„ä»»åŠ¡ï¼Œæˆ‘ä»¬å¯ä»¥é‡å è¿™ä¸¤ä¸ªæ“ä½œï¼Œè®© GPU overlap CPU ä¸Šçš„è®¡ç®—å¼€é”€

vocab mask çš„ç”Ÿæˆè¿˜ä¾èµ– verify inputï¼Œæˆ‘ä»¬éœ€è¦ä¸€æ¬¡å¼‚æ­¥æ‹·è´(GPU->CPU)

sample éœ€è¦ vocab mask åº”ç”¨åˆ° logits ä¸Šï¼Œä¹Ÿéœ€è¦ä¸€æ¬¡å¼‚æ­¥æ‹·è´(CPU->GPU)

### Overview

ä¼˜åŒ–åçš„è°ƒåº¦é€»è¾‘å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

- æˆ‘ä»¬å°† GPU åˆ° CPU çš„ verify input æ‹·è´ä½¿ç”¨å¼‚æ­¥æ‹·è´

- ä¹‹å‰çš„ constraint decoding + speculative decoding æ˜¯æ²¡æœ‰è¿›è¡Œè°ƒåº¦ä¾§çš„ overlap çš„ï¼›è¿™é‡Œæˆ‘ä»¬åœ¨ GPU è¿›è¡Œ target verify çš„åŒæ—¶ï¼Œå¤„ç† last batch çš„ accept tokens

- Target sample ä¾èµ– cpu ç”Ÿæˆçš„ vocab maskï¼Œè¿™é‡Œä½¿ç”¨ .to(device) è¿›è¡ŒåŒæ­¥

![](static/opt_eagle2.png)

### Implementation

- ScheduleBatch ä¸­ç»´æŠ¤ä¸€ä¸ª (request, accepted_token_ids) çš„ listï¼Œå­˜æ”¾ last batch è¿˜æœªç»è¿‡ grammar å¤„ç†çš„ accept_tokens

- event_loop_overlap ä¸­ current batch ä¸­æºå¸¦ last batch çš„ accept_tokens

  ```python
  last_batch, last_result = self.result_queue[-1]
  # here batch is copied, so has_grammar need also as a param
  if last_batch.has_grammar:
      batch.last_batch_accept_tokens = (last_batch, last_result)
      # Mark that grammar accept will be processed in the next batch's verify
      last_result.grammar_accept_processed = True
  ```

- Verify()
  - GPU åˆ° CPU çš„ verify input çš„æ‹·è´ç”¨å¼‚æ­¥æ‹·è´
  - GPU è¿›è¡Œ Target Verify çš„åŒæ—¶ï¼ŒCPU å¯¹ä¸Šä¸€è½®çš„ grammar accept token è¿›è¡Œå¤„ç†
  - CPU ç­‰å¾… verify input æ‹·è´å®Œæˆåç”Ÿæˆæœ¬è½®çš„ vocab maskï¼Œç„¶ååŒæ­¥åˆ° GPU ä¸Šå‡†å¤‡è¿›è¡Œ Target Sample

### JSON Unit Test Result

| æµ‹è¯•åœºæ™¯                    | No Overlapï¼ˆåŸºå‡†ï¼‰ | Overlapï¼ˆDouble Syncï¼‰ | Overlapï¼ˆOnce Syncï¼‰ | æœ€ä½³ç­–ç•¥    |
| --------------------------- | ------------------ | ---------------------- | -------------------- | ----------- |
| JSON Generateï¼ˆæ ‡å‡†é•¿ç”Ÿæˆï¼‰ | 0.8557s            | 0.7296sï¼ˆ+14.7%ï¼‰      | 0.6687sï¼ˆ+21.8%ï¼‰    | Once Sync   |
| JSON OpenAIï¼ˆçŸ­æ–‡æœ¬ / APIï¼‰ | 0.4455s            | 0.2549sï¼ˆ+42.8%ï¼‰      | 0.3861sï¼ˆ+13.3%ï¼‰    | Double Sync |
| Mix Concurrentï¼ˆæ··åˆå¹¶å‘ï¼‰  | 0.6386s            | 0.5623sï¼ˆ+11.9%ï¼‰      | 0.5468sï¼ˆ+14.4%ï¼‰    | Once Sync   |

```shell
# no overlap
[2025-12-23 13:20:02] Test: test_json_generate | Duration: 0.8557s | Status: PASSED
[2025-12-23 13:20:03] Test: test_json_openai | Duration: 0.4455s | Status: PASSED
[2025-12-23 13:20:04] Test: test_mix_json_and_other | Duration: 0.6386s | Status: PASSED
D

# overlap with double sync mask
[2025-12-23 13:20:47] Test: test_json_generate | Duration: 0.7296s | Status: PASSED
[2025-12-23 13:20:47] Test: test_json_openai | Duration: 0.2549s | Status: PASSED
[2025-12-23 13:20:48] Test: test_mix_json_and_other | Duration: 0.5623s | Status: PASSED

# overlap with once sync mask
[2025-12-23 14:18:26] Test: test_json_generate | Duration: 0.6687s | Status: PASSED
[2025-12-23 14:18:27] Test: test_json_openai | Duration: 0.3861s | Status: PASSED
[2025-12-23 14:18:27] Test: test_mix_json_and_other | Duration: 0.5468s | Status: PASSED
```

### Benchmark Result(bs = 4)

#### Hiding CPU Overhead

- TPOT (Time Per Output Token) ä» **4.07ms é™ä½åˆ°äº† 3.22ms**ï¼Œé™å¹…è¶…è¿‡ 20%ã€‚

#### Accept Length æå‡

- Accept Length ä» **2.59 æå‡åˆ°äº† 2.9**ã€‚
- å¾ˆç¥å¥‡ï¼Œæ­£å¸¸ä¸åº”è¯¥æœ‰ accept length å¢é•¿è¿™ä¹ˆå¤šçš„æƒ…å†µï¼Œå› ä¸ºä½¿ç”¨ç›¸åŒçš„æ¨¡å‹

#### é¦–å­—å»¶è¿Ÿ (TTFT) å¾®å¢

- TTFT ä» **21ms å¢åŠ åˆ°äº† 27ms**ã€‚
- Overlap æµæ°´çº¿é€šå¸¸éœ€è¦æ›´å¤æ‚çš„åˆå§‹åŒ–è¿‡ç¨‹ï¼ˆä¾‹å¦‚é¢„åˆ†é…æ›´å¤æ‚çš„ Cuda Eventã€å»ºç«‹ Pending Info ç»“æ„ã€é¢„çƒ­æµæ°´çº¿çŠ¶æ€ï¼‰ã€‚
- ç¬¬ä¸€è½® Draft/Verify å¾€å¾€æ— æ³•äº«å—åˆ° overlap çš„çº¢åˆ©ï¼ˆå› ä¸ºæ²¡æœ‰ä¸Šä¸€è½®ï¼‰ï¼Œåè€Œæ‰¿æ‹…äº†é¢å¤–çš„è°ƒåº¦é€»è¾‘å¼€é”€ã€‚

### GSM8K Just Eagle2 Test

```yaml
# No overlap
python3 benchmark/gsm8k/bench_sglang.py --num-shots 8 --num-questions 1319 --parallel 1319
Accuracy: 0.232
Invalid: 0.003
Latency: 44.037 s
Output throughput: 3763.649 token/s

# Overlap
python3 benchmark/gsm8k/bench_sglang.py --num-shots 8 --num-questions 1319 --parallel 1319
Accuracy: 0.230
Invalid: 0.003
Latency: 36.554 s
Output throughput: 4559.657 token/s
```

## **Reference**

[1]. [Clover: Regressive Lightweight Speculative Decoding with Sequential Knowledge](https://arxiv.org/pdf/2405.00263)

[2]. [Fast Inference from Transformers via Speculative Decoding](https://arxiv.org/abs/2211.17192)

[3]. [Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy](https://arxiv.org/pdf/2312.12728)

[4]. [Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads](https://arxiv.org/abs/2401.10774)

[5]. [EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty](https://arxiv.org/abs/2401.15077)

[6]. [EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees](https://arxiv.org/abs/2406.16858)

[7]. [EAGLE-3: Scaling up Inference Acceleration of Large Language Models via Training-Time Test](https://arxiv.org/abs/2503.01840)

[8]. [Speculative Decoding Slides](https://docs.google.com/presentation/d/1iD0ud3Otd1VbB4Q-G7_UQDFgRfVrIEQr3XDyKkcy-xc/edit?slide=id.p#slide=id.p)
