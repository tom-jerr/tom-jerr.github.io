- 进行了 vllm 和 sglang scheduler 的分析
	- vllm 不再区分Req 的 prefill 和 decode 阶段，只是保存需要生成的 token 数；**batcdh 中混合 prefill 和 decode，通过后端来进行区分处理**
	- sglang 仍然区分 prefill 和 decode 阶段，prefill 请求优先调度，一个 batch 中**只有 prefill 或者 decode**
- 查看了下 sglang 的 pr，发现 speculative coding 现在很热门，接下来我的主要方向是向这个领域尽可能针对 Issue 合入 PR
- 晚上回来和师兄和同门聊到 llm inference 的相关基础知识，CUDA 和 GPU 硬件的对应还是不清晰，需要继续学习
- nvidia 市值突破 5 万亿，工作后一定买它的股票