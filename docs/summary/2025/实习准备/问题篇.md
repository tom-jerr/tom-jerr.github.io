
### Pytorch Pin Memory 原理

**只有一步 (DMA 拷贝):** 当你需要把数据传给 GPU 时，因为数据已经在锁页内存中了，物理地址固定。GPU 可以直接通过 DMA 从这块内存读取数据到显存。
    
> **优点：**
> 
> 1. **省去了一次 CPU 拷贝**。
>     
> 2. **异步操作：** 因为 DMA 独立于 CPU 工作，CPU 发出“传输指令”后就可以立马去干别的事（比如准备下一个 Batch 的数据），实现了 CPU 和 GPU 的并行流水线。
>

**未开启 Pin Memory:**

```
[用户数据 (Pageable)]  -->  (CPU 复制)  -->  [临时缓冲区 (Pinned)]  -->  (DMA 复制)  -->  [GPU 显存]
```

**开启 Pin Memory:**

```
[用户数据 (Pinned)]  --------------------->  (DMA 复制)  -------------------------->  [GPU 显存]
```
### SGLang 和 VLLM 的哪些地方有差别


### SGLang 和 VLLM 的调度哪个比较好



## 量化

### Weight only int4量化和fp8量化，你觉得二者有什么应用上的区别


### 为什么只量化weight，不量化activation


### 动态量化和静态量化的区别？


## Kernel

### 什么是bank conflict，为什么会产生 bank conflict，有哪些解决方法？cutlass 中如何做的？

### 为什么 gemm 解决 bank conflict 使用转置存储？不使用有什么影响？

### 为什么 shared memory 可以优化 gemm，什么情况下需要使用__syncthreads进行同步?


### flash attention 的理解，hopper 架构新特性？


### 怎么定位性能热点，对于cuda kernel有哪些优化手段


### 对c++ template的理解


## 模型推理

### llm推理为什么需要 kvcache，怎么计算kvcache大小，如何管理kvcache？

### stable diffusion 有哪些加速策略，和llm serving有什么区别


### 怎么理解延迟与吞吐，在具体业务场景下怎么选择


### 主流的moe模型推理时通讯过程存在的问题以及解决办法?


I found that some errors appeared when performing tests on baseline code, used `FastVideo/FastWan2.1-T2V-1.3B-Diffusers` Model. 
```shell
sglang generate --model-path=FastVideo/FastWan2.1-T2V-1.3B-Diffusers
  --prompt='a beautiful scene' \
  --width=720 --height=720 \
  --save-output \
  --profile \
```
It is caused by `DmdDenoisingStage`. Two problems have been identified so far: 

1. **weight load in `ComponentLoader`**

```shell
Traceback (most recent call last):
  File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/sgl-workspace/sglang/python/sglang/multimodal_gen/runtime/managers/gpu_worker.py", line 177, in run_scheduler_process
    scheduler = Scheduler(
                ^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/multimodal_gen/runtime/managers/scheduler.py", line 59, in __init__
    worker = GPUWorker(
             ^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/multimodal_gen/runtime/managers/gpu_worker.py", line 59, in __init__
    self.init_device_and_model()
  File "/sgl-workspace/sglang/python/sglang/multimodal_gen/runtime/managers/gpu_worker.py", line 88, in init_device_and_model
    self.pipeline = build_pipeline(self.server_args)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/multimodal_gen/runtime/pipelines_core/__init__.py", line 50, in build_pipeline
    pipeline = pipeline_cls(model_path, server_args)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/multimodal_gen/runtime/pipelines_core/lora_pipeline.py", line 61, in __init__
    super().__init__(*args, **kwargs)
  File "/sgl-workspace/sglang/python/sglang/multimodal_gen/runtime/pipelines_core/composed_pipeline_base.py", line 95, in __init__
    self.modules = self.load_modules(server_args, loaded_modules)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/multimodal_gen/runtime/pipelines_core/composed_pipeline_base.py", line 319, in load_modules
    module = PipelineComponentLoader.load_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/multimodal_gen/runtime/loader/component_loader.py", line 774, in load_module
    raise e
  File "/sgl-workspace/sglang/python/sglang/multimodal_gen/runtime/loader/component_loader.py", line 764, in load_module
    return loader.load(
           ^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/multimodal_gen/runtime/loader/component_loader.py", line 161, in load
    should_offload = self.should_offload(server_args)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/multimodal_gen/runtime/loader/component_loader.py", line 123, in should_offload
    raise NotImplementedError()
NotImplementedError
```

2. After I solved this problem by simply adjusting the parameters, the next problem arose.: **parameters in WanTransformer3DModel.forward()**
```shell
[12-07 09:01:11] [denoising_step_0] Error during execution after 0.8526 ms: WanTransformer3DModel.forward() got an unexpected keyword argument 'guidance'
Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/multimodal_gen/runtime/pipelines_core/stages/denoising_dmd.py", line 145, in forward
    pred_noise = self.transformer(
                 ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: WanTransformer3DModel.forward() got an unexpected keyword argument 'guidance'
```


## Project

### MiniInfer

#### 为什么 kv cache 预先分配？

- 减少 OOM 可能，在初始化阶段就暴露问题，保证推理服务稳定性
	- 一次性把 GPU 上剩余的显存全部，划分成无数个固定大小的块（Blocks），用于存放 KV Cache。
- 减少内存碎片，可以不用分配连续显存，类似操作系统页表
- 减少 CPU 开销，所有分配在模型加载后一次性调用，后续避免调用昂贵的 `CudaMalloc()`

#### 为什么用 `(2, hf_config.num_hidden_layers, config.num_kvcache_blocks, self.block_size, num_kv_heads, head_dim)` 这种方式来进行分配？
- 使用 `torch.empty()` 速度极快，因为它不初始化（不清零）内存，只是在显存上划了个地盘。这块内存里原本的垃圾数据还在，之后写入 KV 时会覆盖它。
- 读取某个 Token 的 KV 时，它的所有 Head 数据在内存中是连续的

#### pytorch 的 Pin Memory 和 异步传输？
- **`pin_memory=True` (锁页内存):**
    - 操作系统通常会对内存进行分页和交换（Swap）。如果内存是“可分页”的，CPU 在拷贝数据给 GPU 之前，必须先把它复制到一个临时的“锁页”缓冲区。
    - 设置 `pin_memory=True` 直接在 CPU 上申请锁页内存。这样 GPU 的 DMA（直接内存访问）控制器可以直接读取这块内存，**省去了一次 CPU 内部的拷贝**，大幅提升传输带宽。

- **`non_blocking=True` (异步传输):**
    - 默认情况下，`.cuda()` 是同步的，CPU 会卡住等待数据完全传到显存。
    - 设置 `non_blocking=True` 后，CPU 发出传输指令后**立即返回**，继续执行下一行 Python 代码（比如准备下一个 Batch 的数据），而不需要傻等数据传输完成。这实现了 **CPU 计算与 GPU 数据传输的流水线重叠（Overlap）**。
- CUDA Stream 上的任务是严格顺序的
	- 虽然 CPU 发出了 `model(input_tensor)` 指令，但这个计算指令会被放入**同一个 Stream 队列**。 GPU 会严格遵守队列顺序：**必须等前面的“搬运指令”执行完，才会执行后面的“计算指令”。**
	- **所以，数据绝对是安全的**