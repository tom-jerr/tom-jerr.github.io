---
title: å¤§æ¨¡å‹æ¨ç†æœåŠ¡ä¸­çš„ Batching
tags:
  - LLMInference
created: 2025-11-20
include:
  - ai-summary
ai-summary-config:
  api: "tongyi"
  model: "qwen-turbo"
  prompt: "å¸®æˆ‘æŠŠä¸‹é¢çš„å†…å®¹æ€»ç»“ä¸º500å­—ä»¥å†…çš„æ‘˜è¦ï¼š"
---

# å¤§æ¨¡å‹æ¨ç†æœåŠ¡ä¸­çš„ Batching

ç°åœ¨çš„å¤§æ¨¡å‹æ¨ç†çš„æ¡†æ¶åŸºæœ¬éƒ½å®ç°äº† **Continuous Batching**ï¼Œæœ¬æ–‡å°†ä»å¤§æ¨¡å‹æ¨ç†æœåŠ¡ä¸ºä»€ä¹ˆéœ€è¦ Batching å¼€å§‹ï¼Œé€æ­¥è®²è§£è¯¥é¢†åŸŸçš„æŠ€æœ¯æ¼”è¿›ã€‚

> [!WARNING]
> è¿™é‡Œå¤§æ¨¡å‹ç‰¹æŒ‡**è‡ªå›å½’ç±»å¤§æ¨¡å‹(GPT ç±»)**

## Two Phase in LLM Inference

LLM æ¨ç†ç”±ä¸¤ä¸ªé˜¶æ®µç»„æˆ Prefill é˜¶æ®µå’Œ Decode é˜¶æ®µ

- **é˜¶æ®µ 1ï¼šé¢„å¡«å…… (Prefill) - è®¡ç®—å¯†é›†å‹**ï¼šåœ¨é¢„å¡«å……é˜¶æ®µï¼Œæ¨¡å‹å¹¶è¡Œå¤„ç†è¾“å…¥æç¤ºä¸­çš„**æ‰€æœ‰ Â Tokenï¼Œä»¥è®¡ç®—ç”Ÿæˆç¬¬ä¸€ä¸ªè¾“å‡º Token æ‰€éœ€çš„é”®å€¼ç¼“å­˜ (KV Cache)**Â ã€‚
- **é˜¶æ®µ 2ï¼šè§£ç  (Decode) - è®¿å­˜å¯†é›†å‹**ï¼šåœ¨è§£ç é˜¶æ®µï¼Œæ¨¡å‹ä»¥è‡ªå›å½’ (Autoregressive) çš„æ–¹å¼\_**é€ä¸ªç”Ÿæˆ Token**Â ã€‚GPU éœ€è¦ä¸ºç”Ÿæˆçš„æ¯ä¸€ä¸ª TokenÂ  ä»é«˜å¸¦å®½å†…å­˜ (HBM, å³ GPU æ˜¾å­˜) ä¸­é‡å¤**è¯»å–å®Œæ•´çš„æ¨¡å‹æƒé‡å’Œå·²ç´¯ç§¯çš„ã€è§„æ¨¡åºå¤§çš„ KV Cache**Â ã€‚

## Why Batching?

å¯¹äº Prefill æ¥è¯´ï¼Œå¯¹æ‰€æœ‰ token è¿›è¡Œ Attention å’Œ MLP æ“ä½œï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§çŸ©é˜µä¹˜æ³•ï¼ˆ`[batch_size x hidden_dim] @ [hidden_dim x hidden_dim]`ï¼‰ï¼Œå¯ä»¥å……åˆ†åˆ©ç”¨ GPU çš„è®¡ç®—èµ„æº

è€Œ Decode é˜¶æ®µï¼Œä¸€ä¸ª request ä¸€æ¬¡åªä¼šæ ¹æ®ä¸Šä¸€ä¸ª token ç”Ÿæˆä¸‹ä¸€ä¸ª tokenï¼Œç›¸å½“äºåšä¸€ä¸ª **batch size = 1** çš„çŸ©é˜µä¹˜æ³•ï¼ˆ`[1 x hidden_dim] @ [hidden_dim x hidden_dim]`ï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ªæå°çš„çŸ©é˜µä¹˜æ³•â€”â€”**GPU æ— æ³•è¢«æœ‰æ•ˆåˆ©ç”¨**

**Batching** æŠŠå¤šä¸ªç”¨æˆ·è¯·æ±‚åœ¨åŒä¸€æ—¶é—´ â€œæ‰“åŒ…â€ åˆ°ä¸€èµ·ï¼Œ**è®© GPU ä¸€æ¬¡è®¡ç®—å¤šä¸ªåºåˆ—çš„ forward**ã€‚
è¿™æ ·çŸ©é˜µä¹˜æ³•ä» `[1 x hidden_dim] @ [hidden_dim x hidden_dim]` å˜æˆ `[batch_size x hidden_dim] @ [hidden_dim x hidden_dim]` è¿™æ—¶ batch_size å¯ä»¥æ˜¯å‡ åç”šè‡³ä¸Šç™¾ï¼Œä»è€Œæ˜¾è‘—æé«˜ GPU åˆ©ç”¨ç‡ã€‚

## Batching Problems

é™¤äº†**æå‡æ¨ç†æœåŠ¡çš„ååé‡ï¼Œé™ä½ TTFTï¼ŒTBT å»¶è¿Ÿ**ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸ºä¸‹é¢è¿™ä¸‰ç§ batching é—®é¢˜æä¾›é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼š

1. **ä¸¤ä¸ªè¯·æ±‚éƒ½å¤„äº Prefill é˜¶æ®µ**ï¼Œä½†å„è‡ªçš„è¾“å…¥ token æ•°é‡ä¸åŒã€‚

2. **ä¸¤ä¸ªè¯·æ±‚éƒ½å¤„äº Decode é˜¶æ®µ**ï¼Œä½†å½“å‰å¤„ç†çš„ token ç´¢å¼•ï¼ˆindexï¼‰ä¸åŒã€‚

3. **ä¸¤ä¸ªè¯·æ±‚åˆ†å±ä¸åŒé˜¶æ®µ**â€”â€”ä¸€ä¸ªåœ¨ Prefill é˜¶æ®µï¼Œå¦ä¸€ä¸ªåœ¨ Decode é˜¶æ®µã€‚

å®é™…ä¸Šï¼Œè¿™ä¸‰ä¸ªé—®é¢˜çš„äº§ç”Ÿä¸è®¡ç®—å±‚çš„ kernel æ¯æ¯ç›¸å…³ï¼Œæ‰€ä»¥æˆ‘ä»¬é™¤äº†éœ€è¦è€ƒè™‘è°ƒåº¦å±‚çš„ä¼˜åŒ–ï¼Œä¹Ÿéœ€è¦å¯¹ kernel è¿›è¡Œæ”¹è¿›ï¼Œä» **padding åˆ° prepacking**ï¼Œå‡å°è®¡ç®—èµ„æºçš„æµªè´¹ã€‚

## Batching Technology Evolution

æœ¬èŠ‚å°†ç³»ç»Ÿæ¢³ç†å¤§æ¨¡å‹æ¨ç†æœåŠ¡ä¸­ **Batching æŠ€æœ¯çš„æ¼”è¿›è·¯å¾„**ï¼Œé˜è¿°å…¶å¦‚ä½•ä»æ—©æœŸçš„é™æ€æ‰¹å¤„ç†é€æ­¥å‘å±•åˆ°è¿ç»­æ‰¹å¤„ç† + chunked prefillã€‚æœ¬èŠ‚ä¸»è¦å…³äºè°ƒåº¦å±‚çš„ä¼˜åŒ–ï¼Œè®¡ç®—å±‚çš„ä¼˜åŒ–ç•¥æœ‰æ¶‰åŠã€‚

### Overview

æœ€å¼€å§‹å¤§æ¨¡å‹æ¨ç†æœåŠ¡æ˜¯é€šè¿‡**é™æ€æ‰¹å¤„ç†**å¤„ç†å¤šä¸ªè¯·æ±‚ï¼Œä½†æ˜¯è¿™å¸¦æ¥äº†**è®¡ç®—æµªè´¹å’Œå¤§é‡ç©ºé—² GPU cycles** ç­‰é—®é¢˜ã€‚é™æ€æ‰¹å¤„ç†å¯ä»¥è®¤ä¸ºæ˜¯ **request-level** çš„è°ƒåº¦ï¼Œåç»­æå‡ºäº†**token-level** çš„è¿ç»­æ‰¹å¤„ç†ï¼Œå…è®¸è¯·æ±‚æå‰é€€å‡ºå’Œç«‹å³å¼€å§‹æ¨ç†ã€‚

ä½†æ˜¯çœŸæ­£é«˜æ•ˆè§£å†³äº† Batching Problems æ˜¯å¤šç§æŠ€æœ¯çš„èåˆï¼š

- **ORCA** æå‡ºäº† `iteration-level scheduling`ï¼Œå…è®¸è¯·æ±‚æå‰é€€å‡ºå’Œç«‹å³è¿›å…¥ã€‚

- **Page Attention** è§£å†³äº†é—®é¢˜ 2ï¼Œé€šè¿‡å®šåˆ¶åŒ–çš„ kernel å®ç°äº†å¯¹å˜é•¿ kv cache çš„ attention è®¡ç®—ã€‚è€Œé—®é¢˜ 1 ç”±å…¶ä»–ç¬¬ä¸‰æ–¹åº“çš„ kernel è§£å†³ã€‚

- **Chunked Prefill** åˆ©ç”¨ FlashInfer æä¾›çš„ Kernelï¼Œè§£å†³äº†ä¸‰ä¸ª Batching é—®é¢˜ã€‚åŒæ—¶å°† prefill åˆ†å—ä¸ decode å…±åŒç»„æˆä¸€ä¸ª batchï¼Œå¯ä»¥**ä¿è¯åœ¨ TBT æœåŠ¡è´¨é‡åŒæ—¶å¢åŠ  decode é˜¶æ®µçš„ç®—æœ¯å¯†é›†ç¨‹åº¦**ã€‚

### Static Batching(é™æ€æ‰¹å¤„ç†)

**é™æ€æ‰¹å¤„ç†ï¼ˆStatic Batchingï¼‰**ï¼šåœ¨æ¨ç†å¼€å§‹ä¹‹å‰ï¼Œ**å›ºå®šä¸€ç»„è¯·æ±‚ï¼ˆå›ºå®š batch sizeï¼‰**ï¼Œå°†ä¸€ç»„ $N$ ä¸ªå…·æœ‰ä¸åŒé•¿åº¦ $L_1, L_2, \dots, L_N$ çš„è¾“å…¥è¯·æ±‚ï¼ˆpromptsï¼‰å¼ºè¡Œè½¬æ¢ä¸ºä¸€ä¸ªå¯†é›†çš„ã€çŸ©å½¢çš„å¼ é‡ã€‚è¯¥æ“ä½œé€šè¿‡å°†**æ‰€æœ‰åºåˆ—å¡«å…… (Padding) åˆ°æ‰¹æ¬¡ä¸­â€œæœ€é•¿åºåˆ—çš„é•¿åº¦â€ $L_{max}$ æ¥å®ç°ï¼Œæœ€ç»ˆå½¢æˆä¸€ä¸ªå½¢çŠ¶ä¸º $[N, L_{max}]$ çš„å¼ é‡**ã€‚

> [!NOTE]
> æ ‡å‡†çš„ MatMul Kernel **æ— æ³•ç›´æ¥æ“ä½œ â€œä¸è§„åˆ™â€ (ragged) æˆ–å¯å˜é•¿åº¦çš„åºåˆ—**ã€‚å› æ­¤ï¼Œå¡«å……æˆä¸ºäº†ä¸€ç§å¿…éœ€çš„â€œé¢„å¤„ç†â€æ­¥éª¤ï¼Œä»¥ä¾¿å°†å¤šä¸ªç‹¬ç«‹è¯·æ±‚ flatten ä¸º GPU å¯ä»¥ä¸€æ¬¡æ€§å¤„ç†çš„å•ä¸€ã€å¤§å‹è®¡ç®—ä»»åŠ¡ã€‚

#### Problems

è¿™ç§å¤„ç†æ–¹å¼æ¥è§£å†³ä¸Šé¢çš„ batching Problems å¸¦æ¥äº†ä¸€ç³»åˆ—çš„é—®é¢˜ï¼š

- **é—®é¢˜ 1ï¼šè®¡ç®—æµªè´¹ (Compute Waste)**
  - GPU å·²ç»ä¸ºè®¡ç®—æ•´ä¸ª $[N, L_{max}, L_{max}]$ çŸ©é˜µï¼ˆåŒ…æ‹¬æ‰€æœ‰ padding Token å¯¹ï¼‰æ¶ˆè€—äº†å¤§é‡çš„ FLOPsã€‚
- **é—®é¢˜ 2ï¼šæ˜¾å­˜æµªè´¹ (VRAM Waste)**
  - é«˜æ˜¾å­˜å ç”¨ä¸»è¦å½’å’äº KV Cacheã€‚KV Cache çš„å¤§å°ä¸åºåˆ—é•¿åº¦å’Œæ‰¹æ¬¡å¤§å°æˆçº¿æ€§å…³ç³»$Size = b \times t \times n\_layers \times n\_heads \times d\_head \times p\_a$ï¼Œå…¶ä¸­ $b$ æ˜¯æ‰¹æ¬¡å¤§å°ï¼Œ$t$ æ˜¯åºåˆ—æ€»é•¿åº¦ã€‚
  - åœ¨é™æ€æ‰¹å¤„ç†ä¸­ï¼Œç³»ç»Ÿå¿…é¡»ä¸ºæ‰¹æ¬¡ä¸­çš„**æ¯ä¸€ä¸ªåºåˆ—**ï¼Œé¢„å…ˆåˆ†é…ä¸€ä¸ªè¶³ä»¥**å®¹çº³å®Œæ•´å¡«å……é•¿åº¦ $L_{max}$ çš„ KV Cache ç¼“å†²åŒº** ã€‚
- **é—®é¢˜ 3ï¼šç©ºé—²çš„ GPU cycles**

  - è¯·æ±‚åœ¨ä¸åŒçš„è¿­ä»£ä¸­ç»“æŸï¼Œä¸èƒ½æå‰é€€å‡ºã€‚åªæœ‰æ•´ä¸ª batch ä¸­æœ€é•¿è¯·æ±‚çš„ç»“æŸï¼Œæ•´ä¸ª batch æ‰€æœ‰è¯·æ±‚æ‰èƒ½é€€å‡º
  - æ–°çš„è¯·æ±‚ä¹Ÿä¸èƒ½ç«‹åˆ»è¿›è¡Œæ¨ç†ï¼Œå¿…é¡»ç­‰å¾…æ•´ä¸ª batch æ¨ç†ç»“æŸ

  ![](img/static_batching.png)

### Continuous Batching

`ORCAï¼šA Distributed Serving System for Transformer-Based Generative Models` é¦–å…ˆæå‡ºäº† `iteration-level scheduling` çš„è°ƒåº¦ç­–ç•¥ï¼Œå®é™…ä¸Šå°±æ˜¯ `token-levle scheduling`ã€‚ç”±äº**ä¸ä½¿ç”¨ padding**ä»¥åŠè®¡ç®—å±‚ kernel æœ¬èº«çš„é™åˆ¶ï¼Œæå‡ºäº† `selective batching` ç­–ç•¥ï¼Œåªå¯¹ **non-attention** æ“ä½œè¿›è¡Œ batching

#### Motivation

- æˆ‘ä»¬ä¸å¸Œæœ›æµªè´¹è®¡ç®—èµ„æºï¼Œè¿™é‡Œ**ä¸ç”¨ padding**ï¼Œå› ä¸º padding å¯¹è®¡ç®—èµ„æºæ˜¯æå¤§çš„æµªè´¹
- æˆ‘ä»¬å¸Œæœ›å°½å¯èƒ½å‡å° **TTFT å’Œ TBT**ï¼Œæ‰€ä»¥æå‰å®Œæˆçš„è¯·æ±‚è¦**ç«‹å³é€€å‡ºæ¨ç†**ä»¥åŠåæ¥çš„è¯·æ±‚è¦**ç«‹å³å¼€å§‹æ¨ç†**
- æˆ‘ä»¬å¸Œæœ› Batching ä»»æ„ä¸€ç»„å¤§å°ä¸åŒçš„è¯·æ±‚ï¼Œä½†æ˜¯å­˜åœ¨ä¸‰ç§æƒ…å½¢ä½¿å¾—ä¸€å¯¹è¯·æ±‚æ— æ³•åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­å…±åŒæ‰¹å¤„ç†ï¼ˆlength ä¸åŒï¼ŒKV Cache é•¿åº¦ä¸åŒï¼‰ï¼š

  1.  **ä¸¤ä¸ªè¯·æ±‚éƒ½å¤„äºå¯åŠ¨é˜¶æ®µï¼ˆinitiation phaseï¼‰**ï¼Œä½†å„è‡ªçš„è¾“å…¥ token æ•°é‡ä¸åŒã€‚
  2.  **ä¸¤ä¸ªè¯·æ±‚éƒ½å¤„äºå¢é‡é˜¶æ®µï¼ˆincrement phaseï¼‰**ï¼Œä½†å½“å‰å¤„ç†çš„ token ç´¢å¼•ï¼ˆindexï¼‰ä¸åŒã€‚
  3.  **ä¸¤ä¸ªè¯·æ±‚åˆ†å±ä¸åŒé˜¶æ®µ**â€”â€”ä¸€ä¸ªåœ¨å¯åŠ¨é˜¶æ®µï¼Œå¦ä¸€ä¸ªåœ¨å¢é‡é˜¶æ®µã€‚

#### Design

##### è¿­ä»£çº§è°ƒåº¦ï¼ˆIteration-level schedulingï¼‰

ORCA çš„è°ƒåº¦å™¨å¯ä»¥åœ¨**æ¯ä¸€æ¬¡è¿­ä»£ååŠ¨æ€æ”¹å˜è¦å¤„ç†çš„è¯·æ±‚é›†åˆ**ï¼š

- è°ƒåº¦å™¨åœ¨æ¯æ¬¡è¿­ä»£ç»“æŸåéƒ½ä¼šæ”¶åˆ°è¿”å›ç»“æœï¼Œå› æ­¤å®ƒèƒ½å¤Ÿ**æ£€æµ‹åˆ°è¯·æ±‚æ˜¯å¦å·²å®Œæˆ**ï¼Œå¹¶å¯ä»¥**ç«‹å³å°†ç”Ÿæˆçš„ tokens è¿”å›ç»™å®¢æˆ·ç«¯**ã€‚
- å¯¹äºä¸€ä¸ªæ–°åˆ°è¾¾çš„è¯·æ±‚ï¼Œè¯¥è¯·æ±‚å¯ä»¥åœ¨å½“å‰è¿­ä»£æ‰§è¡Œå®Œä¹‹å**ç«‹åˆ»è·å¾—è°ƒåº¦æœºä¼š**ï¼ˆå³è°ƒåº¦å™¨å¯åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£é€‰æ‹©å®ƒè¿è¡Œï¼‰ï¼Œä»è€Œæ˜¾è‘—**å‡å°‘æ’é˜Ÿç­‰å¾…å»¶è¿Ÿ**ã€‚

![](img/orca1.png)

##### é€‰æ‹©æ€§æ‰¹å¤„ç†ï¼ˆSelective Batchingï¼‰

ç”±äº GPU è¦æ±‚è¾“å…¥éœ€è¦ shape å®Œå…¨å¯¹é½ï¼Œæ‰€ä»¥å³ä½¿é‡‡ç”¨ `iteration-level scheduling`ï¼Œä»ç„¶ä¸èƒ½å¯¹ Attention å®ç° batcingã€‚

> [!WARNING]
> `torch.bmm` åŠå…¶ä»£è¡¨çš„æ ‡å‡†è®¡ç®—èŒƒå¼ï¼Œ**åœ¨è®¾è®¡ä¸Šè¦æ±‚æ‰€æœ‰æ•°æ®åœ¨å†…å­˜ä¸­æ˜¯è¿ç»­ä¸”ç»Ÿä¸€çš„ï¼ˆcontiguous and denseï¼‰**ã€‚å®ƒå‡è®¾æ‰¹æ¬¡ä¸­çš„æ‰€æœ‰ K/V ç¼“å­˜å¯ä»¥è¢«ç»„ç»‡æˆä¸€ä¸ªå•ä¸€çš„ã€å·¨å¤§çš„ã€å½¢çŠ¶è§„æ•´çš„å¼ é‡

æ‰€ä»¥è¿™é‡Œåªå¯¹**éƒ¨åˆ†æ“ä½œ**è¿›è¡Œæ‰¹å¤„ç†ï¼ŒğŸ’€ å®é™…ä¸Šè¿™æ˜¯å¯¹è®¡ç®—å±‚çš„å¦¥åï¼š

- **Attention æ“ä½œä¸èƒ½å¤„ç†è¿™ç§ä¸è§„åˆ™å½¢çŠ¶ tensor**ï¼Œå®ƒå¿…é¡»çŸ¥é“æ¯ä¸ª token å±äºå“ªä¸ªè¯·æ±‚ï¼Œä»¥ç¡®ä¿æ³¨æ„åŠ›ä»…åœ¨åŒä¸€è¯·æ±‚çš„ tokens ä¹‹é—´è®¡ç®—
- **éæ³¨æ„åŠ›ç±»ï¼ˆnon-Attentionï¼‰çš„çŸ©é˜µä¹˜æ³•ï¼ˆLinearï¼‰ã€å±‚å½’ä¸€åŒ–ï¼ˆLayerNormï¼‰ç­‰æ“ä½œå¯ä»¥ç›´æ¥ flatten æ¥å¤„ç†**ï¼Œå› ä¸ºè¿™äº›æ“ä½œ**ä¸éœ€è¦åŒºåˆ† token å±äºå“ªä¸ªè¯·æ±‚**

Selective Batching æœºåˆ¶èƒ½å¤Ÿæ ¹æ®ä¸åŒæ“ä½œçš„ç‰¹æ€§åšå‡ºåŒºåˆ†ï¼š

- å¯¹äº **Attention** æ“ä½œï¼Œæ‹†åˆ†æ‰¹æ¬¡ï¼Œåœ¨æ¯ä¸ªè¯·æ±‚ä¸Š**å•ç‹¬æ‰§è¡Œ**ï¼›
- å¯¹äºå…¶ä»– **é Attention æ“ä½œ**ï¼Œä¸ä»¥è¯·æ±‚ä¸ºå•ä½ï¼Œè€Œä»¥ token ä¸ºå•ä½è¿›è¡Œæ‰¹å¤„ç†ã€‚

![](img/orca2.png)

#### Problems

åœ¨ **Orca (OSDIâ€™22)** ä¸­ï¼Œå¾®è½¯æå‡ºäº†â€œ**è¿­ä»£çº§è°ƒåº¦ï¼ˆiteration-level schedulingï¼‰**â€ï¼Œè®©æ¨ç†ç³»ç»Ÿèƒ½åŠ¨æ€æ¥å…¥å’Œé‡Šæ”¾è¯·æ±‚ï¼Œä»è€Œæ‰“ç ´äº†ä¼ ç»Ÿâ€œé™æ€æ‰¹å¤„ç†â€çš„å›ºå®šæ‰¹æ¬¡ã€‚ä½†ä»ç„¶æœ‰ä¸¤ä¸ªé—®é¢˜äºŸéœ€è§£å†³ï¼š

- **ä»ç„¶æ— æ³•å°†ä¸åŒé˜¶æ®µã€ä¸åŒé•¿åº¦çš„è¯·æ±‚æ‰¹åœ¨ä¸€èµ·æ‰§è¡Œã€‚**
  - Orca ç”¨ **Selective Batching** å±€éƒ¨è§£å†³è¿™ä¸€é—®é¢˜ â€”â€” è®©é-Attention å±‚ï¼ˆå¦‚ Linearã€LayerNormï¼‰è·¨è¯·æ±‚æ··åˆæ‰§è¡Œï¼Œä½† Attention ä»éœ€â€œæŒ‰è¯·æ±‚æ‹†å¼€â€è¿è¡Œã€‚
  - ğŸ’€ æœ¬è´¨ä¸Šï¼Œ**å®ƒä»å—é™äºã€ŒåŒå½¢å¼ é‡ã€çš„è¦æ±‚**ï¼ŒBatch å¹¶éçœŸæ­£è¿ç»­æˆ–æ— ç¼ã€‚
- **å†…å­˜ç¢ç‰‡ï¼š** ä¼ ç»Ÿçš„å†…å­˜åˆ†é…å™¨ï¼ˆå¦‚ PyTorch ä¸­çš„ï¼‰è¦æ±‚ä¸º KV Cache åˆ†é…è¿ç»­çš„(contiguous) VRAM å—(**å¤–éƒ¨ç¢ç‰‡**)ï¼Œå¹¶ä¸”ä¼šåˆ†é…æ¯” req æ›´é•¿çš„å†…å­˜ä½œä¸ºé¢„ç•™ç©ºé—´(**å†…éƒ¨ç¢ç‰‡**)

---

### Page Attention

`Efficient Memory Management for Large Language  Model Serving with PagedAttention` å€Ÿé‰´æ“ä½œç³»ç»Ÿçš„è™šæ‹Ÿå†…å­˜å’Œåˆ†é¡µï¼Œå°† KV Cache åˆ†æˆä¸åŒçš„ physical blockï¼›ç³»ç»Ÿä¸ºæ¯ä¸ª request ç»´æŠ¤ä¸€ä¸ª block table æ˜ å°„é€»è¾‘ token ä½ç½®åˆ°å®é™…æ˜¾å­˜çš„ç‰©ç†å—ä½ç½®ï¼›é€šè¿‡é«˜åº¦å®šåˆ¶åŒ–çš„ PageAttention kernel è§£å†³äº†**ä¸åŒ token index çš„ decoding request æ‰¹å¤„ç†é—®é¢˜**

#### Movtivation

ä¸ºäº†èƒ½å¤Ÿå°†è¯·æ±‚ Â `i`Â  ä¸å…¶ä»–è¯·æ±‚æ‰¹å¤„ç†ï¼Œç³»ç»Ÿå¿…é¡»æå‰ä¸ºè¯·æ±‚ Â `i`Â  åˆ†é…ä¸€å—è¿ç»­çš„å†…å­˜ç©ºé—´ï¼Œè¿™å—ç©ºé—´å¿…é¡»å¤§åˆ°è¶³ä»¥å®¹çº³å…¶**å¯èƒ½ç”Ÿæˆçš„æœ€å¤§åºåˆ—é•¿åº¦**ï¼ˆä¾‹å¦‚ 2048 æˆ– 4096 tokensï¼‰ã€‚è¿™ç§ç­–ç•¥å¯¼è‡´äº†ç¾éš¾æ€§çš„å†…å­˜ç¢ç‰‡ï¼š

1. **å†…éƒ¨ç¢ç‰‡ï¼ˆInternal Fragmentationï¼‰ï¼š**Â  ä¸€ä¸ªç”¨æˆ·åªè¾“å…¥äº† 10 ä¸ª tokenï¼Œç”Ÿæˆäº† 190 ä¸ª tokenï¼ˆæ€»å…± 200 tokensï¼‰å°±ç»“æŸäº†ã€‚ä½†ç³»ç»Ÿä¸ºä»–é¢„ç•™äº† 2048 tokens çš„ç©ºé—´ã€‚è¿™å¯¼è‡´è¯¥è¯·æ±‚ 90% çš„é¢„ç•™æ˜¾å­˜è¢«ç™½ç™½æµªè´¹ Â ã€‚
2. **å¤–éƒ¨ç¢ç‰‡ï¼ˆExternal Fragmentationï¼‰ï¼š**Â  éšç€è¯·æ±‚çš„è¿›è¿›å‡ºå‡ºï¼ŒGPU æ˜¾å­˜è¢«åˆ†å‰²æˆè®¸å¤šå°çš„ã€ä¸è¿ç»­çš„ç©ºé—²å—ã€‚å½“ä¸€ä¸ªæ–°è¯·æ±‚ï¼ˆä¾‹å¦‚éœ€è¦ 1024 tokens çš„è¿ç»­ç©ºé—´ï¼‰åˆ°è¾¾æ—¶ï¼Œå³ä½¿æ€»çš„ç©ºé—²æ˜¾å­˜ï¼ˆä¾‹å¦‚ 2000 tokensï¼‰è¶³å¤Ÿï¼Œä½†ç”±äºæ‰¾ä¸åˆ°**è¿ç»­çš„ 1024 tokens ç©ºé—´**ï¼Œç³»ç»Ÿä¹Ÿä¼šå›  OOM (Out-of-Memory) è€Œå´©æºƒ Â ã€‚

![](img/memory_waste.png)

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒvLLM æå‡ºäº† PageAttention æœºåˆ¶ä»¥åŠå¯¹åº”çš„ Attention kernel è§£å†³äº†**æ˜¾å­˜ç¢ç‰‡é—®é¢˜**ä»¥åŠ Batching Problems ä¸­ï¼Œ**ä¸åŒ token index çš„ decoding request æ‰¹å¤„ç†**çš„é—®é¢˜ã€‚

#### Design

##### Page Attention

vLLM çš„ PagedAttention æœºåˆ¶ï¼Œå…¶çµæ„Ÿæ¥è‡ªäºç°ä»£æ“ä½œç³»ç»Ÿï¼ˆOSï¼‰ä¸­æˆç†Ÿçš„è™šæ‹Ÿå†…å­˜å’Œåˆ†é¡µæŠ€æœ¯ Â ã€‚

vLLM çš„å†…å­˜ç®¡ç†å™¨é¦–å…ˆå°† GPU æ˜¾å­˜ä¸­ç”¨äº KV ç¼“å­˜çš„åŒºåŸŸï¼Œåˆ’åˆ†ä¸ºæ•°åƒä¸ªå¤§å°å›ºå®šçš„â€œç‰©ç†å—â€ï¼ˆPhysical Blocksï¼‰ï¼Œä¾‹å¦‚ï¼Œæ¯ä¸ªå—å›ºå®šä¸º 16 tokens çš„å¤§å° Â ã€‚

å½“è¯·æ±‚ç”Ÿæˆ token æ—¶ï¼Œç³»ç»Ÿä¼šâ€œæŒ‰éœ€â€ï¼ˆon-demandï¼‰ä¸ºå…¶åˆ†é…ç‰©ç†å— Â ã€‚ä¸€ä¸ª 100-token çš„ KV ç¼“å­˜ï¼Œç°åœ¨è¢«å­˜å‚¨åœ¨ 7 ä¸ªï¼ˆ`100/16`Â  å‘ä¸Šå–æ•´ï¼‰ç‰©ç†å—ä¸­ã€‚æœ€å…³é”®çš„æ˜¯ï¼Œ**è¿™äº›ç‰©ç†å—åœ¨æ˜¾å­˜ä¸­å®Œå…¨ä¸éœ€è¦æ˜¯è¿ç»­çš„**Â ã€‚

è¿™ç§â€œåˆ†é¡µâ€ç®¡ç†æ–¹å¼å¸¦æ¥äº†ç«‹ç«¿è§å½±çš„å†…å­˜ä¼˜åŠ¿ï¼š

- **æ¶ˆé™¤å†…éƒ¨ç¢ç‰‡ï¼š**Â  å†…å­˜æŒ‰éœ€åˆ†é…ï¼Œæœ€å°å•ä½æ˜¯ 1 ä¸ªå—ï¼ˆ16 tokensï¼‰ï¼Œåªæœ‰**æœ€åä¸€ä¸ªå—çš„å°¾éƒ¨ä¼šæœ‰æµªè´¹**ã€‚
- **æ¶ˆé™¤å¤–éƒ¨ç¢ç‰‡ï¼š**Â  æ‰€æœ‰å—çš„å¤§å°éƒ½ç›¸åŒï¼Œä»»ä½•ä¸€ä¸ªç©ºé—²å—éƒ½å¯ä»¥è¢«ä»»ä½•è¯·æ±‚ä½¿ç”¨ Â ã€‚
- **å®ç°é«˜æ•ˆå…±äº«ï¼š**Â  è¿™ä¸€è®¾è®¡ä½¿å¾— KV ç¼“å­˜çš„å…±äº«å˜å¾—æå…¶ç®€å•å’Œå»‰ä»·ã€‚ä¾‹å¦‚ï¼Œåœ¨å¹¶è¡Œé‡‡æ ·ï¼ˆparallel samplingï¼‰æˆ–å‰ç¼€ç¼“å­˜ï¼ˆprefix cachingï¼‰ä¸­ï¼Œå¤šä¸ªé€»è¾‘è¯·æ±‚ï¼ˆä¾‹å¦‚ï¼Œå…·æœ‰ç›¸åŒ prompt çš„ 3 ä¸ªè¯·æ±‚ï¼‰çš„ **KV ç¼“å­˜å¯ä»¥æŒ‡å‘ç›¸åŒçš„ç‰©ç†å—**Â ã€‚

##### Prefill First Schedule Policy

- vLLM ä¼šå°½å¯èƒ½å¤šåœ°è°ƒåº¦æ–°çš„ prefillï¼Œç„¶åæ‰æ¢å¤æ­£åœ¨è¿›è¡Œçš„ decodeï¼Œä»è€Œå¼•å‘ generation stallã€‚(**ç‰ºç‰² token é—´å»¶è¿Ÿï¼ˆTBTï¼‰æ¥æ¢å–æ›´é«˜ååç‡**)

##### PagedAttention Kernelï¼šå¼‚æ„æ‰¹å¤„ç†åœ¨è®¡ç®—å±‚é¢çš„å®ç°

vLLM å®ç°äº†ä¸€ä¸ªé«˜åº¦å®šåˆ¶åŒ–çš„ CUDA kernelï¼Œé€šå¸¸ç§°ä¸º Â `paged_attention_kernel`ã€‚è¿™ä¸ª kernel ä»ä¸€å¼€å§‹å°±æ˜¯ä¸ºäº†åœ¨ PagedAttention æä¾›çš„**éè¿ç»­ã€åˆ†é¡µçš„å†…å­˜å¸ƒå±€ä¸Šæ‰§è¡Œ Attention è®¡ç®—**è€Œè®¾è®¡çš„ Â ã€‚è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„â€œå†…å­˜-è®¡ç®—ååŒè®¾è®¡â€ï¼ˆMemory-Compute Co-designï¼‰çš„èŒƒä¾‹ Â ã€‚

vLLM çš„è°ƒåº¦ç­–ç•¥**åªä¼šå­˜åœ¨ all decode å’Œ all prefill çš„ batch**ï¼ŒPageAttention Kernel å¤„ç†çš„æ­£æ˜¯**åŒ…å«ä¸åŒé•¿åº¦ KV Cache çš„ decode batch**ï¼›è€Œ all prefill åˆ™ç”±å…¶ä»–çš„ batching kernel å¤„ç†ï¼Œå¦‚ flashinfer kernel æˆ–è€… flash attentionã€‚

#### Problems

- **Prefill Block Decode**ï¼šå®ƒä»¬åœ¨æ‰§è¡Œæ–°çš„ prefillï¼ˆé¢„å¡«å……ï¼‰æ—¶ä¼š**æš‚åœæ­£åœ¨è¿›è¡Œçš„ decodeï¼ˆè§£ç ï¼‰**ï¼Œæ˜¾è‘—å¢åŠ  TBTã€‚

---

### Chunked Prefill

`Taming Throughput-Latency Tradeoff in LLM Inference with Sarathi-Serve` æå‡ºäº† `chunked prefill` å’Œä¸€ç§æ··åˆ `prefill` å’Œ `decode` çš„ `stall-free scheduling` è°ƒåº¦ç­–ç•¥ã€‚å¯ä»¥åœ¨ä¿è¯ TBT çš„æœåŠ¡è´¨é‡åŒæ—¶ï¼Œå°½å¯èƒ½å¢åŠ ååé‡ã€‚

> åœ¨ç®—æœ¯å¯†é›†åº¦æ¯”è¾ƒä½çš„ decode é˜¶æ®µï¼Œä¸è¢«åˆ†å—çš„ prefill ä»»åŠ¡ä¸€èµ·ä½œä¸ºä¸€ä¸ª batch è¿›è¡Œæ‰¹å¤„ç†ã€‚

#### Motivation

- **Cost Analysis of Prefill and Decode**

  - æ‰¹å¤„ç†æå¤§åœ°æé«˜äº†è§£ç é˜¶æ®µçš„ååé‡ï¼Œä½†å¯¹é¢„å¡«å……ååé‡å½±å“å¾ˆå°

  ![](img/prefill_decode.png)

- **Low Compute Utilization during Decodes**

  - Decode é˜¶æ®µçš„ç®—æœ¯å¯†é›†ç¨‹åº¦å¾ˆä½ï¼ŒPrefill ç®—æœ¯å¯†é›†ç¨‹åº¦å¾ˆé«˜
  - æˆ‘ä»¬å¯ä»¥åœ¨ decode é˜¶æ®µè€ƒè™‘åŠ å…¥ prefillï¼Œå…±åŒç»„æˆä¸€ä¸ª batch

  ![](img/arithmetic_intensity.png)

- **Throughput-Latency Trade-off**

  - vLLM ä¼šå°½å¯èƒ½å¤šåœ°è°ƒåº¦æ–°çš„ prefillï¼Œç„¶åæ‰æ¢å¤æ­£åœ¨è¿›è¡Œçš„ decodeï¼Œä»è€Œå¼•å‘ generation stallã€‚(**ç‰ºç‰² token é—´å»¶è¿Ÿï¼ˆTBTï¼‰æ¥æ¢å–æ›´é«˜ååç‡**)

  - Orca æ”¯æŒæ··åˆæ‰¹æ¬¡ï¼ˆprefill + decode æ··åˆï¼‰ï¼Œè€Œ vLLM åªèƒ½å¤„ç†å…¨ prefill æˆ–å…¨ decode çš„æ‰¹æ¬¡ã€‚(**ç‰ºç‰² token é—´å»¶è¿Ÿï¼ˆTBTï¼‰æ¥æ¢å–æ›´é«˜ååç‡)**
    > [!WARNING]
    > å³ä¾¿å¦‚æ­¤ï¼ŒOrca ä»æ— æ³•å®Œå…¨é¿å… stallï¼Œå› ä¸º**å«æœ‰é•¿ prompt çš„ prefill æ‰¹æ¬¡æ‰§è¡Œæ—¶é—´å¤ªé•¿ã€‚**
  - FasterTransformer é‡‡å– **ä¸¥æ ¼çš„è¯·æ±‚çº§ï¼ˆrequest-levelï¼‰æ‰¹å¤„ç†**ï¼Œä¸äº¤å‰ prefill ä¸ decodeã€‚**è¿™ç§â€œå…ˆå…¨éƒ¨ decodeï¼Œå† prefill æ–°è¯·æ±‚â€çš„æ–¹å¼ä¿æŒç¨³å®šå»¶è¿Ÿï¼Œä½† GPU é—²ç½®æ—¶é—´å¤šï¼Œååç‡è¾ƒå·®**ã€‚

- **Pipeline Bubbles waste GPU Cycles**

  - æˆ‘ä»¬åœ¨æ¨ç†è¿‡ç¨‹ä¸­è¯†åˆ«å‡ºä¸‰ç§ç±»å‹çš„æµæ°´çº¿æ°”æ³¡ï¼ˆPipeline Bubblesï¼‰ï¼š
    1. **$PB_1$ å‹æ°”æ³¡**ï¼šç”±äºç›¸é‚»ä¸¤ä¸ªå¾®æ‰¹æ¬¡ä¸­çš„é¢„å¡«å…… token æ•°é‡ä¸åŒè€Œäº§ç”Ÿï¼›
    2. **$PB_2$ å‹æ°”æ³¡**ï¼šå½“é¢„å¡«å……é˜¶æ®µä¸è§£ç é˜¶æ®µäº¤æ›¿æ‰§è¡Œæ—¶ï¼Œç”±äºä¸¤è€…è®¡ç®—æ—¶é—´ä¸åŒè€Œäº§ç”Ÿï¼›
    3. **$PB_3$ å‹æ°”æ³¡**ï¼šå½“ä¸åŒå¾®æ‰¹æ¬¡çš„è§£ç é˜¶æ®µè®¡ç®—æ—¶é—´ä¸åŒè€Œäº§ç”Ÿã€‚
  - è¿™ç§å·®å¼‚çš„æ ¹æœ¬åŸå› åœ¨äºæ³¨æ„åŠ›è®¡ç®—çš„å¼€é”€å–å†³äºç´¯ç§¯çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆå³ **KV-cache å¤§å°**ï¼‰ï¼Œè€Œè¯¥é•¿åº¦åœ¨ä¸åŒè¯·æ±‚ä¹‹é—´æ˜¯ä¸åŒçš„ã€‚

  - å¦‚æœæˆ‘ä»¬èƒ½å¤Ÿç¡®ä¿æ¯ä¸ª micro-batch æ‰§è¡Œçš„è®¡ç®—é‡å¤§è‡´ç›¸åŒï¼Œå°±èƒ½æ˜¾è‘—**å‡å°‘è¿™äº›æµæ°´çº¿æ°”æ³¡**ã€‚

  ![](img/orca_bubble.png)

#### Design

**Sarathi-Serve é‡‡ç”¨äº†ï¼š**

- **Chunked Prefillï¼ˆåˆ†å—é¢„å¡«å……ï¼‰**ï¼šå°†é•¿ prefill æ‹†åˆ†ä¸ºå¤šä¸ªå°å—ï¼›
- **Stall-free Schedulingï¼ˆæ— åœé¡¿è°ƒåº¦ï¼‰**ï¼šdecode ä¸å°å— prefill äº¤é”™æ‰§è¡Œï¼Œä¸ä¼šé˜»å¡ï¼›

- **Uniform Batchingï¼ˆå‡åŒ€æ‰¹æ¬¡ï¼‰**ï¼šä½¿å¾—åŒä¸€æ‰¹å†…ä»»åŠ¡æ‰§è¡Œæ—¶é—´æ›´æ¥è¿‘ï¼Œå°½å¯èƒ½å‡å°‘æµæ°´çº¿æ°”æ³¡ã€‚

![](img/chunked_prefill.png)

##### Chunked Prefill

**è§£ç æ‰¹æ¬¡ï¼ˆdecode batchesï¼‰å—åˆ¶äºæ˜¾å­˜å¸¦å®½**ï¼Œå…¶**ç®—æœ¯å¼ºåº¦ï¼ˆarithmetic intensityï¼‰è¾ƒä½**ã€‚æˆ‘ä»¬å¯ä»¥åœ¨è§£ç æ‰¹æ¬¡ä¸­**å åŠ é¢å¤–çš„ prefill è®¡ç®—ä»»åŠ¡**ï¼Œä½†æ˜¯å¦‚æœç›´æ¥å°†å¦‚æ­¤**é•¿çš„é¢„å¡«å……**ä¸è§£ç æ‰¹æ¬¡æ··åˆæ‰§è¡Œï¼Œä¼šå¯¼è‡´**time-between-tokensï¼ˆTBTï¼‰æ˜¾è‘—ä¸Šå‡**ã€‚

**Chunked-Prefillï¼ˆåˆ†å—é¢„å¡«å……ï¼‰** æŠ€æœ¯ï¼Œå°†å¤§å‹çš„é¢„å¡«å……ä»»åŠ¡**æ‹†åˆ†ä¸ºå¤šä¸ªå°å—ï¼ˆchunkï¼‰**ï¼Œå°†è¿™äº›åˆ†å—åçš„é¢„å¡«å……ä¸è§£ç ä»»åŠ¡**ç»„åˆæˆåˆé€‚ token æ•°é‡çš„æ‰¹æ¬¡**ï¼Œä»è€Œåœ¨**ä¸è¿å TBT SLOï¼ˆæœåŠ¡ç­‰çº§ç›®æ ‡ï¼‰** çš„å‰æä¸‹ï¼Œ**å……åˆ†åˆ©ç”¨è§£ç é˜¶æ®µçš„ç®—åŠ›æ½œèƒ½**ã€‚

##### Stall-free Scheduling

ä¸ **Orca å’Œ vLLM** ä¸åŒï¼Œå®ƒä»¬åœ¨æ‰§è¡Œæ–°çš„ prefillï¼ˆé¢„å¡«å……ï¼‰æ—¶ä¼š**æš‚åœæ­£åœ¨è¿›è¡Œçš„ decodeï¼ˆè§£ç ï¼‰**ã€‚

**æ— åœé¡¿æ‰¹å¤„ç†ï¼ˆstall-free batching)** åˆ™åˆ©ç”¨è§£ç é˜¶æ®µä¸­ç®—æœ¯å¯†é›†åº¦çš„â€œç©ºé—²çª—å£â€ï¼ˆarithmetic intensity slackï¼‰æ¥æ’å…¥ Chunked Prefillï¼Œä»è€Œä¸æ‰“æ–­ decode çš„æ‰§è¡Œã€‚

- ä¼˜å…ˆå¤„ç†ä¸Šä¸€è½®çš„ decode batch
- å¦‚æœ budget è¿˜æœ‰å‰©ä½™ï¼Œå¯¹ chunked prefill åç»­çš„ chunk è¿›è¡Œå¤„ç†
- å¦‚æœè¿˜æœ‰å‰©ä½™ï¼Œå¯¹æ–°åŠ å…¥çš„ request è¿›è¡Œ chunked prefillï¼Œç„¶åå¤„ç†ç¬¬ä¸€ä¸ª chunk

![](img/stall_free_scheduling.png)

- Continuous Batching ç»“åˆ Chunked Prefill åŸºæœ¬æ„æˆäº†ç°åœ¨ä¸»æµå¤§æ¨¡å‹æ¨ç†æœåŠ¡æ¡†æ¶çš„è°ƒåº¦å±‚ï¼Œåœ¨ä¿è¯ TBT è´¨é‡çš„æƒ…å†µä¸‹å¢åŠ  GPU åˆ©ç”¨ç‡ã€‚

> ä¸‹ä¸€èŠ‚å°†ä»‹ç»è®¡ç®—å±‚æ˜¯å¦‚ä½•é€‚é…ä¸åŒçš„ batching çš„

---

## Batching Kernel

å®é™…ä¸Šï¼Œæˆ‘ä»¬éœ€è¦æ–°çš„ kernel æ¥é€‚é…ä¸Šé¢ä¸‰ä¸ªä¸åŒçš„ Batching æƒ…å†µã€‚æˆ‘ä»¬ä¼šä»‹ç»é’ˆå¯¹å˜é•¿ prefill çš„ prepacking æŠ€æœ¯ä»¥åŠ vLLM ä½¿ç”¨çš„ flashinfer å’Œ flashattention å†…æ ¸å‡½æ•°ã€‚

### Prepacking Technology

è¯¥æŠ€æœ¯æ˜¯è§£å†³å˜é•¿ Prefill çš„å…³é”®ï¼ŒæŠŠå¤šä¸ªè¾ƒçŸ­çš„ prompt æ”¾å…¥ä¸€ä¸ªâ€œå®¹å™¨â€é‡Œï¼Œä½¿å¾—æ€»é•¿åº¦æ¥è¿‘æŸä¸€æœ€å¤§é•¿åº¦ï¼Œé¿å… paddingã€‚

- **åˆå¹¶åºåˆ— + ä¿®æ”¹ Attention Mask ä¸ä½ç½®ç¼–ç  (Positional Encoding Restart)**
  - åœ¨æ‹¼æ¥å¤šä¸ª prompt ä¸ºä¸€ä¸ªåºåˆ—åï¼Œå¼•å…¥äº†**ç‹¬ç«‹æ©ç ï¼ˆindependent maskingï¼‰** ä¿è¯ä¸åŒ prompt ä¹‹é—´ **ä¸ä¼šäº’ç›¸ attend**ã€‚
- **ä¸€æ¬¡ Prefill è°ƒç”¨å¤šä¸ª Prompts çš„ KV-Cache ç”Ÿæˆ**
  - åˆ©ç”¨ä¸Šè¿°æ‰“åŒ…æœºåˆ¶ï¼Œå¯ä»¥åœ¨ä¸€æ¬¡æ¨¡å‹è°ƒç”¨ä¸­å¤„ç†å¤šä¸ª promptï¼Œä»è€Œç”Ÿæˆå¤šä¸ª KV-ç¼“å­˜ã€‚å‡å°‘ kernel å¯åŠ¨å¼€é”€ã€å‡å°‘å¡«å…… token çš„è®¡ç®—æµªè´¹

![](img/prepacking.png)

### FlashInfer & Flash Attention

vLLM ç­‰å¤§æ¨¡å‹æ¨ç†æœåŠ¡ç³»ç»Ÿä¼šä¾èµ–ä¸“ä¸šçš„å†…æ ¸åº“å¦‚ FlashInfer å’Œ Flash Attentionã€‚

- å®ƒä»¬ä¸“é—¨æä¾›é’ˆå¯¹åˆ†é¡µ KV Cache çš„é«˜æ•ˆ Batch æ³¨æ„åŠ›å†…æ ¸ Â ã€‚

#### FlashInfer

- æä¾›äº†ä¸€ä¸ª BatchPrefillWithPagedKVCacheWrapperï¼Œå…è®¸å¯¹å¤šä¸ªè¯·æ±‚å¸¦æœ‰åˆ†é¡µ KV Cache çš„ prefill è¿›è¡Œå¤„ç†ã€‚

  - `qo_indptr`ï¼ˆlength = num_sequences + 1ï¼‰
    - å«ä¹‰ï¼š`qo_indptr[i]` æ˜¯ç¬¬ i ä¸ª sequence åœ¨ q ä¸­çš„èµ·å§‹ä½ç½®ï¼ˆoffsetï¼‰ï¼Œ`qo_indptr[i+1] - qo_indptr[i]` æ˜¯è¯¥ sequence å¯¹åº”çš„ query token æ•°ï¼ˆprefill å¯èƒ½ä¸º chunk é•¿åº¦ï¼Œdecode ä¸º 1ï¼‰ã€‚
  - `kv_page_indptr`ï¼ˆlength = num_sequences + 1ï¼‰
    - å«ä¹‰ï¼šæŠŠæ‰å¹³é¡µè¡¨ `kv_page_indices` åˆ‡åˆ†æˆæ¯ä¸ª sequence çš„é¡µèŒƒå›´ã€‚ç¬¬ i ä¸ª sequence ä½¿ç”¨çš„é¡µæ˜¯ `kv_page_indices[kv_page_indptr[i]:kv_page_indptr[i+1]]`ã€‚
  - `kv_page_indices`ï¼ˆflat listï¼‰

    - å«ä¹‰ï¼šæŒ‰åºåˆ—æ‹¼æ¥çš„ç‰©ç†é¡µ id åˆ—è¡¨ï¼Œæ¯ä¸ª entry æ˜¯ä¸€ä¸ª page çš„å…¨å±€ç´¢å¼•ï¼ˆèŒƒå›´ `0..max_num_pages-1`ï¼‰ã€‚kernel ç”¨è¿™ä¸ªç´¢å¼•å»ä» `paged_kv_cache` ä¸­å–å‡ºè¯¥é¡µçš„ K/V æ•°æ®ã€‚

  - `kv_last_page_len`ï¼ˆlength = num_sequencesï¼‰
    - å«ä¹‰ï¼šå¯¹äºæ¯ä¸ª sequenceï¼Œæœ€åä¸€ä¸ª page å¯èƒ½æœªå¡«æ»¡ï¼ˆåªæœ‰ L ä¸ªæœ‰æ•ˆ tokenï¼‰ï¼Œè¿™é‡Œè®°å½•æœ€åä¸€ä¸ª page çš„æœ‰æ•ˆ token æ•°ï¼ˆè‹¥æ»¡é¡µåˆ™ç­‰äº `page_size`ï¼‰ã€‚ç”¨äºè®¡ç®— attention æ—¶å±è”½ page å°¾éƒ¨çš„éæ³•å…ƒç´ ã€é¿å…è¶Šç•Œä¸é”™è¯¯ attentionã€‚

```python
prefill_wrapper = flashinfer.BatchPrefillWithPagedKVCacheWrapper(
    workspace_buffer, "NHD"
)

prefill_wrapper.plan(
    qo_indptr,
    paged_kv_indptr,
    paged_kv_indices,
    paged_kv_last_page_len,
    num_qo_heads,
    num_kv_heads,
    head_dim,
    page_size,
    causal=True,
)

# =========================
# é€å±‚æ‰§è¡Œ batch prefill attention
# =========================
outputs = []
for i in range(num_layers):
    q = q_at_layer[i]
    kv_cache = kv_cache_at_layer[i]
    # è®¡ç®— batched prefill attentionï¼ˆå¯å¤ç”¨ planï¼‰
    o = prefill_wrapper.run(q, kv_cache)
    outputs.append(o)
```

#### Flash Attention

- Flash Attention æä¾›äº† Â `flash_attn_with_kvcache` å‡½æ•°ï¼Œå®ƒç›´æ¥æ¥å—æ•´ä¸ªé¡µè¡¨ï¼Œå®ƒæä¾›äº†å¯¹åˆ†é¡µ KV ç¼“å­˜ï¼ˆé¡µé¢å¤§å° > 1ï¼‰çš„åŸç”Ÿæ”¯æŒï¼Œå…è®¸ **â€œragged tensorï¼ˆä¸è§„åˆ™å¼ é‡ï¼‰â€** çš„å¤„ç†ï¼Œè€Œ Â `flash_attn_varlen_func`Â  ä¸æ”¯æŒé¡µè¡¨ã€‚

> `flash_attn_varlen_func` ç”¨äº MLAï¼Œç›´æ¥è®¡ç®— attentionï¼Œ**ä¸ä»é¢„å­˜çš„ KV cache è¯»å–**

```python
def flash_attn_with_kvcache(
    q,
    k_cache,
    v_cache,
    cache_seqlens: Optional[Union[(int, torch.Tensor)]] = None,
    page_table: Optional[torch.Tensor] = None,
    cu_seqlens_q: Optional[torch.Tensor] = None,
    cu_seqlens_k_new: Optional[torch.Tensor] = None,
    max_seqlen_q: Optional[int] = None,
    causal=False,
):
    """
    Arguments:
        q: (batch_size, seqlen, nheads, headdim)
        k_cache: (batch_size_cache, seqlen_cache, nheads_k, headdim) if there's no page_table,
            or (num_blocks, page_block_size, nheads_k, headdim) if there's a page_table (i.e. paged KV cache)
            page_block_size must be a multiple of 256.
        v_cache: (batch_size_cache, seqlen_cache, nheads_k, headdim_v) if there's no page_table,
            or (num_blocks, page_block_size, nheads_k, headdim_v) if there's a page_table (i.e. paged KV cache)
        cache_seqlens: int, or (batch_size,), dtype torch.int32. The sequence lengths of the
            KV cache.
        page_table [optional]: (batch_size, max_num_blocks_per_seq), dtype torch.int32.
            The page table for the KV cache. It will derived attention backend's req_to_token_pool.
        cu_seqlens_q: (batch_size,), dtype torch.int32. The cumulative sequence lengths of the query.
        cu_seqlens_k_new: (batch_size,), dtype torch.int32. The cumulative sequence lengths of the new key/value.
        max_seqlen_q: int. The maximum sequence length of the query.
        causal: bool. Whether to apply causal attention mask (e.g., for auto-regressive modeling).

    Return:
        out: (batch_size, seqlen, nheads, headdim).
    """
```

---

## Summary

åœ¨å¤§æ¨¡å‹æ¨ç†ç³»ç»Ÿä¸­ï¼Œ**Batching æ˜¯ååé‡ä¸å»¶è¿Ÿå¹³è¡¡çš„æ ¸å¿ƒæœºåˆ¶**ã€‚å®ƒçš„ç›®æ ‡æ˜¯ï¼šåœ¨ä¸ç‰ºç‰²æœåŠ¡è´¨é‡ï¼ˆTTFTã€TBTï¼‰çš„å‰æä¸‹ï¼Œæœ€å¤§åŒ– GPU çš„åˆ©ç”¨ç‡ï¼Œå……åˆ†æŒ–æ˜ç®—åŠ›æ½œèƒ½ã€‚

ä¸‹é¢æˆ‘ä»¬å°†é‡æ–°å›é¡¾ä¸Šé¢çš„æŠ€æœ¯æ¼”è¿›è¿‡ç¨‹ï¼šä»**é™æ€æ‰¹å¤„ç†**åˆ°**è¿ç»­æ‰¹å¤„ç†**å†åˆ°**åˆ†å—é¢„å¡«å……**çš„æ¼”åŒ–è„‰ç»œï¼Œä½“ç°äº†è°ƒåº¦å±‚ä¸è®¡ç®—å±‚çš„ååŒä¼˜åŒ–ã€‚

### è°ƒåº¦å±‚

- é™æ€æ‰¹å¤„ç†ï¼ˆStatic Batchingï¼‰â€”â€”**Padding**

  - **ç‰¹ç‚¹**ï¼šä¸€æ¬¡å›ºå®š batch æ‰¹é‡æ¨ç†ï¼›æ‰€æœ‰åºåˆ—å¡«å……åˆ°ç›¸åŒé•¿åº¦ã€‚
  - **ä¼˜åŠ¿**ï¼šå®ç°ç®€å•ï¼›å¯ç›´æ¥åˆ©ç”¨æ ‡å‡† dense kernelã€‚
  - **ç¼ºé™·**ï¼šå¸¦æ¥ä¸¥é‡çš„ **è®¡ç®—æµªè´¹**ã€**æ˜¾å­˜æµªè´¹** å’Œ **GPU ç©ºé—²å‘¨æœŸ**ï¼›  
     æ— æ³•åŠ¨æ€æ¥å…¥è¯·æ±‚æˆ–æå‰é€€å‡ºã€‚

> [!NOTE]
> æœ¬è´¨ï¼šrequest-level batchingï¼Œä½æ•ˆä½†æ˜“äºå®ç°ã€‚

---

- è¿ç»­æ‰¹å¤„ç†ï¼ˆContinuous Batching / Iteration-level Schedulingï¼‰â€”â€”**è¿­ä»£è°ƒåº¦ï¼Œéå¯¹é½æ‰§è¡Œ**

  - **ä»£è¡¨ç³»ç»Ÿ**ï¼šORCA
  - **æ ¸å¿ƒæ€æƒ³**ï¼šæ¯æ¬¡è¿­ä»£åå¯åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡ç»„æˆï¼Œè®©å·²å®Œæˆè¯·æ±‚é€€å‡ºã€æ–°è¯·æ±‚ç«‹å³åŠ å…¥ã€‚
  - **å…³é”®ä¼˜åŒ–**ï¼šSelective Batching â€”â€” å¯¹ non-Attention æ“ä½œè¿›è¡Œè·¨è¯·æ±‚ batchingï¼Œé¿å… paddingã€‚
  - **ç“¶é¢ˆ**ï¼šAttention ä»éœ€å•ç‹¬æ‰§è¡Œï¼Œä»å—é™äºâ€œåŒå½¢å¼ é‡â€å‡è®¾ï¼›  
     å†…å­˜åˆ†é…ç¢ç‰‡ä¸¥é‡ï¼Œå½±å“é•¿æœŸç¨³å®šæ€§ã€‚

> [!NOTE]
> æœ¬è´¨ï¼štoken-level batchingï¼Œä½†å—é™äº kernel èƒ½åŠ›ã€‚

---

- Page Attention â€”â€”**åˆ†é¡µå†…å­˜ç®¡ç† + page attention kernel**

  - **ä»£è¡¨ç³»ç»Ÿ**ï¼švLLM
  - **åˆ›æ–°ç‚¹**ï¼šå¼•å…¥ KV Cache åˆ†é¡µæœºåˆ¶ï¼Œæ¯ä¸ªè¯·æ±‚ç»´æŠ¤ block tableï¼Œå®ç°éè¿ç»­æ˜¾å­˜ç®¡ç†ã€‚
  - **ä¼˜åŠ¿**ï¼š
    - æ¶ˆé™¤å†…/å¤–éƒ¨ç¢ç‰‡ï¼›
    - æ”¯æŒä¸åŒ token index çš„è§£ç è¯·æ±‚æ‰¹å¤„ç†ï¼›
    - æå¤§æå‡å†…å­˜åˆ©ç”¨ç‡ã€‚
  - **å±€é™**ï¼š
    - ä»é‡‡ç”¨ Prefill-First ç­–ç•¥ï¼Œè§£ç é˜¶æ®µä¼šè¢« prefill é˜»å¡ï¼›
    - ååä¸å»¶è¿Ÿå­˜åœ¨æ˜¾è‘—æƒè¡¡ã€‚

> [!NOTE]
> æœ¬è´¨ï¼šåœ¨è®¡ç®—å±‚é€šè¿‡ PagedAttention Kernel æ”¯æŒä¸åŒé•¿åº¦ KV Cache çš„ batchã€‚

---

- Chunked Prefill + Stall-free Scheduling â€”â€”**ç®—åŠ›å¹³è¡¡ä¸å»¶è¿Ÿå…±èµ¢**

  - **ä»£è¡¨ç³»ç»Ÿ**ï¼šSarathi-Serve
  - **æ ¸å¿ƒåˆ›æ–°**ï¼šå°†é•¿ prefill åˆ†å—ï¼ˆChunked Prefillï¼‰ï¼Œä¸ decode é˜¶æ®µäº¤é”™æ‰§è¡Œï¼ˆStall-free Schedulingï¼‰ã€‚
  - **ä¼˜åŠ¿**ï¼š
    - å…¼é¡¾ç®—æœ¯å¯†é›†ä¸è®¿å­˜å¯†é›†é˜¶æ®µï¼›
    - æ¶ˆé™¤ pipeline bubbleï¼›
    - åœ¨ä¿è¯ TBT SLO çš„å‰æä¸‹æå‡ååç‡ã€‚

> [!NOTE]
> æœ¬è´¨ï¼šPrefill-Decode æ··åˆæ‰¹æ¬¡è°ƒåº¦ï¼Œå®ç°ååä¸å»¶è¿Ÿçš„åŠ¨æ€å¹³è¡¡ã€‚

---

### è®¡ç®—å±‚

- **Kernel-Level æ¼”è¿›**ï¼šä» Padding åˆ° Prepacking

  - **Prepacking** æŠ€æœ¯é€šè¿‡æ‰“åŒ…å¤šä¸ª promptã€ä¿®æ”¹ attention mask å’Œ positional encodingï¼Œå®ç°å˜é•¿ prefill çš„ä¸€æ¬¡æ€§ KV-Cache ç”Ÿæˆã€‚

- **FlashInfer / FlashAttention** åˆ™æä¾›åº•å±‚é«˜æ•ˆçš„ kernel å®ç°ï¼Œæ”¯æŒ ragged tensor ä¸ paged KV cacheï¼ŒçœŸæ­£å®ç°äº†è®¡ç®—å±‚å¯¹å˜é•¿åºåˆ—çš„å‹å¥½æ”¯æŒã€‚

> [!NOTE]
> æœ¬è´¨ï¼šç®—å­å±‚çš„ç»“æ„æ€§ä¼˜åŒ–ï¼Œä¸º Continuous Batching ä¸ Chunked Prefill æä¾›ç®—åŠ›æ”¯æ’‘ã€‚

---
