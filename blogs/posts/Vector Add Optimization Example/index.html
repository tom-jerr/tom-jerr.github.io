<!DOCTYPE html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Experience the journey of a database wizard, from the basics to advanced topics."><meta name=author content=tom-jerr><link href=https://tom-jerr.github.io/blogs/posts/Vector%20Add%20Optimization%20Example/ rel=canonical><link href=../PageAttention/ rel=prev><link href=../%E4%B8%8A%E7%AF%87%EF%BC%9A%E5%88%9D%E8%AF%86%20Nebula%20Graph%20%E2%80%94%E2%80%94%20%E5%90%91%E9%87%8F%E7%B1%BB%E5%9E%8B%E6%94%AF%E6%8C%81/ rel=next><link rel=icon href=../../../img/rocket.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.23"><title>一步步实现 CUDA Vector Add 优化 - Want to be a MlSys wizard</title><link rel=stylesheet href=../../../assets/stylesheets/main.84d31ad4.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=JetBrains+Mono:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"JetBrains Mono";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../css/custom.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css><link rel=stylesheet href=https://gcore.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css><link rel=stylesheet href=../../../css/card.css><link rel=stylesheet href=../../../css/flink.css><link rel=stylesheet href=../../../css/tasklist.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-20LWGZNLLR"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-20LWGZNLLR",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-20LWGZNLLR",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link href=../../../assets/stylesheets/glightbox.min.css rel=stylesheet><script src=../../../assets/javascripts/glightbox.min.js></script><style id=glightbox-style>
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#cuda-vector-add class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="Want to be a MlSys wizard" class="md-header__button md-logo" aria-label="Want to be a MlSys wizard" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"></path></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Want to be a MlSys wizard </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 一步步实现 CUDA Vector Add 优化 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=indigo aria-label="light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="dark mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"></path></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/tom-jerr/tom-jerr.github.io/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg> </div> <div class=md-source__repository> tom-jerr's Site </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"></path></svg> Home </a> </li> <li class=md-tabs__item> <a href=../../../notes/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"></path></svg> Notes </a> </li> <li class=md-tabs__item> <a href=../../../paperreadings/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M384 512H96c-53 0-96-43-96-96V96C0 43 43 0 96 0h304c26.5 0 48 21.5 48 48v288c0 20.9-13.4 38.7-32 45.3V448c17.7 0 32 14.3 32 32s-14.3 32-32 32zM96 384c-17.7 0-32 14.3-32 32s14.3 32 32 32h256v-64zm32-232c0 13.3 10.7 24 24 24h176c13.3 0 24-10.7 24-24s-10.7-24-24-24H152c-13.3 0-24 10.7-24 24m24 72c-13.3 0-24 10.7-24 24s10.7 24 24 24h176c13.3 0 24-10.7 24-24s-10.7-24-24-24z"></path></svg> PaperReading </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M224 24c0-13.3 10.7-24 24-24 145.8 0 264 118.2 264 264 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-119.3-96.7-216-216-216-13.3 0-24-10.7-24-24M80 96c26.5 0 48 21.5 48 48v224c0 26.5 21.5 48 48 48s48-21.5 48-48-21.5-48-48-48c-8.8 0-16-7.2-16-16v-64c0-8.8 7.2-16 16-16 79.5 0 144 64.5 144 144s-64.5 144-144 144S32 447.5 32 368V144c0-26.5 21.5-48 48-48m168 0c92.8 0 168 75.2 168 168 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-66.3-53.7-120-120-120-13.3 0-24-10.7-24-24s10.7-24 24-24"></path></svg> Blogs </a> </li> <li class=md-tabs__item> <a href=../../../summary/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1zM5 8v11h14V8zm2 2h10v2H7z"></path></svg> Summaries </a> </li> <li class=md-tabs__item> <a href=../../../tags/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M5.5 7A1.5 1.5 0 0 1 4 5.5 1.5 1.5 0 0 1 5.5 4 1.5 1.5 0 0 1 7 5.5 1.5 1.5 0 0 1 5.5 7m15.91 4.58-9-9C12.05 2.22 11.55 2 11 2H4c-1.11 0-2 .89-2 2v7c0 .55.22 1.05.59 1.41l8.99 9c.37.36.87.59 1.42.59s1.05-.23 1.41-.59l7-7c.37-.36.59-.86.59-1.41 0-.56-.23-1.06-.59-1.42"></path></svg> Tags </a> </li> <li class=md-tabs__item> <a href=../../../links/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.78 3.653a3.936 3.936 0 1 1 5.567 5.567l-3.627 3.627a3.936 3.936 0 0 1-5.88-.353.75.75 0 0 0-1.18.928 5.436 5.436 0 0 0 8.12.486l3.628-3.628a5.436 5.436 0 1 0-7.688-7.688l-3 3a.75.75 0 0 0 1.06 1.061z"></path><path d="M7.28 11.153a3.936 3.936 0 0 1 5.88.353.75.75 0 0 0 1.18-.928 5.436 5.436 0 0 0-8.12-.486L2.592 13.72a5.436 5.436 0 1 0 7.688 7.688l3-3a.75.75 0 1 0-1.06-1.06l-3 3a3.936 3.936 0 0 1-5.567-5.568z"></path></svg> Links </a> </li> <li class=md-tabs__item> <a href=../../../about/ class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-90.6-190.1c20.4 28 53.4 46.1 90.6 46.1s70.2-18.1 90.6-46.1c7.8-10.7 22.8-13.1 33.5-5.3s13.1 22.8 5.3 33.5C356.3 390 309.2 416 256 416s-100.3-26-129.4-65.9c-7.8-10.7-5.4-25.7 5.3-33.5s25.7-5.4 33.5 5.3M144 208a32 32 0 1 1 64 0 32 32 0 1 1-64 0m164 8c0 11-9 20-20 20s-20-9-20-20c0-33.1 26.9-60 60-60h16c33.1 0 60 26.9 60 60 0 11-9 20-20 20s-20-9-20-20-9-20-20-20h-16c-11 0-20 9-20 20"></path></svg> About </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="Want to be a MlSys wizard" class="md-nav__button md-logo" aria-label="Want to be a MlSys wizard" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"></path></svg> </a> Want to be a MlSys wizard </label> <div class=md-nav__source> <a href=https://github.com/tom-jerr/tom-jerr.github.io/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg> </div> <div class=md-source__repository> tom-jerr's Site </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"></path></svg> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <div class="md-nav__link md-nav__container"> <a href=../../../notes/ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"></path></svg> <span class=md-ellipsis> Notes </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Notes </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex=0> <span class=md-ellipsis> SGLang </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> SGLang </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../notes/sglang/DP%20Attention/ class=md-nav__link> <span class=md-ellipsis> DP Attention </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/sglang/SGLang%20Scheduler%20%E6%8A%80%E6%9C%AF%E5%8F%98%E8%BF%81/ class=md-nav__link> <span class=md-ellipsis> SGLang Schedular 技术变迁 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3> <label class=md-nav__link for=__nav_2_3 id=__nav_2_3_label tabindex=0> <span class=md-ellipsis> tiny-llm </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> tiny-llm </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../notes/tiny-llm/Group%20Query%20Attention/ class=md-nav__link> <span class=md-ellipsis> Group Query Attention </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/tiny-llm/RMSNorm%20%26%20MLP/ class=md-nav__link> <span class=md-ellipsis> RMSNorm &amp; MLP </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/tiny-llm/Batching%20Inference%20%26%20KV%20Cache/ class=md-nav__link> <span class=md-ellipsis> Batch Inference &amp; KV Cache </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_4> <label class=md-nav__link for=__nav_2_4 id=__nav_2_4_label tabindex=0> <span class=md-ellipsis> cuda </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_4> <span class="md-nav__icon md-icon"></span> cuda </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href="../../../notes/cuda/Roofline & Basic Analysis.md" class=md-nav__link> <span class=md-ellipsis> Roofline &amp; Basic Analysis </span> </a> </li> <li class=md-nav__item> <a href="../../../notes/cuda/Vector Add Optimization Example.md" class=md-nav__link> <span class=md-ellipsis> Vector Add Optimization Example </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_5> <div class="md-nav__link md-nav__container"> <a href=../../llm_inference/ class="md-nav__link "> <span class=md-ellipsis> LLM Inference </span> </a> <label class="md-nav__link " for=__nav_2_5 id=__nav_2_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_5_label aria-expanded=false> <label class=md-nav__title for=__nav_2_5> <span class="md-nav__icon md-icon"></span> LLM Inference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../llm_inference/Introduction/ class=md-nav__link> <span class=md-ellipsis> Introduction for LLM Inference </span> </a> </li> <li class=md-nav__item> <a href=../../llm_inference/parallelization/ class=md-nav__link> <span class=md-ellipsis> Parallelizatoin in ML System </span> </a> </li> <li class=md-nav__item> <a href=../../llm_inference/LLMparallelization/ class=md-nav__link> <span class=md-ellipsis> Parallelization in LLM Inference </span> </a> </li> <li class=md-nav__item> <a href=../../llm_inference/pageattention/ class=md-nav__link> <span class=md-ellipsis> PageAttention </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_6> <label class=md-nav__link for=__nav_2_6 id=__nav_2_6_label tabindex=0> <span class=md-ellipsis> Active SLAM </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_6_label aria-expanded=false> <label class=md-nav__title for=__nav_2_6> <span class="md-nav__icon md-icon"></span> Active SLAM </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../paperreadings/activeslam/vins%E5%9F%BA%E7%A1%80/ class=md-nav__link> <span class=md-ellipsis> VINS 基础 </span> </a> </li> <li class=md-nav__item> <a href=../../../paperreadings/activeslam/active%20slam/ class=md-nav__link> <span class=md-ellipsis> Active SLAM 概述 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_7> <label class=md-nav__link for=__nav_2_7 id=__nav_2_7_label tabindex=0> <span class=md-ellipsis> nebula </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_7_label aria-expanded=false> <label class=md-nav__title for=__nav_2_7> <span class="md-nav__icon md-icon"></span> nebula </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../projects/nebula-vsearch/understanding/1.visitor%20pattern/ class=md-nav__link> <span class=md-ellipsis> Vistor Pattern in nebula </span> </a> </li> <li class=md-nav__item> <a href=../../../projects/nebula-vsearch/understanding/2.memory%20management/ class=md-nav__link> <span class=md-ellipsis> Memory Management in nebula </span> </a> </li> <li class=md-nav__item> <a href=../../../projects/nebula-vsearch/understanding/3.concurrent%20lru%20cache/ class=md-nav__link> <span class=md-ellipsis> Concurrent LRU Cache in nebula </span> </a> </li> <li class=md-nav__item> <a href=../../../projects/nebula-vsearch/understanding/4.folly%20future%20promise/ class=md-nav__link> <span class=md-ellipsis> Folly Future Promise framework in nebula </span> </a> </li> <li class=md-nav__item> <a href=../../../projects/nebula-vsearch/understanding/5.nGQL%20life/ class=md-nav__link> <span class=md-ellipsis> nGQL Life in Nebula </span> </a> </li> <li class=md-nav__item> <a href=../../../projects/nebula-vsearch/understanding/6.raft-wal/ class=md-nav__link> <span class=md-ellipsis> Raft Wal in Nebula </span> </a> </li> <li class=md-nav__item> <a href=../../../projects/nebula-vsearch/understanding/7.how%20to%20modify%20sql/ class=md-nav__link> <span class=md-ellipsis> How to Modify nGQL </span> </a> </li> <li class=md-nav__item> <a href="../../../projects/nebula-vsearch/understandings/8.a kv life.md" class=md-nav__link> <span class=md-ellipsis> A Life of KV Pairs </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_8> <label class=md-nav__link for=__nav_2_8 id=__nav_2_8_label tabindex=0> <span class=md-ellipsis> CS61C </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_8_label aria-expanded=false> <label class=md-nav__title for=__nav_2_8> <span class="md-nav__icon md-icon"></span> CS61C </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../notes/CS61C/lecture2-Intro%20to%20C/ class=md-nav__link> <span class=md-ellipsis> 1 C Intro </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CS61C/lecture4_C%20Memory%20Endianness/ class=md-nav__link> <span class=md-ellipsis> 4 C Memory Endianness </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CS61C/lecture10_Combinational%20Logic/ class=md-nav__link> <span class=md-ellipsis> 10 Combinational Logic </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CS61C/lecture11_FSMs/ class=md-nav__link> <span class=md-ellipsis> 11 FSMs </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CS61C/lecture14_Datapath/ class=md-nav__link> <span class=md-ellipsis> 14 Datapath </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CS61C/lecture15_Data-LevelParallelism/ class=md-nav__link> <span class=md-ellipsis> 15 Data-Level Parallelism </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CS61C/lecture16_Thread-LevelParallelism/ class=md-nav__link> <span class=md-ellipsis> 16 Thread-Level Parallelism </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CS61C/lecture17_Process_LevelParallelism/ class=md-nav__link> <span class=md-ellipsis> 17 Process-Level Parallelism </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CS61C/lecture18_Caches/ class=md-nav__link> <span class=md-ellipsis> 18 Caches </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CS61C/lecture21_Virtual_Memory/ class=md-nav__link> <span class=md-ellipsis> 21 Virtual Memory </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_9> <label class=md-nav__link for=__nav_2_9 id=__nav_2_9_label tabindex=0> <span class=md-ellipsis> CSAPP </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_9_label aria-expanded=false> <label class=md-nav__title for=__nav_2_9> <span class="md-nav__icon md-icon"></span> CSAPP </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../notes/CSAPP/5-%E4%BC%98%E5%8C%96%E7%A8%8B%E5%BA%8F%E6%80%A7%E8%83%BD/ class=md-nav__link> <span class=md-ellipsis> 5-优化程序性能 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CSAPP/6-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84/ class=md-nav__link> <span class=md-ellipsis> 6-存储器层次结构 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CSAPP/7-%E9%93%BE%E6%8E%A5/ class=md-nav__link> <span class=md-ellipsis> 7-链接 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CSAPP/8-%E5%BC%82%E5%B8%B8%E6%8E%A7%E5%88%B6%E6%B5%81/ class=md-nav__link> <span class=md-ellipsis> 8-异常控制流 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CSAPP/%E7%A8%8B%E5%BA%8F%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E6%89%A7%E8%A1%8C/ class=md-nav__link> <span class=md-ellipsis> 程序的结构和执行 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CSAPP/%E5%9C%A8%E7%B3%BB%E7%BB%9F%E4%B8%8A%E8%BF%90%E8%A1%8C%E7%A8%8B%E5%BA%8F/ class=md-nav__link> <span class=md-ellipsis> 在系统上运行程序 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_10> <label class=md-nav__link for=__nav_2_10 id=__nav_2_10_label tabindex=0> <span class=md-ellipsis> 6.s081 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_10_label aria-expanded=false> <label class=md-nav__title for=__nav_2_10> <span class="md-nav__icon md-icon"></span> 6.s081 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../notes/6.s081/1-OS%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7/ class=md-nav__link> <span class=md-ellipsis> 1 OS的隔离性 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/6.s081/2-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%AE%9E%E7%8E%B0/ class=md-nav__link> <span class=md-ellipsis> 2 虚拟内存实现 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/6.s081/3-%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E5%92%8C%E9%99%B7%E5%85%A5/ class=md-nav__link> <span class=md-ellipsis> 3 系统调用和陷入 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/6.s081/4-%E7%BC%BA%E9%A1%B5%E4%B8%AD%E6%96%AD/ class=md-nav__link> <span class=md-ellipsis> 4 缺页中断 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/6.s081/5-%E7%A1%AC%E4%BB%B6%E4%B8%AD%E6%96%AD/ class=md-nav__link> <span class=md-ellipsis> 5 硬件中断 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/6.s081/6-%E5%A4%9A%E6%A0%B8%E5%92%8C%E9%94%81/ class=md-nav__link> <span class=md-ellipsis> 6 多核和锁 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/6.s081/7-%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2/ class=md-nav__link> <span class=md-ellipsis> 7 进程切换 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/6.s081/8-%E7%9D%A1%E7%9C%A0%E5%92%8C%E5%94%A4%E9%86%92/ class=md-nav__link> <span class=md-ellipsis> 8 睡眠和唤醒 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_11> <label class=md-nav__link for=__nav_2_11 id=__nav_2_11_label tabindex=0> <span class=md-ellipsis> C++ Primer </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_11_label aria-expanded=false> <label class=md-nav__title for=__nav_2_11> <span class="md-nav__icon md-icon"></span> C++ Primer </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/2_%E5%8F%98%E9%87%8F%E5%92%8C%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B/ class=md-nav__link> <span class=md-ellipsis> 2_变量和基本类型 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/3_%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%90%91%E9%87%8F%E6%95%B0%E7%BB%84/ class=md-nav__link> <span class=md-ellipsis> 3_字符串向量数组 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/4_%E8%A1%A8%E8%BE%BE%E5%BC%8F/ class=md-nav__link> <span class=md-ellipsis> 4_表达式 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/5_%E8%AF%AD%E5%8F%A5/ class=md-nav__link> <span class=md-ellipsis> 5_语句 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/6_%E5%87%BD%E6%95%B0/ class=md-nav__link> <span class=md-ellipsis> 6_函数 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/7_%E7%B1%BB/ class=md-nav__link> <span class=md-ellipsis> 7_类 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/8_IO%E5%BA%93/ class=md-nav__link> <span class=md-ellipsis> 8_IO库 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/9_%E9%A1%BA%E5%BA%8F%E5%AE%B9%E5%99%A8/ class=md-nav__link> <span class=md-ellipsis> 9_顺序容器 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/10_%E6%B3%9B%E5%9E%8B%E7%AE%97%E6%B3%95/ class=md-nav__link> <span class=md-ellipsis> 10_泛型算法 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/11_%E5%85%B3%E8%81%94%E5%AE%B9%E5%99%A8/ class=md-nav__link> <span class=md-ellipsis> 11_关联容器 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/12_%E5%8A%A8%E6%80%81%E5%86%85%E5%AD%98/ class=md-nav__link> <span class=md-ellipsis> 12_动态内存 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/13_%E6%8B%B7%E8%B4%9D%E6%8E%A7%E5%88%B6/ class=md-nav__link> <span class=md-ellipsis> 13_拷贝控制 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/14_%E9%87%8D%E8%BD%BD%E8%BF%90%E7%AE%97%E5%92%8C%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/ class=md-nav__link> <span class=md-ellipsis> 14_重载运算和类型转换 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/15_%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/ class=md-nav__link> <span class=md-ellipsis> 15_面向对象程序设计 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B/ class=md-nav__link> <span class=md-ellipsis> 并发与多线程编程 </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/c%2B%2Bprimer/Makefile%E5%AD%A6%E4%B9%A0/ class=md-nav__link> <span class=md-ellipsis> Makefile学习 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_12> <label class=md-nav__link for=__nav_2_12 id=__nav_2_12_label tabindex=0> <span class=md-ellipsis> C++ 新特性 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_12_label aria-expanded=false> <label class=md-nav__title for=__nav_2_12> <span class="md-nav__icon md-icon"></span> C++ 新特性 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../notes/C%2B%2B/1-Container/ class=md-nav__link> <span class=md-ellipsis> 1-Container </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/C%2B%2B/2-Algorithm/ class=md-nav__link> <span class=md-ellipsis> 2-Algorithm </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/C%2B%2B/3-Iterator/ class=md-nav__link> <span class=md-ellipsis> 3-Iterator </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/C++/4-FileSystem.md class=md-nav__link> <span class=md-ellipsis> 4-FileSystem </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/C%2B%2B/5-View/ class=md-nav__link> <span class=md-ellipsis> 5-View </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/C%2B%2B/6-Span/ class=md-nav__link> <span class=md-ellipsis> 6-Span </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_13> <label class=md-nav__link for=__nav_2_13 id=__nav_2_13_label tabindex=0> <span class=md-ellipsis> C++ Concurrency in Action </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_13_label aria-expanded=false> <label class=md-nav__title for=__nav_2_13> <span class="md-nav__icon md-icon"></span> C++ Concurrency in Action </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../notes/C%2B%2BConcurrency/1-thread/ class=md-nav__link> <span class=md-ellipsis> 1-Thread </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/C%2B%2BConcurrency/2-Memory%20Model/ class=md-nav__link> <span class=md-ellipsis> 2-Memory Model in C++ </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_14> <label class=md-nav__link for=__nav_2_14 id=__nav_2_14_label tabindex=0> <span class=md-ellipsis> CMU15445 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_14_label aria-expanded=false> <label class=md-nav__title for=__nav_2_14> <span class="md-nav__icon md-icon"></span> CMU15445 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../notes/CMU15445/3-Database%20Storage/ class=md-nav__link> <span class=md-ellipsis> 3-Database Storage </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/4-Database_Storage_II/ class=md-nav__link> <span class=md-ellipsis> 4-Database_Storage_II </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/5-Buffer%20Pool/ class=md-nav__link> <span class=md-ellipsis> 5-Buffer Pool </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/6-Hash%20Table/ class=md-nav__link> <span class=md-ellipsis> 6-Hash Table </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/7-B%2BTree/ class=md-nav__link> <span class=md-ellipsis> 7-B+Tree </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/8-Index%20Concurrency/ class=md-nav__link> <span class=md-ellipsis> 8-Index Concurrency </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/9-Sort%26Aggregation/ class=md-nav__link> <span class=md-ellipsis> 9-Sort&amp;Aggregation </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/10-Join%20Algorithm/ class=md-nav__link> <span class=md-ellipsis> 10-Join Algorithm </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/11-Query_Execution/ class=md-nav__link> <span class=md-ellipsis> 11-Query_Execution </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/12-Query_Plan%26Optimization/ class=md-nav__link> <span class=md-ellipsis> 12-Query_Plan&amp;Optimization </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/13-Concurrency_Control_Theory/ class=md-nav__link> <span class=md-ellipsis> 13-Concurrency_Control_Theory </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/14-Two_Phase_Lock/ class=md-nav__link> <span class=md-ellipsis> 14-Two_Phase_Lock </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/15-Timestamp_Ordering_Concurrency/ class=md-nav__link> <span class=md-ellipsis> 15-Timestamp_Ordering_Concurrency </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/16-Mult-Version_Concurrency/ class=md-nav__link> <span class=md-ellipsis> 16-Mult-Version_Concurrency </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/17-Database_Logging/ class=md-nav__link> <span class=md-ellipsis> 17-Database_Logging </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/18-Database_Recovery/ class=md-nav__link> <span class=md-ellipsis> 18-Database_Recovery </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/CMU15445/19-Introducd_to_distributed_database/ class=md-nav__link> <span class=md-ellipsis> 19-Introducd_to_distributed_database </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_15> <label class=md-nav__link for=__nav_2_15 id=__nav_2_15_label tabindex=0> <span class=md-ellipsis> 6.824 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_15_label aria-expanded=false> <label class=md-nav__title for=__nav_2_15> <span class="md-nav__icon md-icon"></span> 6.824 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../notes/6.824/MapReduce/ class=md-nav__link> <span class=md-ellipsis> MapReduce 论文阅读 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_16> <label class=md-nav__link for=__nav_2_16 id=__nav_2_16_label tabindex=0> <span class=md-ellipsis> Linux Tools </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_16_label aria-expanded=false> <label class=md-nav__title for=__nav_2_16> <span class="md-nav__icon md-icon"></span> Linux Tools </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../notes/linux%20tools/1-grep/ class=md-nav__link> <span class=md-ellipsis> grep </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/linux%20tools/2-sed/ class=md-nav__link> <span class=md-ellipsis> sed </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/linux%20tools/3-awk/ class=md-nav__link> <span class=md-ellipsis> awk </span> </a> </li> <li class=md-nav__item> <a href=../../../notes/linux%20tools/4-find/ class=md-nav__link> <span class=md-ellipsis> find </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../../../paperreadings/ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M384 512H96c-53 0-96-43-96-96V96C0 43 43 0 96 0h304c26.5 0 48 21.5 48 48v288c0 20.9-13.4 38.7-32 45.3V448c17.7 0 32 14.3 32 32s-14.3 32-32 32zM96 384c-17.7 0-32 14.3-32 32s14.3 32 32 32h256v-64zm32-232c0 13.3 10.7 24 24 24h176c13.3 0 24-10.7 24-24s-10.7-24-24-24H152c-13.3 0-24 10.7-24 24m24 72c-13.3 0-24 10.7-24 24s10.7 24 24 24h176c13.3 0 24-10.7 24-24s-10.7-24-24-24z"></path></svg> <span class=md-ellipsis> PaperReading </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> PaperReading </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> Database Systems </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Database Systems </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../paperreadings/db/storage/NoMMAP/ class=md-nav__link> <span class=md-ellipsis> Do not use MMAP in DBMS </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3> <label class=md-nav__link for=__nav_3_3 id=__nav_3_3_label tabindex=0> <span class=md-ellipsis> Vector Search </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> Vector Search </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../paperreadings/vector%20search/IQAN/ class=md-nav__link> <span class=md-ellipsis> IQAN </span> </a> </li> <li class=md-nav__item> <a href=../../../paperreadings/vector%20search/MIRAGE-ANNS/ class=md-nav__link> <span class=md-ellipsis> MIRAGE-ANNS </span> </a> </li> <li class=md-nav__item> <a href=../../../paperreadings/vector%20search/LSM-VEC/ class=md-nav__link> <span class=md-ellipsis> LSM-VEC </span> </a> </li> <li class=md-nav__item> <a href=../../../paperreadings/vector%20search/PANNS/ class=md-nav__link> <span class=md-ellipsis> PANNS </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_4> <label class=md-nav__link for=__nav_3_4 id=__nav_3_4_label tabindex=0> <span class=md-ellipsis> Active SLAM </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_4_label aria-expanded=false> <label class=md-nav__title for=__nav_3_4> <span class="md-nav__icon md-icon"></span> Active SLAM </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../paperreadings/activeslam/PL-VINS/ class=md-nav__link> <span class=md-ellipsis> PL-VINS </span> </a> </li> <li class=md-nav__item> <a href=../../../paperreadings/activeslam/3D%20Active%20Metric-Semantic%20SLAM/ class=md-nav__link> <span class=md-ellipsis> 3D Active Metric-Semantic SLAM </span> </a> </li> <li class=md-nav__item> <a href=../../../paperreadings/activeslam/Exploration%20with%20Global%20Consistency%20%20Using%20Real-Time%20Re-integration%20and%20Active%20Loop%20Closure/ class=md-nav__link> <span class=md-ellipsis> Exploration with Global Consistency Using Real-Time Re-integration and Active Loop Closure </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M224 24c0-13.3 10.7-24 24-24 145.8 0 264 118.2 264 264 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-119.3-96.7-216-216-216-13.3 0-24-10.7-24-24M80 96c26.5 0 48 21.5 48 48v224c0 26.5 21.5 48 48 48s48-21.5 48-48-21.5-48-48-48c-8.8 0-16-7.2-16-16v-64c0-8.8 7.2-16 16-16 79.5 0 144 64.5 144 144s-64.5 144-144 144S32 447.5 32 368V144c0-26.5 21.5-48 48-48m168 0c92.8 0 168 75.2 168 168 0 13.3-10.7 24-24 24s-24-10.7-24-24c0-66.3-53.7-120-120-120-13.3 0-24-10.7-24-24s10.7-24 24-24"></path></svg> <span class=md-ellipsis> Blogs </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Blogs </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex=0> <span class=md-ellipsis> SGLang 专题 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> SGLang 专题 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../SGLang%20Scheduler%20%E6%8A%80%E6%9C%AF%E5%8F%98%E8%BF%81/ class=md-nav__link> <span class=md-ellipsis> SGLang Schedular 技术变迁 </span> </a> </li> <li class=md-nav__item> <a href=../DP%20Attention/ class=md-nav__link> <span class=md-ellipsis> DP Attention </span> </a> </li> <li class=md-nav__item> <a href=../SGLang%20%E7%9A%84%20KV%20Cache/ class=md-nav__link> <span class=md-ellipsis> SGLang 的 Cache 设计 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../PageAttention/ class=md-nav__link> <span class=md-ellipsis> PageAttention </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Vector Add Optimization Example </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Vector Add Optimization Example </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#prerequisite class=md-nav__link> <span class=md-ellipsis> Prerequisite </span> </a> <nav class=md-nav aria-label=Prerequisite> <ul class=md-nav__list> <li class=md-nav__item> <a href=#arithmetic-intensityai class=md-nav__link> <span class=md-ellipsis> Arithmetic Intensity(AI) </span> </a> </li> <li class=md-nav__item> <a href=#roofline class=md-nav__link> <span class=md-ellipsis> Roofline </span> </a> </li> <li class=md-nav__item> <a href=#stall-in-ncu class=md-nav__link> <span class=md-ellipsis> Stall in NCU </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#baseline class=md-nav__link> <span class=md-ellipsis> baseline </span> </a> <nav class=md-nav aria-label=baseline> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> 分析 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#optimization-v1-vectorized-access class=md-nav__link> <span class=md-ellipsis> Optimization V1 -- vectorized access </span> </a> <nav class=md-nav aria-label="Optimization V1 -- vectorized access"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 优化 </span> </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 分析 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#optimization-v2-fp16-compute class=md-nav__link> <span class=md-ellipsis> Optimization V2 -- fp16 compute </span> </a> <nav class=md-nav aria-label="Optimization V2 -- fp16 compute"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 优化 </span> </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> 分析 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#optimization-v3-fp16-more-compute-per-thread class=md-nav__link> <span class=md-ellipsis> Optimization V3 -- fp16 + more compute per thread </span> </a> <nav class=md-nav aria-label="Optimization V3 -- fp16 + more compute per thread"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_6 class=md-nav__link> <span class=md-ellipsis> 优化 </span> </a> </li> <li class=md-nav__item> <a href=#_7 class=md-nav__link> <span class=md-ellipsis> 分析 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#optimization-v4-fp16-more-compute-per-thread-memory-alignment class=md-nav__link> <span class=md-ellipsis> Optimization V4 -- fp16 + more compute per thread + memory alignment </span> </a> <nav class=md-nav aria-label="Optimization V4 -- fp16 + more compute per thread + memory alignment"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_8 class=md-nav__link> <span class=md-ellipsis> 优化 </span> </a> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> 分析 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> <nav class=md-nav aria-label=Summary> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-vs-kernel-launch-overhead class=md-nav__link> <span class=md-ellipsis> 洞察 1：问题规模 vs. 启动开销 (Kernel Launch Overhead) </span> </a> </li> <li class=md-nav__item> <a href=#2-memory-bound class=md-nav__link> <span class=md-ellipsis> 洞察 2：内存带宽是瓶颈 (Memory-Bound) </span> </a> </li> <li class=md-nav__item> <a href=#3baseline class=md-nav__link> <span class=md-ellipsis> 洞察 3：baseline 实现在较小的问题规模下已足够好 </span> </a> </li> <li class=md-nav__item> <a href=#41m-fp16-x2 class=md-nav__link> <span class=md-ellipsis> 洞察 4：1M 数据测试下 FP16 x2 是最佳的 "工作粒度" </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_10 class=md-nav__link> <span class=md-ellipsis> 附录 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../%E4%B8%8A%E7%AF%87%EF%BC%9A%E5%88%9D%E8%AF%86%20Nebula%20Graph%20%E2%80%94%E2%80%94%20%E5%90%91%E9%87%8F%E7%B1%BB%E5%9E%8B%E6%94%AF%E6%8C%81/ class=md-nav__link> <span class=md-ellipsis> 上篇：初识 Nebula Graph —— 向量类型支持 </span> </a> </li> <li class=md-nav__item> <a href=../bision%20debug/ class=md-nav__link> <span class=md-ellipsis> bision debug </span> </a> </li> <li class=md-nav__item> <a href=../C%2B%2B%E5%BC%82%E6%AD%A5%E6%96%B9%E6%A1%88/ class=md-nav__link> <span class=md-ellipsis> C++ 异步方案演进 </span> </a> </li> <li class=md-nav__item> <a href=../bustub%E9%80%9A%E5%85%B3%E6%8C%87%E5%8C%97/ class=md-nav__link> <span class=md-ellipsis> Bustub 通关指北 </span> </a> </li> <li class=md-nav__item> <a href=../Implement%20of%20Concurrent/ class=md-nav__link> <span class=md-ellipsis> 并发组件实现浅析 </span> </a> </li> <li class=md-nav__item> <a href=../CS144/ class=md-nav__link> <span class=md-ellipsis> 实现一个TCP </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <div class="md-nav__link md-nav__container"> <a href=../../../summary/ class="md-nav__link "> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1zM5 8v11h14V8zm2 2h10v2H7z"></path></svg> <span class=md-ellipsis> Summaries </span> </a> <label class="md-nav__link " for=__nav_5 id=__nav_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Summaries </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_2> <label class=md-nav__link for=__nav_5_2 id=__nav_5_2_label tabindex=0> <span class=md-ellipsis> plan </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_2_label aria-expanded=false> <label class=md-nav__title for=__nav_5_2> <span class="md-nav__icon md-icon"></span> plan </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../summary/2025/semester-plan/ class=md-nav__link> <span class=md-ellipsis> 研一下规划 </span> </a> </li> <li class=md-nav__item> <a href=../../../summary/2025/LLM%20%E6%8E%A8%E7%90%86%E7%B3%BB%E7%BB%9F%E6%8A%80%E8%83%BD%E5%9B%BE%E8%B0%B1/ class=md-nav__link> <span class=md-ellipsis> 大模型技能掌握 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_3> <label class=md-nav__link for=__nav_5_3 id=__nav_5_3_label tabindex=0> <span class=md-ellipsis> 研究生总结 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_3_label aria-expanded=false> <label class=md-nav__title for=__nav_5_3> <span class="md-nav__icon md-icon"></span> 研究生总结 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../summary/%E7%A0%94%E7%A9%B6%E7%94%9F%E6%80%BB%E7%BB%93/%E7%A0%94%E4%B8%80%E4%B8%8A%E6%80%BB%E7%BB%93/ class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1zM5 8v11h14V8zm2 2h10v2H7z"></path></svg> <span class=md-ellipsis> 研一上总结 </span> </a> </li> <li class=md-nav__item> <a href=../../../summary/%E7%A0%94%E7%A9%B6%E7%94%9F%E6%80%BB%E7%BB%93/%E7%A0%94%E4%B8%80%E4%B8%8B%E6%80%BB%E7%BB%93/ class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1zM5 8v11h14V8zm2 2h10v2H7z"></path></svg> <span class=md-ellipsis> 研一下总结 </span> </a> </li> <li class=md-nav__item> <a href=../../../summary/%E7%A0%94%E7%A9%B6%E7%94%9F%E6%80%BB%E7%BB%93/%E7%A0%94%E4%BA%8C%E4%B8%8A%E6%80%BB%E7%BB%93/ class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M6 1h2v2h8V1h2v2h1a2 2 0 0 1 2 2v14c0 1.11-.89 2-2 2H5a2 2 0 0 1-2-2V5c0-1.11.89-2 2-2h1zM5 8v11h14V8zm2 2h10v2H7z"></path></svg> <span class=md-ellipsis> 研二上总结 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../tags/ class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M5.5 7A1.5 1.5 0 0 1 4 5.5 1.5 1.5 0 0 1 5.5 4 1.5 1.5 0 0 1 7 5.5 1.5 1.5 0 0 1 5.5 7m15.91 4.58-9-9C12.05 2.22 11.55 2 11 2H4c-1.11 0-2 .89-2 2v7c0 .55.22 1.05.59 1.41l8.99 9c.37.36.87.59 1.42.59s1.05-.23 1.41-.59l7-7c.37-.36.59-.86.59-1.41 0-.56-.23-1.06-.59-1.42"></path></svg> <span class=md-ellipsis> Tags </span> </a> </li> <li class=md-nav__item> <a href=../../../links/ class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.78 3.653a3.936 3.936 0 1 1 5.567 5.567l-3.627 3.627a3.936 3.936 0 0 1-5.88-.353.75.75 0 0 0-1.18.928 5.436 5.436 0 0 0 8.12.486l3.628-3.628a5.436 5.436 0 1 0-7.688-7.688l-3 3a.75.75 0 0 0 1.06 1.061z"></path><path d="M7.28 11.153a3.936 3.936 0 0 1 5.88.353.75.75 0 0 0 1.18-.928 5.436 5.436 0 0 0-8.12-.486L2.592 13.72a5.436 5.436 0 1 0 7.688 7.688l3-3a.75.75 0 1 0-1.06-1.06l-3 3a3.936 3.936 0 0 1-5.567-5.568z"></path></svg> <span class=md-ellipsis> Links </span> </a> </li> <li class=md-nav__item> <a href=../../../about/ class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M256 512a256 256 0 1 0 0-512 256 256 0 1 0 0 512m-90.6-190.1c20.4 28 53.4 46.1 90.6 46.1s70.2-18.1 90.6-46.1c7.8-10.7 22.8-13.1 33.5-5.3s13.1 22.8 5.3 33.5C356.3 390 309.2 416 256 416s-100.3-26-129.4-65.9c-7.8-10.7-5.4-25.7 5.3-33.5s25.7-5.4 33.5 5.3M144 208a32 32 0 1 1 64 0 32 32 0 1 1-64 0m164 8c0 11-9 20-20 20s-20-9-20-20c0-33.1 26.9-60 60-60h16c33.1 0 60 26.9 60 60 0 11-9 20-20 20s-20-9-20-20-9-20-20-20h-16c-11 0-20 9-20 20"></path></svg> <span class=md-ellipsis> About </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#prerequisite class=md-nav__link> <span class=md-ellipsis> Prerequisite </span> </a> <nav class=md-nav aria-label=Prerequisite> <ul class=md-nav__list> <li class=md-nav__item> <a href=#arithmetic-intensityai class=md-nav__link> <span class=md-ellipsis> Arithmetic Intensity(AI) </span> </a> </li> <li class=md-nav__item> <a href=#roofline class=md-nav__link> <span class=md-ellipsis> Roofline </span> </a> </li> <li class=md-nav__item> <a href=#stall-in-ncu class=md-nav__link> <span class=md-ellipsis> Stall in NCU </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#baseline class=md-nav__link> <span class=md-ellipsis> baseline </span> </a> <nav class=md-nav aria-label=baseline> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> 分析 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#optimization-v1-vectorized-access class=md-nav__link> <span class=md-ellipsis> Optimization V1 -- vectorized access </span> </a> <nav class=md-nav aria-label="Optimization V1 -- vectorized access"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 优化 </span> </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 分析 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#optimization-v2-fp16-compute class=md-nav__link> <span class=md-ellipsis> Optimization V2 -- fp16 compute </span> </a> <nav class=md-nav aria-label="Optimization V2 -- fp16 compute"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 优化 </span> </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> 分析 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#optimization-v3-fp16-more-compute-per-thread class=md-nav__link> <span class=md-ellipsis> Optimization V3 -- fp16 + more compute per thread </span> </a> <nav class=md-nav aria-label="Optimization V3 -- fp16 + more compute per thread"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_6 class=md-nav__link> <span class=md-ellipsis> 优化 </span> </a> </li> <li class=md-nav__item> <a href=#_7 class=md-nav__link> <span class=md-ellipsis> 分析 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#optimization-v4-fp16-more-compute-per-thread-memory-alignment class=md-nav__link> <span class=md-ellipsis> Optimization V4 -- fp16 + more compute per thread + memory alignment </span> </a> <nav class=md-nav aria-label="Optimization V4 -- fp16 + more compute per thread + memory alignment"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_8 class=md-nav__link> <span class=md-ellipsis> 优化 </span> </a> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> 分析 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> <nav class=md-nav aria-label=Summary> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-vs-kernel-launch-overhead class=md-nav__link> <span class=md-ellipsis> 洞察 1：问题规模 vs. 启动开销 (Kernel Launch Overhead) </span> </a> </li> <li class=md-nav__item> <a href=#2-memory-bound class=md-nav__link> <span class=md-ellipsis> 洞察 2：内存带宽是瓶颈 (Memory-Bound) </span> </a> </li> <li class=md-nav__item> <a href=#3baseline class=md-nav__link> <span class=md-ellipsis> 洞察 3：baseline 实现在较小的问题规模下已足够好 </span> </a> </li> <li class=md-nav__item> <a href=#41m-fp16-x2 class=md-nav__link> <span class=md-ellipsis> 洞察 4：1M 数据测试下 FP16 x2 是最佳的 "工作粒度" </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_10 class=md-nav__link> <span class=md-ellipsis> 附录 </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <div class=md-typeset> <div class=blogging-tags-grid> <a href=https://tom-jerr.github.io/tags#LLMInference class=blogging-tag><code>#LLMInference</code></a> </div> </div> <style>
    .md-typeset .blogging-tags-grid {
        display: flex;
        flex-direction: row;
        flex-wrap: wrap;
        gap: 8px;
        margin-top: 5px;
    }

    .md-typeset .blogging-tag {
        color: var(--md-typeset-color);
        background-color: var(--md-typeset-code-color);
        white-space: nowrap;
        display: block;
    }

    .md-typeset .blogging-tag code {
        border-radius: 5px;
    }
</style> <h1 id=cuda-vector-add>一步步实现 CUDA Vector Add 优化<a class=headerlink href=#cuda-vector-add title="Permanent link">¶</a></h1> <p>📚 本文将从最基础的 vector add 实现开始，使用 nsight compute 工具进行性能分析寻找瓶颈并一步步进行优化。通过这种方式来学习 CUDA 的编程和优化。</p> <h2 id=prerequisite>Prerequisite<a class=headerlink href=#prerequisite title="Permanent link">¶</a></h2> <h3 id=arithmetic-intensityai>Arithmetic Intensity(AI)<a class=headerlink href=#arithmetic-intensityai title="Permanent link">¶</a></h3> <p>算术强度是衡量一个计算任务（如 CUDA Kernel）是“计算密集型”还是“访存密集型”的核心指标。</p> <p><strong>1. 定义：</strong> 它被定义为“总共执行的浮点计算操作次数”与“总共传输的数据字节数”之间的比率。</p> <ul> <li><strong><code>AI = (总计算操作数) / (总访存字节数)</code></strong></li> <li><strong>单位：</strong> <code>FLOPs/Byte</code> (即，每传输一个字节的数据，能对应执行多少次浮点计算)</li> </ul> <p><strong>2. 为什么它如此重要？</strong> AI 决定了一个程序<strong>理论上的性能瓶颈</strong>。我们可以用它来对比一个程序和一个硬件（GPU）的特性：</p> <ul> <li><strong>硬件的“AI”</strong>：GPU 也有一个平衡点，即它的 <code>峰值计算能力 (GFLOPs/s)</code> / `峰值内存带宽 (GB/s)</li> <li><strong>程序的 AI</strong>：内核的 <code>FLOPs / Bytes</code>。</li> </ul> <h3 id=roofline>Roofline<a class=headerlink href=#roofline title="Permanent link">¶</a></h3> <p>Roofline 模型（屋顶线模型）是一种用来<strong>分析程序性能瓶颈</strong>（计算受限还是带宽受限）的方法。<br> 它把<strong>计算性能</strong>（FLOPs/s）和<strong>访存性能</strong>（Bytes/s）联系在一起，。以可视化的方式展示性能上限</p> <div class=arithmatex>\[ Achievable&nbsp;FLOPs=min(AI×Memory&nbsp;BW,Peak&nbsp;FLOPs) \]</div> <p><a class=glightbox data-type=image data-width=80% data-height=auto href=../img/roofline.png data-desc-position=bottom><img alt src=../img/roofline.png></a></p> <h3 id=stall-in-ncu>Stall in NCU<a class=headerlink href=#stall-in-ncu title="Permanent link">¶</a></h3> <table> <thead> <tr> <th>类型</th> <th>代表等待</th> <th>典型瓶颈</th> <th>优化方向</th> </tr> </thead> <tbody> <tr> <td><strong>All Scoreboard</strong></td> <td>所有依赖未满足</td> <td>完全等待</td> <td>提高并发、异步访问</td> </tr> <tr> <td><strong>Long Scoreboard</strong></td> <td>DRAM 访问未返回</td> <td>内存延迟</td> <td>优化访存、共享内存</td> </tr> <tr> <td><strong>Short Scoreboard</strong></td> <td>L1/寄存器依赖</td> <td>数据依赖</td> <td>调整指令顺序</td> </tr> <tr> <td><strong>Execution Dependency</strong></td> <td>算术指令结果未就绪</td> <td>运算链长</td> <td>增加 ILP</td> </tr> <tr> <td><strong>Barrier/Branch</strong></td> <td>同步或分支等待</td> <td>控制流</td> <td>减少分支/同步</td> </tr> </tbody> </table> <h2 id=baseline>baseline<a class=headerlink href=#baseline title="Permanent link">¶</a></h2> <div class="language-cpp highlight"><span class=filename>C++</span><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1></a><a href=#__codelineno-0-1><span class=linenos data-linenos=" 1 "></span></a><span class=c1>// FP32</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2></a><a href=#__codelineno-0-2><span class=linenos data-linenos=" 2 "></span></a><span class=c1>// ElementWise Add grid(N/256),</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3></a><a href=#__codelineno-0-3><span class=linenos data-linenos=" 3 "></span></a><span class=c1>// block(256) a: Nx1, b: Nx1, c: Nx1, c = elementwise_add(a, b)</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4></a><a href=#__codelineno-0-4><span class=linenos data-linenos=" 4 "></span></a><span class=n>__global__</span><span class=w> </span><span class=kt>void</span><span class=w> </span><span class=n>vector_add_kernel</span><span class=p>(</span><span class=k>const</span><span class=w> </span><span class=kt>float</span><span class=w> </span><span class=o>*</span><span class=n>a</span><span class=p>,</span><span class=w> </span><span class=k>const</span><span class=w> </span><span class=kt>float</span><span class=w> </span><span class=o>*</span><span class=n>b</span><span class=p>,</span><span class=w> </span><span class=kt>float</span><span class=w> </span><span class=o>*</span><span class=n>c</span><span class=p>,</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5></a><a href=#__codelineno-0-5><span class=linenos data-linenos=" 5 "></span></a><span class=w>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class=kt>int</span><span class=w> </span><span class=n>n</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6></a><a href=#__codelineno-0-6><span class=linenos data-linenos=" 6 "></span></a><span class=w>&nbsp; </span><span class=kt>int</span><span class=w> </span><span class=n>idx</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7></a><a href=#__codelineno-0-7><span class=linenos data-linenos=" 7 "></span></a><span class=w>&nbsp; </span><span class=k>if</span><span class=w> </span><span class=p>(</span><span class=n>idx</span><span class=w> </span><span class=o>&lt;</span><span class=w> </span><span class=n>n</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8></a><a href=#__codelineno-0-8><span class=linenos data-linenos=" 8 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>c</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>a</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>b</span><span class=p>[</span><span class=n>idx</span><span class=p>];</span>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9></a><a href=#__codelineno-0-9><span class=linenos data-linenos=" 9 "></span></a><span class=w>&nbsp; </span><span class=p>}</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10></a><a href=#__codelineno-0-10><span class=linenos data-linenos="10 "></span></a><span class=p>}</span>
</span></code></pre></div> <h3 id=_1>分析<a class=headerlink href=#_1 title="Permanent link">¶</a></h3> <p>该版本的 vector add，执行一次计算需要三次访存，每次读 4 bytes (read A, read B, write C)</p> <div class=arithmatex>\[ AI = 1 / (3 \times 4) =1/12\approx 0.083 \]</div> <p>说明这是一个 <strong>memory-bound</strong> 的程序</p> <ul> <li>查看 ncu 的 SLO 我们可以看到，确实内存达到峰值性能的 90% 以上</li> </ul> <p><a class=glightbox data-type=image data-width=80% data-height=auto href=../img/vector_add_slo.png data-desc-position=bottom><img alt src=../img/vector_add_slo.png></a></p> <ul> <li>查看 Memory Workload Analysis，我们可以发现我们完全没有用到 shared memory，直接用 L2 Cache 和 L1 Cache</li> </ul> <p><a class=glightbox data-type=image data-width=80% data-height=auto href=../img/memory_chat.png data-desc-position=bottom><img alt src=../img/memory_chat.png></a></p> <ul> <li>Kernel 的主要瓶颈是 <strong><code>Stall Long Scoreboard</code></strong>——即<strong>内存延迟停顿</strong>。GPU 隐藏这种“等待”的唯一机制，就是 <strong>Occupancy (占用率)</strong></li> </ul> <h2 id=optimization-v1-vectorized-access>Optimization V1 -- vectorized access<a class=headerlink href=#optimization-v1-vectorized-access title="Permanent link">¶</a></h2> <h3 id=_2>优化<a class=headerlink href=#_2 title="Permanent link">¶</a></h3> <ul> <li>矢量化内存访问：我们不再一次读取一个 float，而是同时取 4 个 float，<strong>一个 wrap 里面的所有线程同时获取 4 float，可以变为 LDG.128 一次性获取 128 bit 数据</strong></li> <li>⚠ 这里有个 trade-off，如果我们每个 thread 使用了过多的寄存器，那么 SM 上活跃的 Warp 会变少，导致 Occupany 会下降，这同样对性能影响很大</li> </ul> <div class="language-cpp highlight"><span class=filename>C++</span><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1></a><a href=#__codelineno-1-1><span class=linenos data-linenos=" 1 "></span></a><span class=c1>// ElementWise Add + Vec4</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2></a><a href=#__codelineno-1-2><span class=linenos data-linenos=" 2 "></span></a><span class=c1>// grid(N/256), block(256/4)</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3></a><a href=#__codelineno-1-3><span class=linenos data-linenos=" 3 "></span></a><span class=c1>// a: Nx1, b: Nx1, c: Nx1, c = elementwise_add(a, b)</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4></a><a href=#__codelineno-1-4><span class=linenos data-linenos=" 4 "></span></a><span class=n>__global__</span><span class=w> </span><span class=kt>void</span><span class=w> </span><span class=n>vector_add_kernel_vec4</span><span class=p>(</span><span class=k>const</span><span class=w> </span><span class=kt>float</span><span class=w> </span><span class=o>*</span><span class=n>a</span><span class=p>,</span><span class=w> </span><span class=k>const</span><span class=w> </span><span class=kt>float</span><span class=w> </span><span class=o>*</span><span class=n>b</span><span class=p>,</span><span class=w> </span><span class=kt>float</span><span class=w> </span><span class=o>*</span><span class=n>c</span><span class=p>,</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5></a><a href=#__codelineno-1-5><span class=linenos data-linenos=" 5 "></span></a><span class=w>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span><span class=kt>int</span><span class=w> </span><span class=n>n</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6></a><a href=#__codelineno-1-6><span class=linenos data-linenos=" 6 "></span></a><span class=w>&nbsp; </span><span class=kt>int</span><span class=w> </span><span class=n>idx</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=p>(</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>)</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>4</span><span class=p>;</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7></a><a href=#__codelineno-1-7><span class=linenos data-linenos=" 7 "></span></a><span class=w>&nbsp; </span><span class=k>if</span><span class=w> </span><span class=p>(</span><span class=n>idx</span><span class=w> </span><span class=o>&lt;</span><span class=w> </span><span class=n>n</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8></a><a href=#__codelineno-1-8><span class=linenos data-linenos=" 8 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>float4</span><span class=w> </span><span class=n>a_vec</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>FLOAT4</span><span class=p>(</span><span class=n>a</span><span class=p>);</span><span class=w> </span><span class=c1>// registers</span>
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9></a><a href=#__codelineno-1-9><span class=linenos data-linenos=" 9 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>float4</span><span class=w> </span><span class=n>b_vec</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>FLOAT4</span><span class=p>(</span><span class=n>b</span><span class=p>);</span>
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10></a><a href=#__codelineno-1-10><span class=linenos data-linenos="10 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>float4</span><span class=w> </span><span class=n>c_vec</span><span class=p>;</span>
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11></a><a href=#__codelineno-1-11><span class=linenos data-linenos="11 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>c_vec</span><span class=p>.</span><span class=n>x</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>a_vec</span><span class=p>.</span><span class=n>x</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>b_vec</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12></a><a href=#__codelineno-1-12><span class=linenos data-linenos="12 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>c_vec</span><span class=p>.</span><span class=n>y</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>a_vec</span><span class=p>.</span><span class=n>y</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>b_vec</span><span class=p>.</span><span class=n>y</span><span class=p>;</span>
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13></a><a href=#__codelineno-1-13><span class=linenos data-linenos="13 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>c_vec</span><span class=p>.</span><span class=n>z</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>a_vec</span><span class=p>.</span><span class=n>z</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>b_vec</span><span class=p>.</span><span class=n>z</span><span class=p>;</span>
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14></a><a href=#__codelineno-1-14><span class=linenos data-linenos="14 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>c_vec</span><span class=p>.</span><span class=n>w</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>a_vec</span><span class=p>.</span><span class=n>w</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>b_vec</span><span class=p>.</span><span class=n>w</span><span class=p>;</span>
</span><span id=__span-1-15><a id=__codelineno-1-15 name=__codelineno-1-15></a><a href=#__codelineno-1-15><span class=linenos data-linenos="15 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>FLOAT4</span><span class=p>(</span><span class=n>c</span><span class=p>[</span><span class=n>idx</span><span class=p>])</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>c_vec</span><span class=p>;</span>
</span><span id=__span-1-16><a id=__codelineno-1-16 name=__codelineno-1-16></a><a href=#__codelineno-1-16><span class=linenos data-linenos="16 "></span></a><span class=w>&nbsp; </span><span class=p>}</span>
</span><span id=__span-1-17><a id=__codelineno-1-17 name=__codelineno-1-17></a><a href=#__codelineno-1-17><span class=linenos data-linenos="17 "></span></a><span class=p>}</span>
</span></code></pre></div> <h3 id=_3>分析<a class=headerlink href=#_3 title="Permanent link">¶</a></h3> <ul> <li> <p>通过这种优化后，我们已经将内存合并访问，Memory 的效率已经提升了，但是 Compute 效率还是很低</p> </li> <li> <p><strong>时间几乎相同</strong>：21.66 μs → 21.25 μs。</p> </li> <li> <p><strong>内存带宽利用率都高 (~96%)</strong>：说明两者都被 <strong>memory-bound</strong> 限制，而非算力瓶颈。</p> </li> <li> <p><strong>Compute Throughput</strong> 反而下降（14% → 3.6%），因为相同的数据量下，<code>float4</code> 版本需要更少的指令，因此算术部分相对占比变小。</p> </li> <li> <p>：向量化访问 (<code>float4</code>) 优化了访存效率（一次读取 4 个 float），<strong>但总内存带宽已接近饱和，所以性能提升有限。</strong></p> </li> </ul> <p><a class=glightbox data-type=image data-width=80% data-height=auto href=../img/slo_v1.png data-desc-position=bottom><img alt src=../img/slo_v1.png></a></p> <h2 id=optimization-v2-fp16-compute>Optimization V2 -- fp16 compute<a class=headerlink href=#optimization-v2-fp16-compute title="Permanent link">¶</a></h2> <h3 id=_4>优化<a class=headerlink href=#_4 title="Permanent link">¶</a></h3> <ul> <li>在 30 系及以上显卡，对 fp16 和 fp32 的计算几乎无差别，都使用相同的 ALU 进行计算，但是 fp16 每次存取比 fp32 少一般的内存，所以<strong>可以节省内存带宽</strong>，从而大幅提高效率</li> <li>FP16 计算：我们使用的是 RTX Titan，该显卡 fp16 的计算 FLOPS 是 fp32 的 2 倍左右</li> </ul> <div class="language-cpp highlight"><span class=filename>C++</span><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1></a><a href=#__codelineno-2-1><span class=linenos data-linenos="1 "></span></a><span class=c1>// FP16</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2></a><a href=#__codelineno-2-2><span class=linenos data-linenos="2 "></span></a><span class=c1>// ElementWise Add grid(N/256),</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3></a><a href=#__codelineno-2-3><span class=linenos data-linenos="3 "></span></a><span class=c1>// block(256) a: Nx1, b: Nx1, c: Nx1, c = elementwise_add(a, b)</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4></a><a href=#__codelineno-2-4><span class=linenos data-linenos="4 "></span></a><span class=n>__global__</span><span class=w> </span><span class=kt>void</span><span class=w> </span><span class=n>elementwise_add_f16_kernel</span><span class=p>(</span><span class=n>half</span><span class=w> </span><span class=o>*</span><span class=n>a</span><span class=p>,</span><span class=w> </span><span class=n>half</span><span class=w> </span><span class=o>*</span><span class=n>b</span><span class=p>,</span><span class=w> </span><span class=n>half</span><span class=w> </span><span class=o>*</span><span class=n>c</span><span class=p>,</span><span class=w> </span><span class=kt>int</span><span class=w> </span><span class=n>N</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5></a><a href=#__codelineno-2-5><span class=linenos data-linenos="5 "></span></a><span class=w>&nbsp; </span><span class=kt>int</span><span class=w> </span><span class=n>idx</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6></a><a href=#__codelineno-2-6><span class=linenos data-linenos="6 "></span></a><span class=w>&nbsp; </span><span class=k>if</span><span class=w> </span><span class=p>(</span><span class=n>idx</span><span class=w> </span><span class=o>&lt;</span><span class=w> </span><span class=n>N</span><span class=p>)</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7></a><a href=#__codelineno-2-7><span class=linenos data-linenos="7 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>c</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>__hadd</span><span class=p>(</span><span class=n>a</span><span class=p>[</span><span class=n>idx</span><span class=p>],</span><span class=w> </span><span class=n>b</span><span class=p>[</span><span class=n>idx</span><span class=p>]);</span>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8></a><a href=#__codelineno-2-8><span class=linenos data-linenos="8 "></span></a><span class=p>}</span>
</span></code></pre></div> <h3 id=_5>分析<a class=headerlink href=#_5 title="Permanent link">¶</a></h3> <div class=arithmatex>\[ AI = \frac{1 FLOPs}{2 * 3 Bytes} = 1/6 \approx 0.17 FLOPs /Byte \]</div> <p>⚠ <strong>fp16 计算的精度会比 fp32 低很多</strong>，需要考虑应用的场景是否可以接受，测试发现基本精度在 0.2 以下</p> <ul> <li><strong>Memory Throughput 下降 (96%→71%)</strong>：FP16 数据量只有 float 的一半，显存传输压力小。</li> <li><strong>Compute Throughput 上升 (14%→22%)</strong>：虽然数据变小，但 ALU 对 FP16 处理更快（部分架构可双发射或更高密度处理）。</li> </ul> <h2 id=optimization-v3-fp16-more-compute-per-thread>Optimization V3 -- fp16 + more compute per thread<a class=headerlink href=#optimization-v3-fp16-more-compute-per-thread title="Permanent link">¶</a></h2> <h3 id=_6>优化<a class=headerlink href=#_6 title="Permanent link">¶</a></h3> <ul> <li><code>half2</code> 双打包一次访问两倍数据量</li> <li>节省了内存带宽</li> <li>摊销算术成本</li> </ul> <div class="language-cpp highlight"><span class=filename>C++</span><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1></a><a href=#__codelineno-3-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>__global__</span><span class=w> </span><span class=kt>void</span><span class=w> </span><span class=n>elementwise_add_f16x2_kernel</span><span class=p>(</span><span class=n>half</span><span class=w> </span><span class=o>*</span><span class=n>a</span><span class=p>,</span><span class=w> </span><span class=n>half</span><span class=w> </span><span class=o>*</span><span class=n>b</span><span class=p>,</span><span class=w> </span><span class=n>half</span><span class=w> </span><span class=o>*</span><span class=n>c</span><span class=p>,</span><span class=w> </span><span class=kt>int</span><span class=w> </span><span class=n>N</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2></a><a href=#__codelineno-3-2><span class=linenos data-linenos=" 2 "></span></a><span class=w>&nbsp; </span><span class=kt>int</span><span class=w> </span><span class=n>idx</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>2</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=p>(</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>);</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3></a><a href=#__codelineno-3-3><span class=linenos data-linenos=" 3 "></span></a><span class=w>&nbsp; </span><span class=k>if</span><span class=w> </span><span class=p>(</span><span class=n>idx</span><span class=w> </span><span class=o>&lt;</span><span class=w> </span><span class=n>N</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4></a><a href=#__codelineno-3-4><span class=linenos data-linenos=" 4 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>half2</span><span class=w> </span><span class=n>reg_a</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>HALF2</span><span class=p>(</span><span class=n>a</span><span class=p>[</span><span class=n>idx</span><span class=p>]);</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5></a><a href=#__codelineno-3-5><span class=linenos data-linenos=" 5 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>half2</span><span class=w> </span><span class=n>reg_b</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>HALF2</span><span class=p>(</span><span class=n>b</span><span class=p>[</span><span class=n>idx</span><span class=p>]);</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6></a><a href=#__codelineno-3-6><span class=linenos data-linenos=" 6 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>half2</span><span class=w> </span><span class=n>reg_c</span><span class=p>;</span>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7></a><a href=#__codelineno-3-7><span class=linenos data-linenos=" 7 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>reg_c</span><span class=p>.</span><span class=n>x</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>__hadd</span><span class=p>(</span><span class=n>reg_a</span><span class=p>.</span><span class=n>x</span><span class=p>,</span><span class=w> </span><span class=n>reg_b</span><span class=p>.</span><span class=n>x</span><span class=p>);</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8></a><a href=#__codelineno-3-8><span class=linenos data-linenos=" 8 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>reg_c</span><span class=p>.</span><span class=n>y</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>__hadd</span><span class=p>(</span><span class=n>reg_a</span><span class=p>.</span><span class=n>y</span><span class=p>,</span><span class=w> </span><span class=n>reg_b</span><span class=p>.</span><span class=n>y</span><span class=p>);</span>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9></a><a href=#__codelineno-3-9><span class=linenos data-linenos=" 9 "></span></a><span class=w>&nbsp; &nbsp; </span><span class=n>HALF2</span><span class=p>(</span><span class=n>c</span><span class=p>[</span><span class=n>idx</span><span class=p>])</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>reg_c</span><span class=p>;</span>
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10></a><a href=#__codelineno-3-10><span class=linenos data-linenos="10 "></span></a><span class=w>&nbsp; </span><span class=p>}</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11></a><a href=#__codelineno-3-11><span class=linenos data-linenos="11 "></span></a><span class=p>}</span>
</span></code></pre></div> <h3 id=_7>分析<a class=headerlink href=#_7 title="Permanent link">¶</a></h3> <div class=arithmatex>\[ AI = \frac{2*(\_hadd) FLOPs}{4 * 3 Bytes} = 1/6 \approx 0.17 FLOPs /Byte \]</div> <ul> <li><strong>执行时间继续下降</strong>：13.41 μs → 11.17 μs</li> <li><strong>Memory Throughput 恢复上升 (71%→87%)</strong>：<code>half2</code> 双打包一次访问两倍数据量，访问效率提升。</li> <li><strong>Compute Throughput 略降 (22%→14%)</strong>：算术负载被摊薄（计算量少，但访存更快）。</li> </ul> <h2 id=optimization-v4-fp16-more-compute-per-thread-memory-alignment>Optimization V4 -- fp16 + more compute per thread + memory alignment<a class=headerlink href=#optimization-v4-fp16-more-compute-per-thread-memory-alignment title="Permanent link">¶</a></h2> <h3 id=_8>优化<a class=headerlink href=#_8 title="Permanent link">¶</a></h3> <ul> <li>内存对齐 128 bit，可以矢量化访问内存，减少指令数</li> <li>每个线程一次处理 8 个 half（即 4 次 <code>__hadd2</code>），加上 <code>#pragma unroll</code> → 展开循环，避免分支开销</li> </ul> <table> <thead> <tr> <th>优化维度</th> <th>普通版本（__hadd）</th> <th>优化版（__hadd2 + pack）</th> <th>性能效果</th> </tr> </thead> <tbody> <tr> <td><strong>计算模式</strong></td> <td>每次算 1 个 half</td> <td>每次算 2 个 half</td> <td>✅ 计算吞吐提升约 2×</td> </tr> <tr> <td><strong>寄存器利用率</strong></td> <td>较分散，指令依赖多</td> <td>更连续，指令复用率高</td> <td>✅ 提高 ILP、减少 stall</td> </tr> <tr> <td><strong>warp 效率</strong></td> <td>访存指令多，warp 常等待</td> <td>warp 内访存对齐一致</td> <td>✅ warp active cycles 更高</td> </tr> </tbody> </table> <div class="language-cpp highlight"><span class=filename>C++</span><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1></a><a href=#__codelineno-4-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>__global__</span><span class=w> </span><span class=kt>void</span><span class=w> </span><span class=n>elementwise_add_f16x8_pack_kernel</span><span class=p>(</span><span class=n>half</span><span class=w> </span><span class=o>*</span><span class=n>a</span><span class=p>,</span><span class=w> </span><span class=n>half</span><span class=w> </span><span class=o>*</span><span class=n>b</span><span class=p>,</span><span class=w> </span><span class=n>half</span><span class=w> </span><span class=o>*</span><span class=n>c</span><span class=p>,</span><span class=w> </span><span class=kt>int</span><span class=w> </span><span class=n>N</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2></a><a href=#__codelineno-4-2><span class=linenos data-linenos=" 2 "></span></a><span class=w>  </span><span class=kt>int</span><span class=w> </span><span class=n>idx</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>8</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=p>(</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>);</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3></a><a href=#__codelineno-4-3><span class=linenos data-linenos=" 3 "></span></a><span class=w>  </span><span class=c1>// temporary register(memory), .local space in ptx, addressable</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4></a><a href=#__codelineno-4-4><span class=linenos data-linenos=" 4 "></span></a><span class=w>  </span><span class=n>half</span><span class=w> </span><span class=n>pack_a</span><span class=p>[</span><span class=mi>8</span><span class=p>],</span><span class=w> </span><span class=n>pack_b</span><span class=p>[</span><span class=mi>8</span><span class=p>],</span><span class=w> </span><span class=n>pack_c</span><span class=p>[</span><span class=mi>8</span><span class=p>];</span><span class=w> </span><span class=c1>// 8x16 bits=128 bits.</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5></a><a href=#__codelineno-4-5><span class=linenos data-linenos=" 5 "></span></a><span class=w>  </span><span class=c1>// reinterpret as float4 and load 128 bits in 1 memory issue.</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6></a><a href=#__codelineno-4-6><span class=linenos data-linenos=" 6 "></span></a><span class=w>  </span><span class=n>LDST128BITS</span><span class=p>(</span><span class=n>pack_a</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>LDST128BITS</span><span class=p>(</span><span class=n>a</span><span class=p>[</span><span class=n>idx</span><span class=p>]);</span><span class=w> </span><span class=c1>// load 128 bits</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7></a><a href=#__codelineno-4-7><span class=linenos data-linenos=" 7 "></span></a><span class=w>  </span><span class=n>LDST128BITS</span><span class=p>(</span><span class=n>pack_b</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>LDST128BITS</span><span class=p>(</span><span class=n>b</span><span class=p>[</span><span class=n>idx</span><span class=p>]);</span><span class=w> </span><span class=c1>// load 128 bits</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8></a><a href=#__codelineno-4-8><span class=linenos data-linenos=" 8 "></span></a><span class=cp>#pragma unroll</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9></a><a href=#__codelineno-4-9><span class=linenos data-linenos=" 9 "></span></a><span class=w>  </span><span class=k>for</span><span class=w> </span><span class=p>(</span><span class=kt>int</span><span class=w> </span><span class=n>i</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>0</span><span class=p>;</span><span class=w> </span><span class=n>i</span><span class=w> </span><span class=o>&lt;</span><span class=w> </span><span class=mi>8</span><span class=p>;</span><span class=w> </span><span class=n>i</span><span class=w> </span><span class=o>+=</span><span class=w> </span><span class=mi>2</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10></a><a href=#__codelineno-4-10><span class=linenos data-linenos="10 "></span></a><span class=w>    </span><span class=c1>// __hadd2 for half2 x 4</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11></a><a href=#__codelineno-4-11><span class=linenos data-linenos="11 "></span></a><span class=w>    </span><span class=n>HALF2</span><span class=p>(</span><span class=n>pack_c</span><span class=p>[</span><span class=n>i</span><span class=p>])</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>__hadd2</span><span class=p>(</span><span class=n>HALF2</span><span class=p>(</span><span class=n>pack_a</span><span class=p>[</span><span class=n>i</span><span class=p>]),</span><span class=w> </span><span class=n>HALF2</span><span class=p>(</span><span class=n>pack_b</span><span class=p>[</span><span class=n>i</span><span class=p>]));</span>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12></a><a href=#__codelineno-4-12><span class=linenos data-linenos="12 "></span></a><span class=w>  </span><span class=p>}</span>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13></a><a href=#__codelineno-4-13><span class=linenos data-linenos="13 "></span></a><span class=w>  </span><span class=c1>// reinterpret as float4 and store 128 bits in 1 memory issue.</span>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14></a><a href=#__codelineno-4-14><span class=linenos data-linenos="14 "></span></a><span class=w>  </span><span class=k>if</span><span class=w> </span><span class=p>((</span><span class=n>idx</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=mi>7</span><span class=p>)</span><span class=w> </span><span class=o>&lt;</span><span class=w> </span><span class=n>N</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15></a><a href=#__codelineno-4-15><span class=linenos data-linenos="15 "></span></a><span class=w>    </span><span class=n>LDST128BITS</span><span class=p>(</span><span class=n>c</span><span class=p>[</span><span class=n>idx</span><span class=p>])</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>LDST128BITS</span><span class=p>(</span><span class=n>pack_c</span><span class=p>[</span><span class=mi>0</span><span class=p>]);</span>
</span><span id=__span-4-16><a id=__codelineno-4-16 name=__codelineno-4-16></a><a href=#__codelineno-4-16><span class=linenos data-linenos="16 "></span></a><span class=w>  </span><span class=p>}</span><span class=w> </span><span class=k>else</span><span class=w> </span><span class=p>{</span>
</span><span id=__span-4-17><a id=__codelineno-4-17 name=__codelineno-4-17></a><a href=#__codelineno-4-17><span class=linenos data-linenos="17 "></span></a><span class=w>    </span><span class=k>for</span><span class=w> </span><span class=p>(</span><span class=kt>int</span><span class=w> </span><span class=n>i</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>0</span><span class=p>;</span><span class=w> </span><span class=n>idx</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>i</span><span class=w> </span><span class=o>&lt;</span><span class=w> </span><span class=n>N</span><span class=p>;</span><span class=w> </span><span class=n>i</span><span class=o>++</span><span class=p>)</span><span class=w> </span><span class=p>{</span>
</span><span id=__span-4-18><a id=__codelineno-4-18 name=__codelineno-4-18></a><a href=#__codelineno-4-18><span class=linenos data-linenos="18 "></span></a><span class=w>      </span><span class=n>c</span><span class=p>[</span><span class=n>idx</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>i</span><span class=p>]</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>__hadd</span><span class=p>(</span><span class=n>a</span><span class=p>[</span><span class=n>idx</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>i</span><span class=p>],</span><span class=w> </span><span class=n>b</span><span class=p>[</span><span class=n>idx</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>i</span><span class=p>]);</span>
</span><span id=__span-4-19><a id=__codelineno-4-19 name=__codelineno-4-19></a><a href=#__codelineno-4-19><span class=linenos data-linenos="19 "></span></a><span class=w>    </span><span class=p>}</span>
</span><span id=__span-4-20><a id=__codelineno-4-20 name=__codelineno-4-20></a><a href=#__codelineno-4-20><span class=linenos data-linenos="20 "></span></a><span class=w>  </span><span class=p>}</span>
</span><span id=__span-4-21><a id=__codelineno-4-21 name=__codelineno-4-21></a><a href=#__codelineno-4-21><span class=linenos data-linenos="21 "></span></a><span class=p>}</span>
</span></code></pre></div> <h3 id=_9>分析<a class=headerlink href=#_9 title="Permanent link">¶</a></h3> <div class=arithmatex>\[ AI = \frac{4*(\_hadd2) FLOPs}{16 * 3 Bytes} = 1/6 \approx 0.17 FLOPs /Byte \]</div> <ul> <li>一次加载 128 bit 数据，减少内存事务数量，节省时间</li> <li>单个线程的工作量提升</li> <li>实际 benchmark 和 profile 发现，在 RTX Titan 显卡上，对于 1M 大小的数据这个算子的实际 Occupancy 比 <code>fp16x2</code> 算子更少，加速效果略不明显</li> </ul> <h2 id=summary>Summary<a class=headerlink href=#summary title="Permanent link">¶</a></h2> <p>vector add 算子是一个典型的 memory-bound 的算子，我们需要尽可能节省内存带宽并提高计算效率。</p> <blockquote> <p>下面我们使用 benchmark 测试所有算子的开销，观察和我们的分析哪里不同</p> </blockquote> <h3 id=1-vs-kernel-launch-overhead>洞察 1：问题规模 vs. 启动开销 (Kernel Launch Overhead)<a class=headerlink href=#1-vs-kernel-launch-overhead title="Permanent link">¶</a></h3> <p>这个测试完美地展示了为什么 GPU 不适合处理“小任务”。</p> <ul> <li> <p>**在 1K (N=1024) 时：CPU 获胜</p> </li> <li> <p>CPU Time: <strong>0.0030 ms</strong></p> </li> <li> <p>GPU (最快): <strong>0.0078 ms</strong> </p> </li> <li> <p><strong>原因：</strong> 调用一个 CUDA 内核（<code>__global__ void</code>）本身就有<strong>固定的开销</strong>（<code>Kernel Launch Overhead</code>），这个开销通常需要几个微秒 (microseconds)。对于 1K 这样的小问题，GPU 实际执行计算的时间（可能只有 1-2 微秒）远小于启动它所花费的时间（5-6 微秒）。CPU 直接在本地执行循环，没有任何启动开销，所以更快。</p> </li> <li> <p><strong>在 1M (N=1048576) 时：GPU 完胜</strong></p> </li> <li>CPU Time: <strong>3.0058 ms</strong></li> <li>GPU (最快): <strong>0.0132 ms</strong> (即 <code>GPU FP16 x2</code> 版本)</li> <li><strong>原因：</strong> 当问题规模变得足够大时，<strong>大规模并行（Massive Parallelism）</strong>的优势开始显现。启动内核的 5-6 微秒开销在总共 13.2 微秒的执行时间中变得微不足道。此时，GPU 的<strong>巨大内存带宽</strong>（<code>GPU FP16 x2</code> 达到了 <strong>475.7 GB/s</strong>）彻底击败了 CPU 的内存带宽（被限制在 <strong>4.2 GB/s</strong>）。</li> </ul> <hr> <h3 id=2-memory-bound>洞察 2：内存带宽是瓶颈 (Memory-Bound)<a class=headerlink href=#2-memory-bound title="Permanent link">¶</a></h3> <p>逐元素加法（Vector Addition）是一个经典的<strong>内存带宽受限（Memory-Bound）</strong>问题，它的计算密集度 (AI) 极低。这意味着性能的瓶颈是**你能多快地从显存中读取 a 和 b，并写回 c。</p> <p>这个测试结果清楚地证明了这一点：</p> <ul> <li>**FP32 vs. FP16 (在 1M 数据集)</li> <li> <p><code>GPU Standard</code> (FP32): 0.0250 ms </p> </li> <li> <p><code>GPU FP16 Std</code>: 0.0163 ms </p> </li> <li> <p><strong>原因：</strong> FP32 内核需要移动的数据量是 <span class=arithmatex>\(1M \times (4+4+4) = 12 \text{ MB}\)</span>。而 FP16 内核只需要移动 <span class=arithmatex>\(1M \times (2+2+2) = 6 \text{ MB}\)</span>。</p> </li> <li><strong>数据量减半，性能几乎翻倍</strong>（<code>0.0250 / 0.0163 = 1.53x</code> 加速）。这证实了瓶颈在内存，而不是计算。</li> </ul> <hr> <h3 id=3baseline>洞察 3：baseline 实现在较小的问题规模下已足够好<a class=headerlink href=#3baseline title="Permanent link">¶</a></h3> <ul> <li>在数据小于 64K 大小的情况下，baseline 是最优的方法</li> </ul> <div class="language-shell highlight"><span class=filename>Bash</span><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1></a><a href=#__codelineno-5-1><span class=linenos data-linenos=" 1 "></span></a><span class=o>==========</span><span class=w> </span>Testing<span class=w> </span>1K<span class=w> </span><span class=o>(</span><span class=nv>N</span><span class=o>=</span><span class=m>1024</span><span class=o>)</span><span class=w> </span><span class=o>==========</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2></a><a href=#__codelineno-5-2><span class=linenos data-linenos=" 2 "></span></a>---<span class=w> </span>Speedup<span class=w> </span>Analysis<span class=w> </span>---
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3></a><a href=#__codelineno-5-3><span class=linenos data-linenos=" 3 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>Vec4:<span class=w>       </span><span class=m>0</span>.98x
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4></a><a href=#__codelineno-5-4><span class=linenos data-linenos=" 4 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16:<span class=w>       </span><span class=m>0</span>.98x
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5></a><a href=#__codelineno-5-5><span class=linenos data-linenos=" 5 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>     </span><span class=m>0</span>.97x
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6></a><a href=#__codelineno-5-6><span class=linenos data-linenos=" 6 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>     </span><span class=m>0</span>.95x
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7></a><a href=#__codelineno-5-7><span class=linenos data-linenos=" 7 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>0</span>.99x
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8></a><a href=#__codelineno-5-8><span class=linenos data-linenos=" 8 "></span></a>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9></a><a href=#__codelineno-5-9><span class=linenos data-linenos=" 9 "></span></a><span class=o>==========</span><span class=w> </span>Testing<span class=w> </span>4K<span class=w> </span><span class=o>(</span><span class=nv>N</span><span class=o>=</span><span class=m>4096</span><span class=o>)</span><span class=w> </span><span class=o>==========</span>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10></a><a href=#__codelineno-5-10><span class=linenos data-linenos="10 "></span></a>---<span class=w> </span>Speedup<span class=w> </span>Analysis<span class=w> </span>---
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11></a><a href=#__codelineno-5-11><span class=linenos data-linenos="11 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>Vec4:<span class=w>       </span><span class=m>1</span>.02x
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12></a><a href=#__codelineno-5-12><span class=linenos data-linenos="12 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16:<span class=w>       </span><span class=m>0</span>.78x
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13></a><a href=#__codelineno-5-13><span class=linenos data-linenos="13 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>     </span><span class=m>0</span>.79x
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14></a><a href=#__codelineno-5-14><span class=linenos data-linenos="14 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>     </span><span class=m>0</span>.75x
</span><span id=__span-5-15><a id=__codelineno-5-15 name=__codelineno-5-15></a><a href=#__codelineno-5-15><span class=linenos data-linenos="15 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>0</span>.76x
</span><span id=__span-5-16><a id=__codelineno-5-16 name=__codelineno-5-16></a><a href=#__codelineno-5-16><span class=linenos data-linenos="16 "></span></a>
</span><span id=__span-5-17><a id=__codelineno-5-17 name=__codelineno-5-17></a><a href=#__codelineno-5-17><span class=linenos data-linenos="17 "></span></a><span class=o>==========</span><span class=w> </span>Testing<span class=w> </span>16K<span class=w> </span><span class=o>(</span><span class=nv>N</span><span class=o>=</span><span class=m>16384</span><span class=o>)</span><span class=w> </span><span class=o>==========</span>
</span><span id=__span-5-18><a id=__codelineno-5-18 name=__codelineno-5-18></a><a href=#__codelineno-5-18><span class=linenos data-linenos="18 "></span></a>---<span class=w> </span>Speedup<span class=w> </span>Analysis<span class=w> </span>---
</span><span id=__span-5-19><a id=__codelineno-5-19 name=__codelineno-5-19></a><a href=#__codelineno-5-19><span class=linenos data-linenos="19 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>Vec4:<span class=w>       </span><span class=m>1</span>.00x
</span><span id=__span-5-20><a id=__codelineno-5-20 name=__codelineno-5-20></a><a href=#__codelineno-5-20><span class=linenos data-linenos="20 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16:<span class=w>       </span><span class=m>0</span>.99x
</span><span id=__span-5-21><a id=__codelineno-5-21 name=__codelineno-5-21></a><a href=#__codelineno-5-21><span class=linenos data-linenos="21 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>     </span><span class=m>0</span>.99x
</span><span id=__span-5-22><a id=__codelineno-5-22 name=__codelineno-5-22></a><a href=#__codelineno-5-22><span class=linenos data-linenos="22 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>     </span><span class=m>0</span>.87x
</span><span id=__span-5-23><a id=__codelineno-5-23 name=__codelineno-5-23></a><a href=#__codelineno-5-23><span class=linenos data-linenos="23 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>0</span>.91x
</span><span id=__span-5-24><a id=__codelineno-5-24 name=__codelineno-5-24></a><a href=#__codelineno-5-24><span class=linenos data-linenos="24 "></span></a>
</span><span id=__span-5-25><a id=__codelineno-5-25 name=__codelineno-5-25></a><a href=#__codelineno-5-25><span class=linenos data-linenos="25 "></span></a>
</span><span id=__span-5-26><a id=__codelineno-5-26 name=__codelineno-5-26></a><a href=#__codelineno-5-26><span class=linenos data-linenos="26 "></span></a><span class=o>==========</span><span class=w> </span>Testing<span class=w> </span>64K<span class=w> </span><span class=o>(</span><span class=nv>N</span><span class=o>=</span><span class=m>65536</span><span class=o>)</span><span class=w> </span><span class=o>==========</span>
</span><span id=__span-5-27><a id=__codelineno-5-27 name=__codelineno-5-27></a><a href=#__codelineno-5-27><span class=linenos data-linenos="27 "></span></a>---<span class=w> </span>Speedup<span class=w> </span>Analysis<span class=w> </span>---
</span><span id=__span-5-28><a id=__codelineno-5-28 name=__codelineno-5-28></a><a href=#__codelineno-5-28><span class=linenos data-linenos="28 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>Vec4:<span class=w>       </span><span class=m>0</span>.96x
</span><span id=__span-5-29><a id=__codelineno-5-29 name=__codelineno-5-29></a><a href=#__codelineno-5-29><span class=linenos data-linenos="29 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16:<span class=w>       </span><span class=m>0</span>.98x
</span><span id=__span-5-30><a id=__codelineno-5-30 name=__codelineno-5-30></a><a href=#__codelineno-5-30><span class=linenos data-linenos="30 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>     </span><span class=m>1</span>.00x
</span><span id=__span-5-31><a id=__codelineno-5-31 name=__codelineno-5-31></a><a href=#__codelineno-5-31><span class=linenos data-linenos="31 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>     </span><span class=m>0</span>.92x
</span><span id=__span-5-32><a id=__codelineno-5-32 name=__codelineno-5-32></a><a href=#__codelineno-5-32><span class=linenos data-linenos="32 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>0</span>.88x
</span></code></pre></div> <h3 id=41m-fp16-x2>洞察 4：1M 数据测试下 <code>FP16 x2</code> 是最佳的 "工作粒度"<a class=headerlink href=#41m-fp16-x2 title="Permanent link">¶</a></h3> <p>在最大的 1M 测试中，我们看 FP16 的各种实现：</p> <ol> <li><strong><code>GPU FP16 x2</code></strong>: <strong>0.0132 ms</strong> (🏆)</li> <li><code>GPU FP16 x8_pack</code>: 0.0158 ms</li> <li><code>GPU FP16 x8</code>: 0.0161 ms</li> <li><code>GPU FP16 Std</code>: 0.0163 ms</li> </ol> <ul> <li><strong><code>FP16 Std</code> (1 线程/1 元素)</strong> 是最慢的，因为它最朴素，每个线程只做了最少的工作，调度的开销相对最大。</li> <li><strong><code>FP16 x8</code> 和 <code>x8_pack</code> (1 线程/8 元素)</strong> 表现更好，因为它们让每个线程做了更多工作，减少了总的调度开销并使用了向量化指令（如 Nsight 分析所示）。</li> <li><strong><code>FP16 x2</code> 为什么更优？</strong></li> <li><code>FP16 x2</code> 内核使用了 <code>half2</code> 数据类型进行加载。而 <code>x8_pack</code> 使用的是 128-bit (<code>float4</code>) 操作。</li> <li>在这个特定的测试中，<strong><code>half2</code> 达到了“工作粒度”和“硬件亲和性”的 sweet spot</strong>。它比 <code>x8_pack</code> 更简单，需要更少的寄存器(<code>x8_pack</code> 需要 22 个，而 <code>x2</code>只需要 16 个)，<strong>实际占用率 (Achieved Occupancy)更高</strong>。</li> </ul> <h2 id=_10>附录<a class=headerlink href=#_10 title="Permanent link">¶</a></h2> <div class="language-shell highlight"><span class=filename>Bash</span><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1></a><a href=#__codelineno-6-1><span class=linenos data-linenos="  1 "></span></a>Vector<span class=w> </span>Addition<span class=w> </span>Performance<span class=w> </span><span class=nv>Test</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2></a><a href=#__codelineno-6-2><span class=linenos data-linenos="  2 "></span></a><span class=o>================================</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3></a><a href=#__codelineno-6-3><span class=linenos data-linenos="  3 "></span></a>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4></a><a href=#__codelineno-6-4><span class=linenos data-linenos="  4 "></span></a><span class=o>==========</span><span class=w> </span>Testing<span class=w> </span>1K<span class=w> </span><span class=o>(</span><span class=nv>N</span><span class=o>=</span><span class=m>1024</span><span class=o>)</span><span class=w> </span><span class=o>==========</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5></a><a href=#__codelineno-6-5><span class=linenos data-linenos="  5 "></span></a>Mismatch<span class=w> </span>at<span class=w> </span>index<span class=w> </span><span class=m>2</span>:<span class=w> </span><span class=m>2</span>.39844<span class=w> </span>!<span class=o>=</span><span class=w> </span><span class=m>2</span>.4<span class=w> </span><span class=o>(</span>error:<span class=w> </span><span class=m>0</span>.0015626<span class=o>)</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6></a><a href=#__codelineno-6-6><span class=linenos data-linenos="  6 "></span></a>Correctness:<span class=w> </span>FAIL<span class=w> </span><span class=o>(</span>Max<span class=w> </span>error:<span class=w> </span><span class=m>0</span>.037506<span class=o>)</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7></a><a href=#__codelineno-6-7><span class=linenos data-linenos="  7 "></span></a>Array<span class=w> </span>Size:<span class=w> </span><span class=m>1024</span><span class=w> </span>elements<span class=w> </span><span class=o>(</span><span class=m>0</span>.00<span class=w> </span>GB<span class=o>)</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8></a><a href=#__codelineno-6-8><span class=linenos data-linenos="  8 "></span></a>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9></a><a href=#__codelineno-6-9><span class=linenos data-linenos="  9 "></span></a>---<span class=w> </span>Execution<span class=w> </span>Times<span class=w> </span><span class=o>(</span>Kernel<span class=w> </span>Only<span class=o>)</span><span class=w> </span>---
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10></a><a href=#__codelineno-6-10><span class=linenos data-linenos=" 10 "></span></a>CPU<span class=w> </span>Time:<span class=w>           </span><span class=m>0</span>.0030<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>4</span>.1<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11></a><a href=#__codelineno-6-11><span class=linenos data-linenos=" 11 "></span></a>GPU<span class=w> </span>Standard:<span class=w>       </span><span class=m>0</span>.0078<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>1</span>.6<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12></a><a href=#__codelineno-6-12><span class=linenos data-linenos=" 12 "></span></a>GPU<span class=w> </span>Vec4:<span class=w>           </span><span class=m>0</span>.0079<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>1</span>.5<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13></a><a href=#__codelineno-6-13><span class=linenos data-linenos=" 13 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>Std:<span class=w>       </span><span class=m>0</span>.0079<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>0</span>.8<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14></a><a href=#__codelineno-6-14><span class=linenos data-linenos=" 14 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x2:<span class=w>        </span><span class=m>0</span>.0080<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>0</span>.8<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15></a><a href=#__codelineno-6-15><span class=linenos data-linenos=" 15 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x8:<span class=w>        </span><span class=m>0</span>.0082<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>0</span>.8<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16></a><a href=#__codelineno-6-16><span class=linenos data-linenos=" 16 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x8_pack:<span class=w>   </span><span class=m>0</span>.0078<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>0</span>.8<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17></a><a href=#__codelineno-6-17><span class=linenos data-linenos=" 17 "></span></a>
</span><span id=__span-6-18><a id=__codelineno-6-18 name=__codelineno-6-18></a><a href=#__codelineno-6-18><span class=linenos data-linenos=" 18 "></span></a>---<span class=w> </span>Speedup<span class=w> </span>Analysis<span class=w> </span>---
</span><span id=__span-6-19><a id=__codelineno-6-19 name=__codelineno-6-19></a><a href=#__codelineno-6-19><span class=linenos data-linenos=" 19 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>Standard:<span class=w>    </span><span class=m>0</span>.39x
</span><span id=__span-6-20><a id=__codelineno-6-20 name=__codelineno-6-20></a><a href=#__codelineno-6-20><span class=linenos data-linenos=" 20 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>Vec4:<span class=w>        </span><span class=m>0</span>.38x
</span><span id=__span-6-21><a id=__codelineno-6-21 name=__codelineno-6-21></a><a href=#__codelineno-6-21><span class=linenos data-linenos=" 21 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16:<span class=w>        </span><span class=m>0</span>.38x
</span><span id=__span-6-22><a id=__codelineno-6-22 name=__codelineno-6-22></a><a href=#__codelineno-6-22><span class=linenos data-linenos=" 22 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x2:<span class=w>      </span><span class=m>0</span>.38x
</span><span id=__span-6-23><a id=__codelineno-6-23 name=__codelineno-6-23></a><a href=#__codelineno-6-23><span class=linenos data-linenos=" 23 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x8:<span class=w>      </span><span class=m>0</span>.37x
</span><span id=__span-6-24><a id=__codelineno-6-24 name=__codelineno-6-24></a><a href=#__codelineno-6-24><span class=linenos data-linenos=" 24 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>0</span>.39x
</span><span id=__span-6-25><a id=__codelineno-6-25 name=__codelineno-6-25></a><a href=#__codelineno-6-25><span class=linenos data-linenos=" 25 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>Vec4:<span class=w>       </span><span class=m>0</span>.98x
</span><span id=__span-6-26><a id=__codelineno-6-26 name=__codelineno-6-26></a><a href=#__codelineno-6-26><span class=linenos data-linenos=" 26 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16:<span class=w>       </span><span class=m>0</span>.98x
</span><span id=__span-6-27><a id=__codelineno-6-27 name=__codelineno-6-27></a><a href=#__codelineno-6-27><span class=linenos data-linenos=" 27 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>     </span><span class=m>0</span>.97x
</span><span id=__span-6-28><a id=__codelineno-6-28 name=__codelineno-6-28></a><a href=#__codelineno-6-28><span class=linenos data-linenos=" 28 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>     </span><span class=m>0</span>.95x
</span><span id=__span-6-29><a id=__codelineno-6-29 name=__codelineno-6-29></a><a href=#__codelineno-6-29><span class=linenos data-linenos=" 29 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>0</span>.99x
</span><span id=__span-6-30><a id=__codelineno-6-30 name=__codelineno-6-30></a><a href=#__codelineno-6-30><span class=linenos data-linenos=" 30 "></span></a>FP16<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>         </span><span class=m>0</span>.99x
</span><span id=__span-6-31><a id=__codelineno-6-31 name=__codelineno-6-31></a><a href=#__codelineno-6-31><span class=linenos data-linenos=" 31 "></span></a>FP16x2<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>       </span><span class=m>0</span>.98x
</span><span id=__span-6-32><a id=__codelineno-6-32 name=__codelineno-6-32></a><a href=#__codelineno-6-32><span class=linenos data-linenos=" 32 "></span></a>FP16x8<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>1</span>.05x
</span><span id=__span-6-33><a id=__codelineno-6-33 name=__codelineno-6-33></a><a href=#__codelineno-6-33><span class=linenos data-linenos=" 33 "></span></a>
</span><span id=__span-6-34><a id=__codelineno-6-34 name=__codelineno-6-34></a><a href=#__codelineno-6-34><span class=linenos data-linenos=" 34 "></span></a><span class=o>==========</span><span class=w> </span>Testing<span class=w> </span>4K<span class=w> </span><span class=o>(</span><span class=nv>N</span><span class=o>=</span><span class=m>4096</span><span class=o>)</span><span class=w> </span><span class=o>==========</span>
</span><span id=__span-6-35><a id=__codelineno-6-35 name=__codelineno-6-35></a><a href=#__codelineno-6-35><span class=linenos data-linenos=" 35 "></span></a>Mismatch<span class=w> </span>at<span class=w> </span>index<span class=w> </span><span class=m>0</span>:<span class=w> </span><span class=m>9</span>.60156<span class=w> </span>!<span class=o>=</span><span class=w> </span><span class=m>9</span>.6<span class=w> </span><span class=o>(</span>error:<span class=w> </span><span class=m>0</span>.00156212<span class=o>)</span>
</span><span id=__span-6-36><a id=__codelineno-6-36 name=__codelineno-6-36></a><a href=#__codelineno-6-36><span class=linenos data-linenos=" 36 "></span></a>Correctness:<span class=w> </span>FAIL<span class=w> </span><span class=o>(</span>Max<span class=w> </span>error:<span class=w> </span><span class=m>0</span>.037506<span class=o>)</span>
</span><span id=__span-6-37><a id=__codelineno-6-37 name=__codelineno-6-37></a><a href=#__codelineno-6-37><span class=linenos data-linenos=" 37 "></span></a>Array<span class=w> </span>Size:<span class=w> </span><span class=m>4096</span><span class=w> </span>elements<span class=w> </span><span class=o>(</span><span class=m>0</span>.00<span class=w> </span>GB<span class=o>)</span>
</span><span id=__span-6-38><a id=__codelineno-6-38 name=__codelineno-6-38></a><a href=#__codelineno-6-38><span class=linenos data-linenos=" 38 "></span></a>
</span><span id=__span-6-39><a id=__codelineno-6-39 name=__codelineno-6-39></a><a href=#__codelineno-6-39><span class=linenos data-linenos=" 39 "></span></a>---<span class=w> </span>Execution<span class=w> </span>Times<span class=w> </span><span class=o>(</span>Kernel<span class=w> </span>Only<span class=o>)</span><span class=w> </span>---
</span><span id=__span-6-40><a id=__codelineno-6-40 name=__codelineno-6-40></a><a href=#__codelineno-6-40><span class=linenos data-linenos=" 40 "></span></a>CPU<span class=w> </span>Time:<span class=w>           </span><span class=m>0</span>.0120<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>4</span>.1<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-41><a id=__codelineno-6-41 name=__codelineno-6-41></a><a href=#__codelineno-6-41><span class=linenos data-linenos=" 41 "></span></a>GPU<span class=w> </span>Standard:<span class=w>       </span><span class=m>0</span>.0060<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>8</span>.1<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-42><a id=__codelineno-6-42 name=__codelineno-6-42></a><a href=#__codelineno-6-42><span class=linenos data-linenos=" 42 "></span></a>GPU<span class=w> </span>Vec4:<span class=w>           </span><span class=m>0</span>.0059<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>8</span>.3<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-43><a id=__codelineno-6-43 name=__codelineno-6-43></a><a href=#__codelineno-6-43><span class=linenos data-linenos=" 43 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>Std:<span class=w>       </span><span class=m>0</span>.0077<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>3</span>.2<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-44><a id=__codelineno-6-44 name=__codelineno-6-44></a><a href=#__codelineno-6-44><span class=linenos data-linenos=" 44 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x2:<span class=w>        </span><span class=m>0</span>.0077<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>3</span>.2<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-45><a id=__codelineno-6-45 name=__codelineno-6-45></a><a href=#__codelineno-6-45><span class=linenos data-linenos=" 45 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x8:<span class=w>        </span><span class=m>0</span>.0081<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>3</span>.0<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-46><a id=__codelineno-6-46 name=__codelineno-6-46></a><a href=#__codelineno-6-46><span class=linenos data-linenos=" 46 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x8_pack:<span class=w>   </span><span class=m>0</span>.0080<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>3</span>.1<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-47><a id=__codelineno-6-47 name=__codelineno-6-47></a><a href=#__codelineno-6-47><span class=linenos data-linenos=" 47 "></span></a>
</span><span id=__span-6-48><a id=__codelineno-6-48 name=__codelineno-6-48></a><a href=#__codelineno-6-48><span class=linenos data-linenos=" 48 "></span></a>---<span class=w> </span>Speedup<span class=w> </span>Analysis<span class=w> </span>---
</span><span id=__span-6-49><a id=__codelineno-6-49 name=__codelineno-6-49></a><a href=#__codelineno-6-49><span class=linenos data-linenos=" 49 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>Standard:<span class=w>    </span><span class=m>1</span>.98x
</span><span id=__span-6-50><a id=__codelineno-6-50 name=__codelineno-6-50></a><a href=#__codelineno-6-50><span class=linenos data-linenos=" 50 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>Vec4:<span class=w>        </span><span class=m>2</span>.01x
</span><span id=__span-6-51><a id=__codelineno-6-51 name=__codelineno-6-51></a><a href=#__codelineno-6-51><span class=linenos data-linenos=" 51 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16:<span class=w>        </span><span class=m>1</span>.55x
</span><span id=__span-6-52><a id=__codelineno-6-52 name=__codelineno-6-52></a><a href=#__codelineno-6-52><span class=linenos data-linenos=" 52 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x2:<span class=w>      </span><span class=m>1</span>.56x
</span><span id=__span-6-53><a id=__codelineno-6-53 name=__codelineno-6-53></a><a href=#__codelineno-6-53><span class=linenos data-linenos=" 53 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x8:<span class=w>      </span><span class=m>1</span>.48x
</span><span id=__span-6-54><a id=__codelineno-6-54 name=__codelineno-6-54></a><a href=#__codelineno-6-54><span class=linenos data-linenos=" 54 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>1</span>.50x
</span><span id=__span-6-55><a id=__codelineno-6-55 name=__codelineno-6-55></a><a href=#__codelineno-6-55><span class=linenos data-linenos=" 55 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>Vec4:<span class=w>       </span><span class=m>1</span>.02x
</span><span id=__span-6-56><a id=__codelineno-6-56 name=__codelineno-6-56></a><a href=#__codelineno-6-56><span class=linenos data-linenos=" 56 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16:<span class=w>       </span><span class=m>0</span>.78x
</span><span id=__span-6-57><a id=__codelineno-6-57 name=__codelineno-6-57></a><a href=#__codelineno-6-57><span class=linenos data-linenos=" 57 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>     </span><span class=m>0</span>.79x
</span><span id=__span-6-58><a id=__codelineno-6-58 name=__codelineno-6-58></a><a href=#__codelineno-6-58><span class=linenos data-linenos=" 58 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>     </span><span class=m>0</span>.75x
</span><span id=__span-6-59><a id=__codelineno-6-59 name=__codelineno-6-59></a><a href=#__codelineno-6-59><span class=linenos data-linenos=" 59 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>0</span>.76x
</span><span id=__span-6-60><a id=__codelineno-6-60 name=__codelineno-6-60></a><a href=#__codelineno-6-60><span class=linenos data-linenos=" 60 "></span></a>FP16<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>         </span><span class=m>1</span>.01x
</span><span id=__span-6-61><a id=__codelineno-6-61 name=__codelineno-6-61></a><a href=#__codelineno-6-61><span class=linenos data-linenos=" 61 "></span></a>FP16x2<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>       </span><span class=m>0</span>.95x
</span><span id=__span-6-62><a id=__codelineno-6-62 name=__codelineno-6-62></a><a href=#__codelineno-6-62><span class=linenos data-linenos=" 62 "></span></a>FP16x8<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>1</span>.01x
</span><span id=__span-6-63><a id=__codelineno-6-63 name=__codelineno-6-63></a><a href=#__codelineno-6-63><span class=linenos data-linenos=" 63 "></span></a>
</span><span id=__span-6-64><a id=__codelineno-6-64 name=__codelineno-6-64></a><a href=#__codelineno-6-64><span class=linenos data-linenos=" 64 "></span></a><span class=o>==========</span><span class=w> </span>Testing<span class=w> </span>16K<span class=w> </span><span class=o>(</span><span class=nv>N</span><span class=o>=</span><span class=m>16384</span><span class=o>)</span><span class=w> </span><span class=o>==========</span>
</span><span id=__span-6-65><a id=__codelineno-6-65 name=__codelineno-6-65></a><a href=#__codelineno-6-65><span class=linenos data-linenos=" 65 "></span></a>Mismatch<span class=w> </span>at<span class=w> </span>index<span class=w> </span><span class=m>0</span>:<span class=w> </span><span class=m>38</span>.4062<span class=w> </span>!<span class=o>=</span><span class=w> </span><span class=m>38</span>.4<span class=w> </span><span class=o>(</span>error:<span class=w> </span><span class=m>0</span>.00624847<span class=o>)</span>
</span><span id=__span-6-66><a id=__codelineno-6-66 name=__codelineno-6-66></a><a href=#__codelineno-6-66><span class=linenos data-linenos=" 66 "></span></a>Correctness:<span class=w> </span>FAIL<span class=w> </span><span class=o>(</span>Max<span class=w> </span>error:<span class=w> </span><span class=m>0</span>.100006<span class=o>)</span>
</span><span id=__span-6-67><a id=__codelineno-6-67 name=__codelineno-6-67></a><a href=#__codelineno-6-67><span class=linenos data-linenos=" 67 "></span></a>Array<span class=w> </span>Size:<span class=w> </span><span class=m>16384</span><span class=w> </span>elements<span class=w> </span><span class=o>(</span><span class=m>0</span>.00<span class=w> </span>GB<span class=o>)</span>
</span><span id=__span-6-68><a id=__codelineno-6-68 name=__codelineno-6-68></a><a href=#__codelineno-6-68><span class=linenos data-linenos=" 68 "></span></a>
</span><span id=__span-6-69><a id=__codelineno-6-69 name=__codelineno-6-69></a><a href=#__codelineno-6-69><span class=linenos data-linenos=" 69 "></span></a>---<span class=w> </span>Execution<span class=w> </span>Times<span class=w> </span><span class=o>(</span>Kernel<span class=w> </span>Only<span class=o>)</span><span class=w> </span>---
</span><span id=__span-6-70><a id=__codelineno-6-70 name=__codelineno-6-70></a><a href=#__codelineno-6-70><span class=linenos data-linenos=" 70 "></span></a>CPU<span class=w> </span>Time:<span class=w>           </span><span class=m>0</span>.0472<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>4</span>.2<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-71><a id=__codelineno-6-71 name=__codelineno-6-71></a><a href=#__codelineno-6-71><span class=linenos data-linenos=" 71 "></span></a>GPU<span class=w> </span>Standard:<span class=w>       </span><span class=m>0</span>.0044<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>   </span><span class=m>45</span>.1<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-72><a id=__codelineno-6-72 name=__codelineno-6-72></a><a href=#__codelineno-6-72><span class=linenos data-linenos=" 72 "></span></a>GPU<span class=w> </span>Vec4:<span class=w>           </span><span class=m>0</span>.0044<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>   </span><span class=m>45</span>.1<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-73><a id=__codelineno-6-73 name=__codelineno-6-73></a><a href=#__codelineno-6-73><span class=linenos data-linenos=" 73 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>Std:<span class=w>       </span><span class=m>0</span>.0044<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>   </span><span class=m>22</span>.4<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-74><a id=__codelineno-6-74 name=__codelineno-6-74></a><a href=#__codelineno-6-74><span class=linenos data-linenos=" 74 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x2:<span class=w>        </span><span class=m>0</span>.0044<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>   </span><span class=m>22</span>.4<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-75><a id=__codelineno-6-75 name=__codelineno-6-75></a><a href=#__codelineno-6-75><span class=linenos data-linenos=" 75 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x8:<span class=w>        </span><span class=m>0</span>.0050<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>   </span><span class=m>19</span>.5<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-76><a id=__codelineno-6-76 name=__codelineno-6-76></a><a href=#__codelineno-6-76><span class=linenos data-linenos=" 76 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x8_pack:<span class=w>   </span><span class=m>0</span>.0048<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>   </span><span class=m>20</span>.4<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-77><a id=__codelineno-6-77 name=__codelineno-6-77></a><a href=#__codelineno-6-77><span class=linenos data-linenos=" 77 "></span></a>
</span><span id=__span-6-78><a id=__codelineno-6-78 name=__codelineno-6-78></a><a href=#__codelineno-6-78><span class=linenos data-linenos=" 78 "></span></a>---<span class=w> </span>Speedup<span class=w> </span>Analysis<span class=w> </span>---
</span><span id=__span-6-79><a id=__codelineno-6-79 name=__codelineno-6-79></a><a href=#__codelineno-6-79><span class=linenos data-linenos=" 79 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>Standard:<span class=w>   </span><span class=m>10</span>.82x
</span><span id=__span-6-80><a id=__codelineno-6-80 name=__codelineno-6-80></a><a href=#__codelineno-6-80><span class=linenos data-linenos=" 80 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>Vec4:<span class=w>       </span><span class=m>10</span>.82x
</span><span id=__span-6-81><a id=__codelineno-6-81 name=__codelineno-6-81></a><a href=#__codelineno-6-81><span class=linenos data-linenos=" 81 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16:<span class=w>       </span><span class=m>10</span>.74x
</span><span id=__span-6-82><a id=__codelineno-6-82 name=__codelineno-6-82></a><a href=#__codelineno-6-82><span class=linenos data-linenos=" 82 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x2:<span class=w>     </span><span class=m>10</span>.75x
</span><span id=__span-6-83><a id=__codelineno-6-83 name=__codelineno-6-83></a><a href=#__codelineno-6-83><span class=linenos data-linenos=" 83 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x8:<span class=w>      </span><span class=m>9</span>.36x
</span><span id=__span-6-84><a id=__codelineno-6-84 name=__codelineno-6-84></a><a href=#__codelineno-6-84><span class=linenos data-linenos=" 84 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>9</span>.80x
</span><span id=__span-6-85><a id=__codelineno-6-85 name=__codelineno-6-85></a><a href=#__codelineno-6-85><span class=linenos data-linenos=" 85 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>Vec4:<span class=w>       </span><span class=m>1</span>.00x
</span><span id=__span-6-86><a id=__codelineno-6-86 name=__codelineno-6-86></a><a href=#__codelineno-6-86><span class=linenos data-linenos=" 86 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16:<span class=w>       </span><span class=m>0</span>.99x
</span><span id=__span-6-87><a id=__codelineno-6-87 name=__codelineno-6-87></a><a href=#__codelineno-6-87><span class=linenos data-linenos=" 87 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>     </span><span class=m>0</span>.99x
</span><span id=__span-6-88><a id=__codelineno-6-88 name=__codelineno-6-88></a><a href=#__codelineno-6-88><span class=linenos data-linenos=" 88 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>     </span><span class=m>0</span>.87x
</span><span id=__span-6-89><a id=__codelineno-6-89 name=__codelineno-6-89></a><a href=#__codelineno-6-89><span class=linenos data-linenos=" 89 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>0</span>.91x
</span><span id=__span-6-90><a id=__codelineno-6-90 name=__codelineno-6-90></a><a href=#__codelineno-6-90><span class=linenos data-linenos=" 90 "></span></a>FP16<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>         </span><span class=m>1</span>.00x
</span><span id=__span-6-91><a id=__codelineno-6-91 name=__codelineno-6-91></a><a href=#__codelineno-6-91><span class=linenos data-linenos=" 91 "></span></a>FP16x2<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>       </span><span class=m>0</span>.87x
</span><span id=__span-6-92><a id=__codelineno-6-92 name=__codelineno-6-92></a><a href=#__codelineno-6-92><span class=linenos data-linenos=" 92 "></span></a>FP16x8<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>1</span>.05x
</span><span id=__span-6-93><a id=__codelineno-6-93 name=__codelineno-6-93></a><a href=#__codelineno-6-93><span class=linenos data-linenos=" 93 "></span></a>
</span><span id=__span-6-94><a id=__codelineno-6-94 name=__codelineno-6-94></a><a href=#__codelineno-6-94><span class=linenos data-linenos=" 94 "></span></a><span class=o>==========</span><span class=w> </span>Testing<span class=w> </span>64K<span class=w> </span><span class=o>(</span><span class=nv>N</span><span class=o>=</span><span class=m>65536</span><span class=o>)</span><span class=w> </span><span class=o>==========</span>
</span><span id=__span-6-95><a id=__codelineno-6-95 name=__codelineno-6-95></a><a href=#__codelineno-6-95><span class=linenos data-linenos=" 95 "></span></a>Mismatch<span class=w> </span>at<span class=w> </span>index<span class=w> </span><span class=m>0</span>:<span class=w> </span><span class=m>53</span>.5938<span class=w> </span>!<span class=o>=</span><span class=w> </span><span class=m>53</span>.6<span class=w> </span><span class=o>(</span>error:<span class=w> </span><span class=m>0</span>.00625229<span class=o>)</span>
</span><span id=__span-6-96><a id=__codelineno-6-96 name=__codelineno-6-96></a><a href=#__codelineno-6-96><span class=linenos data-linenos=" 96 "></span></a>Correctness:<span class=w> </span>FAIL<span class=w> </span><span class=o>(</span>Max<span class=w> </span>error:<span class=w> </span><span class=m>0</span>.100006<span class=o>)</span>
</span><span id=__span-6-97><a id=__codelineno-6-97 name=__codelineno-6-97></a><a href=#__codelineno-6-97><span class=linenos data-linenos=" 97 "></span></a>Array<span class=w> </span>Size:<span class=w> </span><span class=m>65536</span><span class=w> </span>elements<span class=w> </span><span class=o>(</span><span class=m>0</span>.00<span class=w> </span>GB<span class=o>)</span>
</span><span id=__span-6-98><a id=__codelineno-6-98 name=__codelineno-6-98></a><a href=#__codelineno-6-98><span class=linenos data-linenos=" 98 "></span></a>
</span><span id=__span-6-99><a id=__codelineno-6-99 name=__codelineno-6-99></a><a href=#__codelineno-6-99><span class=linenos data-linenos=" 99 "></span></a>---<span class=w> </span>Execution<span class=w> </span>Times<span class=w> </span><span class=o>(</span>Kernel<span class=w> </span>Only<span class=o>)</span><span class=w> </span>---
</span><span id=__span-6-100><a id=__codelineno-6-100 name=__codelineno-6-100></a><a href=#__codelineno-6-100><span class=linenos data-linenos="100 "></span></a>CPU<span class=w> </span>Time:<span class=w>           </span><span class=m>0</span>.1875<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>4</span>.2<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-101><a id=__codelineno-6-101 name=__codelineno-6-101></a><a href=#__codelineno-6-101><span class=linenos data-linenos="101 "></span></a>GPU<span class=w> </span>Standard:<span class=w>       </span><span class=m>0</span>.0096<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>   </span><span class=m>82</span>.3<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-102><a id=__codelineno-6-102 name=__codelineno-6-102></a><a href=#__codelineno-6-102><span class=linenos data-linenos="102 "></span></a>GPU<span class=w> </span>Vec4:<span class=w>           </span><span class=m>0</span>.0099<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>   </span><span class=m>79</span>.3<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-103><a id=__codelineno-6-103 name=__codelineno-6-103></a><a href=#__codelineno-6-103><span class=linenos data-linenos="103 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>Std:<span class=w>       </span><span class=m>0</span>.0097<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>   </span><span class=m>40</span>.4<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-104><a id=__codelineno-6-104 name=__codelineno-6-104></a><a href=#__codelineno-6-104><span class=linenos data-linenos="104 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x2:<span class=w>        </span><span class=m>0</span>.0096<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>   </span><span class=m>41</span>.0<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-105><a id=__codelineno-6-105 name=__codelineno-6-105></a><a href=#__codelineno-6-105><span class=linenos data-linenos="105 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x8:<span class=w>        </span><span class=m>0</span>.0103<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>   </span><span class=m>38</span>.0<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-106><a id=__codelineno-6-106 name=__codelineno-6-106></a><a href=#__codelineno-6-106><span class=linenos data-linenos="106 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x8_pack:<span class=w>   </span><span class=m>0</span>.0109<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>   </span><span class=m>36</span>.2<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-107><a id=__codelineno-6-107 name=__codelineno-6-107></a><a href=#__codelineno-6-107><span class=linenos data-linenos="107 "></span></a>
</span><span id=__span-6-108><a id=__codelineno-6-108 name=__codelineno-6-108></a><a href=#__codelineno-6-108><span class=linenos data-linenos="108 "></span></a>---<span class=w> </span>Speedup<span class=w> </span>Analysis<span class=w> </span>---
</span><span id=__span-6-109><a id=__codelineno-6-109 name=__codelineno-6-109></a><a href=#__codelineno-6-109><span class=linenos data-linenos="109 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>Standard:<span class=w>   </span><span class=m>19</span>.63x
</span><span id=__span-6-110><a id=__codelineno-6-110 name=__codelineno-6-110></a><a href=#__codelineno-6-110><span class=linenos data-linenos="110 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>Vec4:<span class=w>       </span><span class=m>18</span>.91x
</span><span id=__span-6-111><a id=__codelineno-6-111 name=__codelineno-6-111></a><a href=#__codelineno-6-111><span class=linenos data-linenos="111 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16:<span class=w>       </span><span class=m>19</span>.28x
</span><span id=__span-6-112><a id=__codelineno-6-112 name=__codelineno-6-112></a><a href=#__codelineno-6-112><span class=linenos data-linenos="112 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x2:<span class=w>     </span><span class=m>19</span>.57x
</span><span id=__span-6-113><a id=__codelineno-6-113 name=__codelineno-6-113></a><a href=#__codelineno-6-113><span class=linenos data-linenos="113 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x8:<span class=w>     </span><span class=m>18</span>.13x
</span><span id=__span-6-114><a id=__codelineno-6-114 name=__codelineno-6-114></a><a href=#__codelineno-6-114><span class=linenos data-linenos="114 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x8_pack:<span class=w> </span><span class=m>17</span>.27x
</span><span id=__span-6-115><a id=__codelineno-6-115 name=__codelineno-6-115></a><a href=#__codelineno-6-115><span class=linenos data-linenos="115 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>Vec4:<span class=w>       </span><span class=m>0</span>.96x
</span><span id=__span-6-116><a id=__codelineno-6-116 name=__codelineno-6-116></a><a href=#__codelineno-6-116><span class=linenos data-linenos="116 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16:<span class=w>       </span><span class=m>0</span>.98x
</span><span id=__span-6-117><a id=__codelineno-6-117 name=__codelineno-6-117></a><a href=#__codelineno-6-117><span class=linenos data-linenos="117 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>     </span><span class=m>1</span>.00x
</span><span id=__span-6-118><a id=__codelineno-6-118 name=__codelineno-6-118></a><a href=#__codelineno-6-118><span class=linenos data-linenos="118 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>     </span><span class=m>0</span>.92x
</span><span id=__span-6-119><a id=__codelineno-6-119 name=__codelineno-6-119></a><a href=#__codelineno-6-119><span class=linenos data-linenos="119 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>0</span>.88x
</span><span id=__span-6-120><a id=__codelineno-6-120 name=__codelineno-6-120></a><a href=#__codelineno-6-120><span class=linenos data-linenos="120 "></span></a>FP16<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>         </span><span class=m>1</span>.01x
</span><span id=__span-6-121><a id=__codelineno-6-121 name=__codelineno-6-121></a><a href=#__codelineno-6-121><span class=linenos data-linenos="121 "></span></a>FP16x2<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>       </span><span class=m>0</span>.93x
</span><span id=__span-6-122><a id=__codelineno-6-122 name=__codelineno-6-122></a><a href=#__codelineno-6-122><span class=linenos data-linenos="122 "></span></a>FP16x8<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>0</span>.95x
</span><span id=__span-6-123><a id=__codelineno-6-123 name=__codelineno-6-123></a><a href=#__codelineno-6-123><span class=linenos data-linenos="123 "></span></a>
</span><span id=__span-6-124><a id=__codelineno-6-124 name=__codelineno-6-124></a><a href=#__codelineno-6-124><span class=linenos data-linenos="124 "></span></a><span class=o>==========</span><span class=w> </span>Testing<span class=w> </span>256K<span class=w> </span><span class=o>(</span><span class=nv>N</span><span class=o>=</span><span class=m>262144</span><span class=o>)</span><span class=w> </span><span class=o>==========</span>
</span><span id=__span-6-125><a id=__codelineno-6-125 name=__codelineno-6-125></a><a href=#__codelineno-6-125><span class=linenos data-linenos="125 "></span></a>Mismatch<span class=w> </span>at<span class=w> </span>index<span class=w> </span><span class=m>0</span>:<span class=w> </span><span class=m>14</span>.3984<span class=w> </span>!<span class=o>=</span><span class=w> </span><span class=m>14</span>.4<span class=w> </span><span class=o>(</span>error:<span class=w> </span><span class=m>0</span>.00156307<span class=o>)</span>
</span><span id=__span-6-126><a id=__codelineno-6-126 name=__codelineno-6-126></a><a href=#__codelineno-6-126><span class=linenos data-linenos="126 "></span></a>Correctness:<span class=w> </span>FAIL<span class=w> </span><span class=o>(</span>Max<span class=w> </span>error:<span class=w> </span><span class=m>0</span>.037506<span class=o>)</span>
</span><span id=__span-6-127><a id=__codelineno-6-127 name=__codelineno-6-127></a><a href=#__codelineno-6-127><span class=linenos data-linenos="127 "></span></a>Array<span class=w> </span>Size:<span class=w> </span><span class=m>262144</span><span class=w> </span>elements<span class=w> </span><span class=o>(</span><span class=m>0</span>.00<span class=w> </span>GB<span class=o>)</span>
</span><span id=__span-6-128><a id=__codelineno-6-128 name=__codelineno-6-128></a><a href=#__codelineno-6-128><span class=linenos data-linenos="128 "></span></a>
</span><span id=__span-6-129><a id=__codelineno-6-129 name=__codelineno-6-129></a><a href=#__codelineno-6-129><span class=linenos data-linenos="129 "></span></a>---<span class=w> </span>Execution<span class=w> </span>Times<span class=w> </span><span class=o>(</span>Kernel<span class=w> </span>Only<span class=o>)</span><span class=w> </span>---
</span><span id=__span-6-130><a id=__codelineno-6-130 name=__codelineno-6-130></a><a href=#__codelineno-6-130><span class=linenos data-linenos="130 "></span></a>CPU<span class=w> </span>Time:<span class=w>           </span><span class=m>0</span>.7488<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>4</span>.2<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-131><a id=__codelineno-6-131 name=__codelineno-6-131></a><a href=#__codelineno-6-131><span class=linenos data-linenos="131 "></span></a>GPU<span class=w> </span>Standard:<span class=w>       </span><span class=m>0</span>.0111<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>  </span><span class=m>282</span>.9<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-132><a id=__codelineno-6-132 name=__codelineno-6-132></a><a href=#__codelineno-6-132><span class=linenos data-linenos="132 "></span></a>GPU<span class=w> </span>Vec4:<span class=w>           </span><span class=m>0</span>.0105<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>  </span><span class=m>299</span>.7<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-133><a id=__codelineno-6-133 name=__codelineno-6-133></a><a href=#__codelineno-6-133><span class=linenos data-linenos="133 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>Std:<span class=w>       </span><span class=m>0</span>.0108<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>  </span><span class=m>145</span>.7<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-134><a id=__codelineno-6-134 name=__codelineno-6-134></a><a href=#__codelineno-6-134><span class=linenos data-linenos="134 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x2:<span class=w>        </span><span class=m>0</span>.0101<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>  </span><span class=m>155</span>.5<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-135><a id=__codelineno-6-135 name=__codelineno-6-135></a><a href=#__codelineno-6-135><span class=linenos data-linenos="135 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x8:<span class=w>        </span><span class=m>0</span>.0107<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>  </span><span class=m>146</span>.7<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-136><a id=__codelineno-6-136 name=__codelineno-6-136></a><a href=#__codelineno-6-136><span class=linenos data-linenos="136 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x8_pack:<span class=w>   </span><span class=m>0</span>.0109<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>  </span><span class=m>143</span>.9<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-137><a id=__codelineno-6-137 name=__codelineno-6-137></a><a href=#__codelineno-6-137><span class=linenos data-linenos="137 "></span></a>
</span><span id=__span-6-138><a id=__codelineno-6-138 name=__codelineno-6-138></a><a href=#__codelineno-6-138><span class=linenos data-linenos="138 "></span></a>---<span class=w> </span>Speedup<span class=w> </span>Analysis<span class=w> </span>---
</span><span id=__span-6-139><a id=__codelineno-6-139 name=__codelineno-6-139></a><a href=#__codelineno-6-139><span class=linenos data-linenos="139 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>Standard:<span class=w>   </span><span class=m>67</span>.36x
</span><span id=__span-6-140><a id=__codelineno-6-140 name=__codelineno-6-140></a><a href=#__codelineno-6-140><span class=linenos data-linenos="140 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>Vec4:<span class=w>       </span><span class=m>71</span>.34x
</span><span id=__span-6-141><a id=__codelineno-6-141 name=__codelineno-6-141></a><a href=#__codelineno-6-141><span class=linenos data-linenos="141 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16:<span class=w>       </span><span class=m>69</span>.35x
</span><span id=__span-6-142><a id=__codelineno-6-142 name=__codelineno-6-142></a><a href=#__codelineno-6-142><span class=linenos data-linenos="142 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x2:<span class=w>     </span><span class=m>74</span>.03x
</span><span id=__span-6-143><a id=__codelineno-6-143 name=__codelineno-6-143></a><a href=#__codelineno-6-143><span class=linenos data-linenos="143 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x8:<span class=w>     </span><span class=m>69</span>.83x
</span><span id=__span-6-144><a id=__codelineno-6-144 name=__codelineno-6-144></a><a href=#__codelineno-6-144><span class=linenos data-linenos="144 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x8_pack:<span class=w> </span><span class=m>68</span>.53x
</span><span id=__span-6-145><a id=__codelineno-6-145 name=__codelineno-6-145></a><a href=#__codelineno-6-145><span class=linenos data-linenos="145 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>Vec4:<span class=w>       </span><span class=m>1</span>.06x
</span><span id=__span-6-146><a id=__codelineno-6-146 name=__codelineno-6-146></a><a href=#__codelineno-6-146><span class=linenos data-linenos="146 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16:<span class=w>       </span><span class=m>1</span>.03x
</span><span id=__span-6-147><a id=__codelineno-6-147 name=__codelineno-6-147></a><a href=#__codelineno-6-147><span class=linenos data-linenos="147 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>     </span><span class=m>1</span>.10x
</span><span id=__span-6-148><a id=__codelineno-6-148 name=__codelineno-6-148></a><a href=#__codelineno-6-148><span class=linenos data-linenos="148 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>     </span><span class=m>1</span>.04x
</span><span id=__span-6-149><a id=__codelineno-6-149 name=__codelineno-6-149></a><a href=#__codelineno-6-149><span class=linenos data-linenos="149 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>1</span>.02x
</span><span id=__span-6-150><a id=__codelineno-6-150 name=__codelineno-6-150></a><a href=#__codelineno-6-150><span class=linenos data-linenos="150 "></span></a>FP16<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>         </span><span class=m>1</span>.07x
</span><span id=__span-6-151><a id=__codelineno-6-151 name=__codelineno-6-151></a><a href=#__codelineno-6-151><span class=linenos data-linenos="151 "></span></a>FP16x2<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>       </span><span class=m>0</span>.94x
</span><span id=__span-6-152><a id=__codelineno-6-152 name=__codelineno-6-152></a><a href=#__codelineno-6-152><span class=linenos data-linenos="152 "></span></a>FP16x8<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>0</span>.98x
</span><span id=__span-6-153><a id=__codelineno-6-153 name=__codelineno-6-153></a><a href=#__codelineno-6-153><span class=linenos data-linenos="153 "></span></a>
</span><span id=__span-6-154><a id=__codelineno-6-154 name=__codelineno-6-154></a><a href=#__codelineno-6-154><span class=linenos data-linenos="154 "></span></a><span class=o>==========</span><span class=w> </span>Testing<span class=w> </span>1M<span class=w> </span><span class=o>(</span><span class=nv>N</span><span class=o>=</span><span class=m>1048576</span><span class=o>)</span><span class=w> </span><span class=o>==========</span>
</span><span id=__span-6-155><a id=__codelineno-6-155 name=__codelineno-6-155></a><a href=#__codelineno-6-155><span class=linenos data-linenos="155 "></span></a>Mismatch<span class=w> </span>at<span class=w> </span>index<span class=w> </span><span class=m>0</span>:<span class=w> </span><span class=m>57</span>.5938<span class=w> </span>!<span class=o>=</span><span class=w> </span><span class=m>57</span>.6<span class=w> </span><span class=o>(</span>error:<span class=w> </span><span class=m>0</span>.00625229<span class=o>)</span>
</span><span id=__span-6-156><a id=__codelineno-6-156 name=__codelineno-6-156></a><a href=#__codelineno-6-156><span class=linenos data-linenos="156 "></span></a>Correctness:<span class=w> </span>FAIL<span class=w> </span><span class=o>(</span>Max<span class=w> </span>error:<span class=w> </span><span class=m>0</span>.100006<span class=o>)</span>
</span><span id=__span-6-157><a id=__codelineno-6-157 name=__codelineno-6-157></a><a href=#__codelineno-6-157><span class=linenos data-linenos="157 "></span></a>Array<span class=w> </span>Size:<span class=w> </span><span class=m>1048576</span><span class=w> </span>elements<span class=w> </span><span class=o>(</span><span class=m>0</span>.01<span class=w> </span>GB<span class=o>)</span>
</span><span id=__span-6-158><a id=__codelineno-6-158 name=__codelineno-6-158></a><a href=#__codelineno-6-158><span class=linenos data-linenos="158 "></span></a>
</span><span id=__span-6-159><a id=__codelineno-6-159 name=__codelineno-6-159></a><a href=#__codelineno-6-159><span class=linenos data-linenos="159 "></span></a>---<span class=w> </span>Execution<span class=w> </span>Times<span class=w> </span><span class=o>(</span>Kernel<span class=w> </span>Only<span class=o>)</span><span class=w> </span>---
</span><span id=__span-6-160><a id=__codelineno-6-160 name=__codelineno-6-160></a><a href=#__codelineno-6-160><span class=linenos data-linenos="160 "></span></a>CPU<span class=w> </span>Time:<span class=w>           </span><span class=m>3</span>.0058<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>    </span><span class=m>4</span>.2<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-161><a id=__codelineno-6-161 name=__codelineno-6-161></a><a href=#__codelineno-6-161><span class=linenos data-linenos="161 "></span></a>GPU<span class=w> </span>Standard:<span class=w>       </span><span class=m>0</span>.0250<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>  </span><span class=m>503</span>.4<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-162><a id=__codelineno-6-162 name=__codelineno-6-162></a><a href=#__codelineno-6-162><span class=linenos data-linenos="162 "></span></a>GPU<span class=w> </span>Vec4:<span class=w>           </span><span class=m>0</span>.0233<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>  </span><span class=m>539</span>.8<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-163><a id=__codelineno-6-163 name=__codelineno-6-163></a><a href=#__codelineno-6-163><span class=linenos data-linenos="163 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>Std:<span class=w>       </span><span class=m>0</span>.0163<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>  </span><span class=m>384</span>.9<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-164><a id=__codelineno-6-164 name=__codelineno-6-164></a><a href=#__codelineno-6-164><span class=linenos data-linenos="164 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x2:<span class=w>        </span><span class=m>0</span>.0132<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>  </span><span class=m>475</span>.7<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-165><a id=__codelineno-6-165 name=__codelineno-6-165></a><a href=#__codelineno-6-165><span class=linenos data-linenos="165 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x8:<span class=w>        </span><span class=m>0</span>.0161<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>  </span><span class=m>391</span>.2<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-166><a id=__codelineno-6-166 name=__codelineno-6-166></a><a href=#__codelineno-6-166><span class=linenos data-linenos="166 "></span></a>GPU<span class=w> </span>FP16<span class=w> </span>x8_pack:<span class=w>   </span><span class=m>0</span>.0158<span class=w> </span>ms<span class=w> </span><span class=o>(</span>Bandwidth:<span class=w>  </span><span class=m>398</span>.0<span class=w> </span>GB/s<span class=o>)</span>
</span><span id=__span-6-167><a id=__codelineno-6-167 name=__codelineno-6-167></a><a href=#__codelineno-6-167><span class=linenos data-linenos="167 "></span></a>
</span><span id=__span-6-168><a id=__codelineno-6-168 name=__codelineno-6-168></a><a href=#__codelineno-6-168><span class=linenos data-linenos="168 "></span></a>---<span class=w> </span>Speedup<span class=w> </span>Analysis<span class=w> </span>---
</span><span id=__span-6-169><a id=__codelineno-6-169 name=__codelineno-6-169></a><a href=#__codelineno-6-169><span class=linenos data-linenos="169 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>Standard:<span class=w>  </span><span class=m>120</span>.26x
</span><span id=__span-6-170><a id=__codelineno-6-170 name=__codelineno-6-170></a><a href=#__codelineno-6-170><span class=linenos data-linenos="170 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>Vec4:<span class=w>      </span><span class=m>128</span>.94x
</span><span id=__span-6-171><a id=__codelineno-6-171 name=__codelineno-6-171></a><a href=#__codelineno-6-171><span class=linenos data-linenos="171 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16:<span class=w>      </span><span class=m>183</span>.90x
</span><span id=__span-6-172><a id=__codelineno-6-172 name=__codelineno-6-172></a><a href=#__codelineno-6-172><span class=linenos data-linenos="172 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x2:<span class=w>    </span><span class=m>227</span>.29x
</span><span id=__span-6-173><a id=__codelineno-6-173 name=__codelineno-6-173></a><a href=#__codelineno-6-173><span class=linenos data-linenos="173 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x8:<span class=w>    </span><span class=m>186</span>.88x
</span><span id=__span-6-174><a id=__codelineno-6-174 name=__codelineno-6-174></a><a href=#__codelineno-6-174><span class=linenos data-linenos="174 "></span></a>CPU<span class=w> </span>vs<span class=w> </span>GPU<span class=w> </span>FP16x8_pack:190.17x
</span><span id=__span-6-175><a id=__codelineno-6-175 name=__codelineno-6-175></a><a href=#__codelineno-6-175><span class=linenos data-linenos="175 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>Vec4:<span class=w>       </span><span class=m>1</span>.07x
</span><span id=__span-6-176><a id=__codelineno-6-176 name=__codelineno-6-176></a><a href=#__codelineno-6-176><span class=linenos data-linenos="176 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16:<span class=w>       </span><span class=m>1</span>.53x
</span><span id=__span-6-177><a id=__codelineno-6-177 name=__codelineno-6-177></a><a href=#__codelineno-6-177><span class=linenos data-linenos="177 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>     </span><span class=m>1</span>.89x
</span><span id=__span-6-178><a id=__codelineno-6-178 name=__codelineno-6-178></a><a href=#__codelineno-6-178><span class=linenos data-linenos="178 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>     </span><span class=m>1</span>.55x
</span><span id=__span-6-179><a id=__codelineno-6-179 name=__codelineno-6-179></a><a href=#__codelineno-6-179><span class=linenos data-linenos="179 "></span></a>Standard<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>1</span>.58x
</span><span id=__span-6-180><a id=__codelineno-6-180 name=__codelineno-6-180></a><a href=#__codelineno-6-180><span class=linenos data-linenos="180 "></span></a>FP16<span class=w> </span>vs<span class=w> </span>FP16x2:<span class=w>         </span><span class=m>1</span>.24x
</span><span id=__span-6-181><a id=__codelineno-6-181 name=__codelineno-6-181></a><a href=#__codelineno-6-181><span class=linenos data-linenos="181 "></span></a>FP16x2<span class=w> </span>vs<span class=w> </span>FP16x8:<span class=w>       </span><span class=m>0</span>.82x
</span><span id=__span-6-182><a id=__codelineno-6-182 name=__codelineno-6-182></a><a href=#__codelineno-6-182><span class=linenos data-linenos="182 "></span></a>FP16x8<span class=w> </span>vs<span class=w> </span>FP16x8_pack:<span class=w>  </span><span class=m>1</span>.02x
</span><span id=__span-6-183><a id=__codelineno-6-183 name=__codelineno-6-183></a><a href=#__codelineno-6-183><span class=linenos data-linenos="183 "></span></a>
</span><span id=__span-6-184><a id=__codelineno-6-184 name=__codelineno-6-184></a><a href=#__codelineno-6-184><span class=linenos data-linenos="184 "></span></a><span class=o>==========</span><span class=w> </span>Test<span class=w> </span><span class=nv>Complete</span><span class=w> </span><span class=o>==========</span>
</span><span id=__span-6-185><a id=__codelineno-6-185 name=__codelineno-6-185></a><a href=#__codelineno-6-185><span class=linenos data-linenos="185 "></span></a>➜<span class=w>  </span>build<span class=w> </span>git:<span class=o>(</span>master<span class=o>)</span><span class=w> </span>✗
</span></code></pre></div> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"></path></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="October 28, 2025 23:25:09 CST">October 28, 2025 23:25:09</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"></path></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime" title="October 28, 2025 23:25:09 CST">October 28, 2025 23:25:09</span> </span> </aside> <form class=md-feedback name=feedback hidden> <fieldset> <legend class=md-feedback__title> Support Me! </legend> <div class=md-feedback__inner> <div class=md-feedback__list> <button class="md-feedback__icon md-icon" type=submit title="Support Me!" data-md-value=1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 384 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M96 400c-17.7 0-32 14.3-32 32v48c0 17.7 14.3 32 32 32h224c17.7 0 32-14.3 32-32v-48c0-17.7-14.3-32-32-32zm-22.8-48h64.6l-79.5-88.3c-6.6-7.4-10.3-16.9-10.3-26.8V204c0-16.1 11.9-29.5 27.4-31.7 11.8-1.7 20.6-11.8 20.6-23.8V72c0-13.3 10.7-24 24-24 7.2 0 13.6 3.1 18 8.1 4.6 5.2 11.1 8.1 18 8.1s13.4-3 18-8.1c4.4-5 10.8-8.1 18-8.1 8.5 0 15.9 4.4 20.2 11.1 6.9 10.7 20.9 14.2 32 8 3.5-1.9 7.4-3.1 11.8-3.1 10.6 0 19.7 6.9 22.8 16.6 3.8 11.7 15.9 18.7 28 16 1.7-.4 3.4-.6 5.2-.6 13.3 0 24 10.7 24 24v92.2c0 14.4-3.5 28.5-10.2 41.2L273.6 352h54.3l40.3-76.2c10.4-19.6 15.8-41.5 15.8-63.6V120c0-38.4-30.1-69.8-68.1-71.9C303 28.8 281 16 256 16c-5.7 0-11.2.7-16.5 1.9C226.8 6.8 210.2 0 192 0c-13.1 0-25.4 3.5-36 9.6C145.4 3.5 133.1 0 120 0 80.2 0 48 32.2 48 72v58.7C19.7 143 0 171.2 0 204v32.9c0 21.7 8 42.7 22.6 58.9z"></path></svg> </button> </div> <div class=md-feedback__note> <div data-md-value=1 hidden> <center> 难道说……你愿意给我买一瓶快乐水吗！🫣 </center> <center> How about...buy me a coffee？😋 </center> <img src=/img/wechat.png width=200px> </div> </div> </div> </fieldset> </form> <!-- Insert generated snippet here --> <script src=https://giscus.app/client.js data-repo=tom-jerr/tom-jerr.github.io data-repo-id=R_kgDONZrjcA data-category=Announcements data-category-id=DIC_kwDONZrjcM4Ck-PT data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=1 data-input-position=top data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous async>
    </script> <!-- Synchronize Giscus theme with palette --> <script>
    var giscus = document.querySelector("script[src*=giscus]")

    // Set palette on initial load
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate"
            ? "transparent_dark"
            : "light"

        // Instruct Giscus to set theme
        giscus.setAttribute("data-theme", theme)
    }

    // Register event handlers after documented loaded
    document.addEventListener("DOMContentLoaded", function () {
        var ref = document.querySelector("[data-md-component=palette]")
        ref.addEventListener("change", function () {
            var palette = __md_get("__palette")
            if (palette && typeof palette.color === "object") {
                var theme = palette.color.scheme === "slate"
                    ? "transparent_dark"
                    : "light"

                // Instruct Giscus to change theme
                var frame = document.querySelector(".giscus-frame")
                frame.contentWindow.postMessage(
                    {giscus: {setConfig: {theme}}},
                    "https://giscus.app"
                )
            }
        })
    })
</script> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright © 2025 - Present <a href=https://github.com/tom-jerr/ target=_blank rel=noopener>tom-jerr</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/tom-jerr/ target=_blank rel=noopener title=GitHub class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg> </a> <a href=/img/qq.png target=_blank rel=noopener title=QQ class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M434.1 420.4c-11.5 1.4-44.9-52.7-44.9-52.7 0 31.3-16.1 72.2-51 101.8 16.8 5.2 54.8 19.2 45.8 34.4-7.3 12.3-125.5 7.9-159.6 4-34.1 3.8-152.3 8.3-159.6-4-9-15.2 28.9-29.2 45.8-34.4-34.9-29.5-51.1-70.4-51.1-101.8 0 0-33.3 54.1-44.9 52.7-5.4-.6-12.4-29.6 9.3-99.7 10.3-33 22-60.5 40.1-105.8C60.9 98 109.2-.1 224.3-.1 338-.1 387.5 96 384.6 214.9c18.1 45.2 29.9 72.9 40.1 105.8 21.8 70.1 14.7 99.1 9.3 99.7z"></path></svg> </a> <a href=/img/wechat.png target=_blank rel=noopener title=微信 class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M385.2 167.6c6.4 0 12.6.3 18.8 1.1C387.4 90.3 303.3 32 207.7 32 100.5 32 13 104.8 13 197.4c0 53.4 29.3 97.5 77.9 131.6l-19.3 58.6 68-34.1c24.4 4.8 43.8 9.7 68.2 9.7 6.2 0 12.1-.3 18.3-.8-4-12.9-6.2-26.6-6.2-40.8-.1-84.9 72.9-154 165.3-154m-104.5-52.9c14.5 0 24.2 9.7 24.2 24.4 0 14.5-9.7 24.2-24.2 24.2-14.8 0-29.3-9.7-29.3-24.2.1-14.7 14.6-24.4 29.3-24.4m-136.4 48.6c-14.5 0-29.3-9.7-29.3-24.2 0-14.8 14.8-24.4 29.3-24.4 14.8 0 24.4 9.7 24.4 24.4 0 14.6-9.6 24.2-24.4 24.2M563 319.4c0-77.9-77.9-141.3-165.4-141.3-92.7 0-165.4 63.4-165.4 141.3S305 460.7 397.6 460.7c19.3 0 38.9-5.1 58.6-9.9l53.4 29.3-14.8-48.6C534 402.1 563 363.2 563 319.4m-219.1-24.5c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.8 0 24.4 9.7 24.4 19.3 0 10-9.7 19.6-24.4 19.6m107.1 0c-9.7 0-19.3-9.7-19.3-19.6 0-9.7 9.7-19.3 19.3-19.3 14.5 0 24.4 9.7 24.4 19.3.1 10-9.9 19.6-24.4 19.6"></path></svg> </a> <a href=https://x.com/tom_jerry_jack target=_blank rel=noopener title=X class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z"></path></svg> </a> <a href=https://www.zhihu.com/people/chen-wen-de-jian-ke target=_blank rel=noopener title=Zhihu class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M170.5 148.1v217.5h23.4l7.7 26.4 42-26.4h49.5V148.1H170.4zM268.3 342h-27.9l-27.9 17.5-5.1-17.5h-11.9V171.7h72.8zm-118.5-94.3H97.5c1.7-27.1 2.2-51.6 2.2-73.5h51.2s2-22.6-8.6-22.3H53.8c3.5-13.1 7.9-26.7 13.1-40.7 0 0-24.1 0-32.3 21.6-3.4 8.9-13.2 43.1-30.7 78.1 5.9-.6 25.4-1.2 36.8-22.2 2.1-5.9 2.5-6.7 5.1-14.5h28.9c0 10.5-1.2 66.9-1.7 73.4H20.7c-11.7 0-15.6 23.6-15.6 23.6h65.6c-4.4 49.9-28 91.9-70.8 125.1 20.5 5.9 40.9-.9 51-9.9 0 0 23-20.9 35.6-69.3l54 64.9s7.9-26.9-1.2-40c-7.6-8.9-28.1-33.1-36.8-41.8L87.9 312c4.4-14 7-27.6 7.9-40.7h61.6s-.1-23.6-7.6-23.6m412-1.6c20.8-25.6 45-58.6 45-58.6s-18.6-14.8-27.4-4.1c-6 8.2-36.8 48.2-36.8 48.2l19.2 14.4zm-150-59.1c-9-8.2-25.9 2.1-25.9 2.1s39.5 55 41.1 57.4l19.5-13.7s-25.7-37.6-34.7-45.9zM640 258.4c-19.8 0-130.9.9-131.1.9v-101q7.2 0 22.8-1.2c40.9-2.4 70.1-4 87.8-4.8 0 0 12.2-27.2-.6-33.4-3.1-1.2-23.2 4.6-23.2 4.6s-165.2 16.5-232.4 18c1.6 8.8 7.6 17.1 15.8 19.6 13.3 3.5 22.7 1.7 49.2.9 24.8-1.6 43.7-2.4 56.5-2.4v99.8H351.3s2.8 22.3 25.5 22.9h107.9v70.9c0 14-11.2 22-24.5 21.1-14.1.1-26.1-1.1-41.7-1.8 2 4 6.3 14.4 19.3 21.8 9.9 4.8 16.2 6.6 26 6.6 29.6 0 45.7-17.3 44.9-45.3v-73.3h122.4c9.7 0 8.7-23.8 8.7-23.8z"></path></svg> </a> <a href=mailto:2584074296@qq.com target=_blank rel=noopener title="send email to me!" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M536.4-26.3c9.8-3.5 20.6-1 28 6.3s9.8 18.2 6.3 28l-178 496.9c-5 13.9-18.1 23.1-32.8 23.1-14.2 0-27-8.6-32.3-21.7l-64.2-158c-4.5-11-2.5-23.6 5.2-32.6l94.5-112.4c5.1-6.1 4.7-15-.9-20.6s-14.6-6-20.6-.9l-112.4 94.3c-9.1 7.6-21.6 9.6-32.6 5.2L38.1 216.8c-13.1-5.3-21.7-18.1-21.7-32.3 0-14.7 9.2-27.8 23.1-32.8z"></path></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["content.code.annotate", "content.code.copy", "content.code.select", "content.footnote.tooltips", "content.tabs.link", "header.autohide", "navigation.tracking", "navigation.tabs", "navigation.top", "navigation.path", "navigation.indexes", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../../assets/javascripts/bundle.f55a23d4.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script> <script src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script> <script src=../../../js/mathjax.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>